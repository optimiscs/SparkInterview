"""
ç®€å†æ•°æ®è®¿é—®å±‚ (Data Access Object)
æ¶ˆé™¤æ–‡ä»¶æ“ä½œå†—ä½™ï¼Œæä¾›ç»Ÿä¸€çš„æ•°æ®è®¿é—®æ¥å£
"""
import os
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
from fastapi import HTTPException

logger = logging.getLogger(__name__)

class ResumeDAO:
    """ç®€å†æ•°æ®è®¿é—®å¯¹è±¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®ç›®å½•"""
        self.resume_dir = Path("data/resumes")
        self.analysis_dir = Path("data/resume_analysis")
        self.profile_dir = Path("data/user_profiles")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.resume_dir.mkdir(parents=True, exist_ok=True)
        self.analysis_dir.mkdir(parents=True, exist_ok=True)
        self.profile_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info("âœ… ç®€å†æ•°æ®è®¿é—®å±‚åˆå§‹åŒ–å®Œæˆ")
    
    # ==================== ç®€å†CRUDæ“ä½œ ====================
    
    def save_resume(self, resume_id: str, resume_data: Dict[str, Any]) -> bool:
        """ä¿å­˜ç®€å†æ•°æ®ï¼ˆæ”¯æŒç‰ˆæœ¬æ§åˆ¶ï¼‰"""
        try:
            resume_file = self.resume_dir / f"{resume_id}.json"
            
            # æ·»åŠ ç‰ˆæœ¬æ§åˆ¶å…ƒæ•°æ®
            current_time = datetime.now().isoformat()
            resume_data["updated_at"] = current_time
            
            if "created_at" not in resume_data:
                resume_data["created_at"] = current_time
                resume_data["version"] = "v1"
                resume_data["version_history"] = []
            else:
                # æ›´æ–°ç‰ˆæœ¬
                old_version = resume_data.get("version", "v1")
                new_version_num = int(old_version.replace("v", "")) + 1 if old_version.startswith("v") else 1
                new_version = f"v{new_version_num}"
                
                # è®°å½•ç‰ˆæœ¬å†å²
                if "version_history" not in resume_data:
                    resume_data["version_history"] = []
                
                resume_data["version_history"].append({
                    "version": old_version,
                    "updated_at": resume_data.get("updated_at", current_time),
                    "change_summary": "ç®€å†å†…å®¹æ›´æ–°"
                })
                
                resume_data["version"] = new_version
            
            # æ·»åŠ åˆ†æçŠ¶æ€
            if "analysis_status" not in resume_data:
                resume_data["analysis_status"] = "PROCESSING"
            
            # ç”Ÿæˆç‰ˆæœ¬ID
            resume_data["version_id"] = f"{resume_id}_{resume_data['version']}"
            
            with open(resume_file, 'w', encoding='utf-8') as f:
                json.dump(resume_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ’¾ ç®€å†å·²ä¿å­˜: {resume_id} (ç‰ˆæœ¬: {resume_data['version']})")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç®€å†å¤±è´¥: {resume_id} - {e}")
            return False
    
    def get_resume(self, resume_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ç®€å†æ•°æ®"""
        try:
            resume_file = self.resume_dir / f"{resume_id}.json"
            
            if not resume_file.exists():
                logger.warning(f"âš ï¸ ç®€å†ä¸å­˜åœ¨: {resume_id}")
                return None
            
            with open(resume_file, 'r', encoding='utf-8') as f:
                resume_data = json.load(f)
            
            logger.debug(f"ğŸ“– ç®€å†è¯»å–æˆåŠŸ: {resume_id}")
            return resume_data
            
        except Exception as e:
            logger.error(f"âŒ è¯»å–ç®€å†å¤±è´¥: {resume_id} - {e}")
            return None
    
    def get_resume_with_permission_check(self, resume_id: str, user_id: str) -> Dict[str, Any]:
        """è·å–ç®€å†å¹¶æ£€æŸ¥æƒé™"""
        resume_data = self.get_resume(resume_id)
        
        if not resume_data:
            raise HTTPException(status_code=404, detail="ç®€å†ä¸å­˜åœ¨")
        
        if resume_data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ç®€å†")
        
        return resume_data
    
    def delete_resume(self, resume_id: str, user_id: str) -> bool:
        """åˆ é™¤ç®€å†"""
        try:
            # å…ˆéªŒè¯æƒé™
            resume_data = self.get_resume_with_permission_check(resume_id, user_id)
            
            # åˆ é™¤ç®€å†æ–‡ä»¶
            resume_file = self.resume_dir / f"{resume_id}.json"
            if resume_file.exists():
                resume_file.unlink()
            
            # åˆ é™¤ç›¸å…³åˆ†ææ–‡ä»¶
            self._delete_related_analysis(resume_id)
            
            # åˆ é™¤ç›¸å…³ç”»åƒæ–‡ä»¶
            self._delete_related_profile(resume_id)
            
            logger.info(f"ğŸ—‘ï¸ ç®€å†å·²åˆ é™¤: {resume_id}")
            return True
            
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤ç®€å†å¤±è´¥: {resume_id} - {e}")
            return False
    
    def list_user_resumes(self, user_id: str) -> List[Dict[str, Any]]:
        """è·å–ç”¨æˆ·çš„æ‰€æœ‰ç®€å†"""
        try:
            user_resumes = []
            
            for resume_file in self.resume_dir.glob("*.json"):
                try:
                    with open(resume_file, 'r', encoding='utf-8') as f:
                        resume_data = json.load(f)
                    
                    if resume_data.get("user_id") == user_id:
                        # åªè¿”å›åˆ—è¡¨éœ€è¦çš„å­—æ®µ
                        resume_summary = {
                            "id": resume_file.stem,  # ä½¿ç”¨idå­—æ®µä¿æŒä¸€è‡´æ€§
                            "resume_id": resume_file.stem,  # ä¿ç•™resume_idä»¥å‘åå…¼å®¹
                            "version_name": resume_data.get("version_name", ""),
                            "target_position": resume_data.get("target_position", ""),
                            "created_at": resume_data.get("created_at", ""),
                            "updated_at": resume_data.get("updated_at", ""),
                            "status": resume_data.get("status", "active"),
                            "has_analysis": self._has_analysis(resume_file.stem),
                            "has_profile": self._has_profile(resume_file.stem),
                            "version": resume_data.get("version", "v1"),
                            "analysis_status": resume_data.get("analysis_status", "COMPLETED")
                        }
                        user_resumes.append(resume_summary)
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯»å–ç®€å†æ–‡ä»¶å¤±è´¥: {resume_file} - {e}")
                    continue
            
            # æŒ‰æ›´æ–°æ—¶é—´æ’åº
            user_resumes.sort(key=lambda x: x.get("updated_at", ""), reverse=True)
            
            logger.info(f"ğŸ“‹ ç”¨æˆ· {user_id} çš„ç®€å†åˆ—è¡¨: {len(user_resumes)} ä¸ªç®€å†")
            return user_resumes
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç”¨æˆ·ç®€å†åˆ—è¡¨å¤±è´¥: {user_id} - {e}")
            return []
    
    def get_user_latest_resume(self, user_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ç”¨æˆ·æœ€æ–°çš„ç®€å†"""
        try:
            user_resumes = self.list_user_resumes(user_id)
            
            if not user_resumes:
                return None
            
            # è·å–æœ€æ–°ç®€å†çš„å®Œæ•´æ•°æ®
            latest_resume_id = user_resumes[0]["resume_id"]
            return self.get_resume(latest_resume_id)
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç”¨æˆ·æœ€æ–°ç®€å†å¤±è´¥: {user_id} - {e}")
            return None
    
    # ==================== åˆ†æç»“æœæ“ä½œ ====================
    
    def save_analysis(self, analysis_id: str, analysis_data: Dict[str, Any]) -> bool:
        """ä¿å­˜åˆ†æç»“æœï¼ˆæ”¯æŒç‰ˆæœ¬å…³è”ï¼‰"""
        try:
            analysis_file = self.analysis_dir / f"{analysis_id}.json"
            
            # æ·»åŠ å…ƒæ•°æ®
            analysis_data["saved_at"] = datetime.now().isoformat()
            
            # ç¡®ä¿åŒ…å«ç‰ˆæœ¬ä¿¡æ¯
            if "resume_id" in analysis_data:
                resume_data = self.get_resume(analysis_data["resume_id"])
                if resume_data:
                    analysis_data["resume_version"] = resume_data.get("version", "v1")
                    analysis_data["version_id"] = resume_data.get("version_id")
            
            with open(analysis_file, 'w', encoding='utf-8') as f:
                json.dump(analysis_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜: {analysis_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜åˆ†æç»“æœå¤±è´¥: {analysis_id} - {e}")
            return False
    
    def get_analysis(self, analysis_id: str) -> Optional[Dict[str, Any]]:
        """è·å–åˆ†æç»“æœ"""
        try:
            analysis_file = self.analysis_dir / f"{analysis_id}.json"
            
            if not analysis_file.exists():
                return None
            
            with open(analysis_file, 'r', encoding='utf-8') as f:
                analysis_data = json.load(f)
            
            logger.debug(f"ğŸ“Š åˆ†æç»“æœè¯»å–æˆåŠŸ: {analysis_id}")
            return analysis_data
            
        except Exception as e:
            logger.error(f"âŒ è¯»å–åˆ†æç»“æœå¤±è´¥: {analysis_id} - {e}")
            return None
    
    def get_resume_analysis(self, resume_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ç®€å†çš„æœ€æ–°åˆ†æç»“æœ"""
        try:
            # æŸ¥æ‰¾è¯¥ç®€å†ç›¸å…³çš„åˆ†ææ–‡ä»¶
            analysis_files = list(self.analysis_dir.glob(f"*{resume_id}*.json"))
            
            if not analysis_files:
                return None
            
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°çš„
            analysis_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            latest_analysis_file = analysis_files[0]
            
            with open(latest_analysis_file, 'r', encoding='utf-8') as f:
                analysis_data = json.load(f)
            
            logger.debug(f"ğŸ“Š ç®€å†åˆ†æç»“æœè¯»å–æˆåŠŸ: {resume_id}")
            return analysis_data
            
        except Exception as e:
            logger.error(f"âŒ è¯»å–ç®€å†åˆ†æç»“æœå¤±è´¥: {resume_id} - {e}")
            return None
    
    def delete_analysis(self, analysis_id: str) -> bool:
        """åˆ é™¤åˆ†æç»“æœ"""
        try:
            analysis_file = self.analysis_dir / f"{analysis_id}.json"
            
            if analysis_file.exists():
                analysis_file.unlink()
                logger.info(f"ğŸ—‘ï¸ åˆ†æç»“æœå·²åˆ é™¤: {analysis_id}")
                return True
            else:
                logger.warning(f"âš ï¸ åˆ†æç»“æœä¸å­˜åœ¨: {analysis_id}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤åˆ†æç»“æœå¤±è´¥: {analysis_id} - {e}")
            return False
    
    # ==================== ç”¨æˆ·ç”»åƒæ“ä½œ ====================
    
    def save_profile(self, profile_id: str, profile_data: Dict[str, Any]) -> bool:
        """ä¿å­˜ç”¨æˆ·ç”»åƒ"""
        try:
            profile_file = self.profile_dir / f"{profile_id}.json"
            
            # æ·»åŠ å…ƒæ•°æ®
            profile_data["saved_at"] = datetime.now().isoformat()
            
            with open(profile_file, 'w', encoding='utf-8') as f:
                json.dump(profile_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ’¾ ç”¨æˆ·ç”»åƒå·²ä¿å­˜: {profile_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç”¨æˆ·ç”»åƒå¤±è´¥: {profile_id} - {e}")
            return False
    
    def get_profile(self, profile_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ç”¨æˆ·ç”»åƒ"""
        try:
            profile_file = self.profile_dir / f"{profile_id}.json"
            
            if not profile_file.exists():
                return None
            
            with open(profile_file, 'r', encoding='utf-8') as f:
                profile_data = json.load(f)
            
            logger.debug(f"ğŸ‘¤ ç”¨æˆ·ç”»åƒè¯»å–æˆåŠŸ: {profile_id}")
            return profile_data
            
        except Exception as e:
            logger.error(f"âŒ è¯»å–ç”¨æˆ·ç”»åƒå¤±è´¥: {profile_id} - {e}")
            return None
    
    def get_resume_profile(self, resume_id: str) -> Optional[Dict[str, Any]]:
        """æ ¹æ®ç®€å†IDè·å–å…³è”çš„ç”¨æˆ·ç”»åƒ"""
        try:
            # æ–¹æ³•1ï¼šä»ç®€å†æ•°æ®ä¸­è·å–profile_id
            resume_data = self.get_resume(resume_id)
            if resume_data and resume_data.get("profile_id"):
                return self.get_profile(resume_data["profile_id"])
            
            # æ–¹æ³•2ï¼šæŸ¥æ‰¾ä»¥resume_idå¼€å¤´çš„ç”»åƒæ–‡ä»¶
            profile_files = list(self.profile_dir.glob(f"profile_{resume_id}_*.json"))
            
            if not profile_files:
                return None
            
            # è·å–æœ€æ–°çš„ç”»åƒæ–‡ä»¶
            profile_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            latest_profile_file = profile_files[0]
            
            with open(latest_profile_file, 'r', encoding='utf-8') as f:
                profile_data = json.load(f)
            
            logger.debug(f"ğŸ‘¤ ç®€å†ç”»åƒè¯»å–æˆåŠŸ: {resume_id}")
            return profile_data
            
        except Exception as e:
            logger.error(f"âŒ è¯»å–ç®€å†ç”»åƒå¤±è´¥: {resume_id} - {e}")
            return None
    
    # ==================== ç‰ˆæœ¬æ§åˆ¶æ–¹æ³• ====================
    
    def update_analysis_status(self, resume_id: str, status: str) -> bool:
        """æ›´æ–°ç®€å†çš„åˆ†æçŠ¶æ€"""
        try:
            resume_data = self.get_resume(resume_id)
            if not resume_data:
                return False
            
            resume_data["analysis_status"] = status
            resume_data["analysis_updated_at"] = datetime.now().isoformat()
            
            return self.save_resume(resume_id, resume_data)
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°åˆ†æçŠ¶æ€å¤±è´¥: {resume_id} - {e}")
            return False
    
    def get_resume_by_version(self, resume_id: str, version: str) -> Optional[Dict[str, Any]]:
        """æ ¹æ®ç‰ˆæœ¬è·å–ç®€å†ï¼ˆæš‚æ—¶è¿”å›æœ€æ–°ç‰ˆæœ¬ï¼Œæœªæ¥å¯æ‰©å±•ï¼‰"""
        return self.get_resume(resume_id)
    
    def mark_jd_analysis_stale(self, resume_id: str, old_version: str) -> bool:
        """å°†æ—§ç‰ˆæœ¬çš„JDåˆ†ææ ‡è®°ä¸ºè¿‡æ—¶"""
        try:
            analysis_files = list(self.analysis_dir.glob(f"jd_analysis_{resume_id}_*.json"))
            
            for analysis_file in analysis_files:
                with open(analysis_file, 'r', encoding='utf-8') as f:
                    analysis_data = json.load(f)
                
                # å¦‚æœæ˜¯æ—§ç‰ˆæœ¬çš„åˆ†æï¼Œæ ‡è®°ä¸ºè¿‡æ—¶
                if analysis_data.get("resume_version", "v1") == old_version:
                    analysis_data["status"] = "STALE"
                    analysis_data["stale_reason"] = f"ç®€å†å·²æ›´æ–°è‡³æ–°ç‰ˆæœ¬"
                    analysis_data["marked_stale_at"] = datetime.now().isoformat()
                    
                    with open(analysis_file, 'w', encoding='utf-8') as f:
                        json.dump(analysis_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… å·²æ ‡è®°æ—§ç‰ˆæœ¬JDåˆ†æä¸ºè¿‡æ—¶: {resume_id} v{old_version}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ ‡è®°JDåˆ†æè¿‡æ—¶å¤±è´¥: {resume_id} - {e}")
            return False
    
    # ==================== è¾…åŠ©æ–¹æ³• ====================
    
    def _has_analysis(self, resume_id: str) -> bool:
        """æ£€æŸ¥ç®€å†æ˜¯å¦æœ‰åˆ†æç»“æœ"""
        try:
            analysis_files = list(self.analysis_dir.glob(f"*{resume_id}*.json"))
            return len(analysis_files) > 0
        except:
            return False
    
    def _has_profile(self, resume_id: str) -> bool:
        """æ£€æŸ¥ç®€å†æ˜¯å¦æœ‰ç”¨æˆ·ç”»åƒ"""
        try:
            # æ£€æŸ¥ç®€å†æ–‡ä»¶ä¸­çš„profile_id
            resume_data = self.get_resume(resume_id)
            if resume_data and resume_data.get("profile_id"):
                profile_file = self.profile_dir / f"{resume_data['profile_id']}.json"
                return profile_file.exists()
            
            # æ£€æŸ¥ä»¥resume_idå¼€å¤´çš„ç”»åƒæ–‡ä»¶
            profile_files = list(self.profile_dir.glob(f"profile_{resume_id}_*.json"))
            return len(profile_files) > 0
        except:
            return False
    
    def _delete_related_analysis(self, resume_id: str):
        """åˆ é™¤ç®€å†ç›¸å…³çš„åˆ†ææ–‡ä»¶"""
        try:
            analysis_files = list(self.analysis_dir.glob(f"*{resume_id}*.json"))
            for analysis_file in analysis_files:
                analysis_file.unlink()
                logger.debug(f"ğŸ—‘ï¸ åˆ é™¤åˆ†ææ–‡ä»¶: {analysis_file.name}")
        except Exception as e:
            logger.warning(f"âš ï¸ åˆ é™¤ç›¸å…³åˆ†ææ–‡ä»¶å¤±è´¥: {e}")
    
    def _delete_related_profile(self, resume_id: str):
        """åˆ é™¤ç®€å†ç›¸å…³çš„ç”»åƒæ–‡ä»¶"""
        try:
            profile_files = list(self.profile_dir.glob(f"profile_{resume_id}_*.json"))
            for profile_file in profile_files:
                profile_file.unlink()
                logger.debug(f"ğŸ—‘ï¸ åˆ é™¤ç”»åƒæ–‡ä»¶: {profile_file.name}")
        except Exception as e:
            logger.warning(f"âš ï¸ åˆ é™¤ç›¸å…³ç”»åƒæ–‡ä»¶å¤±è´¥: {e}")
    
    def cleanup_temp_files(self, max_age_days: int = 7):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œè¿‡æœŸåˆ†æç»“æœ"""
        try:
            from datetime import timedelta
            cutoff_time = datetime.now() - timedelta(days=max_age_days)
            
            cleaned_count = 0
            
            # æ¸…ç†è¿‡æœŸçš„åˆ†ææ–‡ä»¶
            for analysis_file in self.analysis_dir.glob("*.json"):
                try:
                    file_time = datetime.fromtimestamp(analysis_file.stat().st_mtime)
                    if file_time < cutoff_time:
                        analysis_file.unlink()
                        cleaned_count += 1
                        logger.debug(f"ğŸ§¹ æ¸…ç†è¿‡æœŸåˆ†ææ–‡ä»¶: {analysis_file.name}")
                except Exception as e:
                    logger.warning(f"âš ï¸ æ¸…ç†æ–‡ä»¶å¤±è´¥: {analysis_file.name} - {e}")
            
            if cleaned_count > 0:
                logger.info(f"ğŸ§¹ æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {cleaned_count} ä¸ªè¿‡æœŸæ–‡ä»¶")
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
    
    def get_storage_stats(self) -> Dict[str, Any]:
        """è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯"""
        try:
            stats = {
                "resume_count": len(list(self.resume_dir.glob("*.json"))),
                "analysis_count": len(list(self.analysis_dir.glob("*.json"))),
                "profile_count": len(list(self.profile_dir.glob("*.json"))),
                "total_size_mb": 0
            }
            
            # è®¡ç®—æ€»å¤§å°
            total_size = 0
            for directory in [self.resume_dir, self.analysis_dir, self.profile_dir]:
                for file_path in directory.glob("*.json"):
                    total_size += file_path.stat().st_size
            
            stats["total_size_mb"] = round(total_size / (1024 * 1024), 2)
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ è·å–å­˜å‚¨ç»Ÿè®¡å¤±è´¥: {e}")
            return {"error": str(e)}


# åˆ›å»ºå…¨å±€DAOå®ä¾‹
_dao_instance = None

def get_resume_dao() -> ResumeDAO:
    """è·å–ç®€å†æ•°æ®è®¿é—®å¯¹è±¡å®ä¾‹"""
    global _dao_instance
    
    if _dao_instance is None:
        _dao_instance = ResumeDAO()
    
    return _dao_instance
