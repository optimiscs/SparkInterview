"""
é¢è¯•å®˜æ™ºèƒ½ä½“ - "æ¨¡æ‹Ÿå™¨" 
è´Ÿè´£ä¸»å¯¼é¢è¯•å¯¹è¯æµç¨‹ï¼Œè¿›è¡ŒåŠ¨æ€è¿½é—®
ä½¿ç”¨LangChainå°è£…å¥½çš„å‡½æ•°å®ç°æµå¼å¤„ç†å’Œå¯¹è¯ç®¡ç†
"""
import time
from typing import Dict, Any, List, Optional
from langchain.memory import ConversationBufferMemory
from langchain.schema import HumanMessage, AIMessage, SystemMessage
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser

from ..models.spark_client import create_spark_chat_model
from ..models.state import InterviewState, InterviewStage, ConversationTurn
from ..tools.media_recorder import create_media_recorder


class InterviewerAgent:
    """é¢è¯•å®˜æ™ºèƒ½ä½“"""
    
    def __init__(self):
        # ä½¿ç”¨Spark Ultraæ¨¡å‹ - æœ€ä½³å¯¹è¯ä½“éªŒï¼Œå“åº”æ›´å¿«
        self.llm = create_spark_chat_model("ultra")
        
        # è®°å¿†æ¨¡å—
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        
        # åˆ›å»ºæµå¼å›è°ƒå¤„ç†å™¨
        self.streaming_handler = StreamingStdOutCallbackHandler()
        
        # åˆ›å»ºæç¤ºæ¨¡æ¿
        self._create_prompt_templates()
        
        # åˆ›å»ºå¯¹è¯é“¾
        self._create_conversation_chains()
        
        # åª’ä½“å½•åˆ¶å™¨
        self.media_recorder = create_media_recorder()
        
        # é¢è¯•å®˜äººè®¾
        self.interviewer_persona = """
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ€æœ¯é¢è¯•å®˜ï¼Œæ‹¥æœ‰10å¹´ä»¥ä¸Šçš„æŠ€æœ¯æ‹›è˜ç»éªŒã€‚ä½ çš„ç‰¹ç‚¹ï¼š

ã€ä¸“ä¸šç´ å…»ã€‘
- æŠ€æœ¯åŠŸåº•æ·±åšï¼Œèƒ½å¤Ÿå‡†ç¡®è¯„ä¼°å€™é€‰äººçš„æŠ€æœ¯èƒ½åŠ›
- å–„äºé€šè¿‡è¡Œä¸ºé¢è¯•æ³•(STAR)æ·±å…¥äº†è§£å€™é€‰äººçš„å®é™…ç»éªŒ
- æ³¨é‡è€ƒå¯Ÿå€™é€‰äººçš„é€»è¾‘æ€ç»´å’Œè§£å†³é—®é¢˜çš„èƒ½åŠ›

ã€é¢è¯•é£æ ¼ã€‘
- æ€åº¦å‹å¥½ä½†ä¸“ä¸šï¼Œåˆ›é€ è½»æ¾çš„é¢è¯•æ°›å›´
- å–„äºæ ¹æ®å€™é€‰äººçš„å›ç­”è¿›è¡Œæ·±å…¥è¿½é—®
- ä¼šæ ¹æ®ç®€å†å†…å®¹æå‡ºé’ˆå¯¹æ€§é—®é¢˜
- æ³¨é‡å¼•å¯¼å€™é€‰äººå……åˆ†å±•ç¤ºè‡ªå·±çš„èƒ½åŠ›

ã€è¿½é—®ç­–ç•¥ã€‘
- å½“å€™é€‰äººæåˆ°é¡¹ç›®ç»éªŒæ—¶ï¼Œä¼šè¯¢é—®å…·ä½“çš„æŠ€æœ¯ç»†èŠ‚å’Œä¸ªäººè´¡çŒ®
- å¯¹äºæŠ€æœ¯æ¦‚å¿µï¼Œä¼šè¦æ±‚å€™é€‰äººä¸¾ä¾‹è¯´æ˜æˆ–æè¿°å®é™…åº”ç”¨
- å½“å›ç­”ä¸å¤Ÿæ·±å…¥æ—¶ï¼Œä¼šé€‚å½“å¼•å¯¼å€™é€‰äººæ›´è¯¦ç»†åœ°é˜è¿°
- ä¼šå…³æ³¨å€™é€‰äººåœ¨å›¢é˜Ÿåä½œä¸­çš„è§’è‰²å’Œæ²Ÿé€šèƒ½åŠ›

è¯·æŒ‰ç…§ä»¥ä¸Šè§’è‰²è®¾å®šè¿›è¡Œé¢è¯•ï¼Œç¡®ä¿æ¯ä¸ªé—®é¢˜éƒ½æœ‰æ˜ç¡®çš„è€ƒå¯Ÿç›®æ ‡ã€‚
"""
    
    def _create_prompt_templates(self):
        """åˆ›å»ºæç¤ºæ¨¡æ¿"""
        
        # é—®é¢˜ç”Ÿæˆæ¨¡æ¿
        self.question_prompt = PromptTemplate(
            input_variables=["persona", "context", "current_question"],
            template="""
{persona}

{context}

è¯·ä½œä¸ºé¢è¯•å®˜ï¼Œæå‡ºå½“å‰é—®é¢˜ã€‚ä½ å¯ä»¥ï¼š
1. ç›´æ¥æå‡ºé—®é¢˜
2. æ ¹æ®ä¹‹å‰çš„å¯¹è¯é€‚å½“è°ƒæ•´é—®é¢˜çš„è¡¨è¿°
3. åœ¨æé—®å‰ç®€çŸ­åœ°è¿‡æ¸¡ä¸€ä¸‹è¯é¢˜

å½“å‰é—®é¢˜: {current_question}

é¢è¯•å®˜è¯´:
"""
        )
        
        # è¿½é—®ç”Ÿæˆæ¨¡æ¿
        self.followup_prompt = PromptTemplate(
            input_variables=["persona", "context", "original_question", "answer"],
            template="""
{persona}

{context}

å€™é€‰äººåˆšåˆšå›ç­”äº†é—®é¢˜: "{original_question}"

å€™é€‰äººçš„å›ç­”: "{answer}"

è¯·åˆ†æè¿™ä¸ªå›ç­”ï¼Œå¦‚æœéœ€è¦è¿½é—®ä»¥è·å¾—æ›´å¤šç»†èŠ‚æˆ–æ¾„æ¸…ï¼Œè¯·ç”Ÿæˆä¸€ä¸ªåˆé€‚çš„è¿½é—®é—®é¢˜ã€‚
è¿½é—®åº”è¯¥ï¼š
1. é’ˆå¯¹å›ç­”ä¸­æåˆ°çš„å…·ä½“é¡¹ç›®æˆ–æŠ€æœ¯
2. è¦æ±‚å€™é€‰äººæä¾›æ›´å¤šæŠ€æœ¯ç»†èŠ‚
3. äº†è§£å€™é€‰äººåœ¨é¡¹ç›®ä¸­çš„å…·ä½“è§’è‰²å’Œè´¡çŒ®
4. æ¢ç´¢å€™é€‰äººçš„æ€è€ƒè¿‡ç¨‹

å¦‚æœå›ç­”å·²ç»è¶³å¤Ÿè¯¦ç»†å’Œå®Œæ•´ï¼Œè¯·å›å¤"æ— éœ€è¿½é—®"ã€‚

è¿½é—®é—®é¢˜:
"""
        )
    
    def _create_conversation_chains(self):
        """åˆ›å»ºå¯¹è¯é“¾"""
        
        # é—®é¢˜ç”Ÿæˆé“¾
        self.question_chain = (
            {"persona": lambda x: self.interviewer_persona, 
             "context": RunnablePassthrough(), 
             "current_question": RunnablePassthrough()}
            | self.question_prompt
            | self.llm
            | StrOutputParser()
        )
        
        # è¿½é—®ç”Ÿæˆé“¾
        self.followup_chain = (
            {"persona": lambda x: self.interviewer_persona,
             "context": RunnablePassthrough(),
             "original_question": RunnablePassthrough(),
             "answer": RunnablePassthrough()}
            | self.followup_prompt
            | self.llm
            | StrOutputParser()
        )
    
    def _build_interview_context(self, state: InterviewState) -> str:
        """æ„å»ºé¢è¯•ä¸Šä¸‹æ–‡"""
        
        user_info = state["user_info"]
        questions = state["questions"]
        current_index = state["current_question_index"]
        
        # ç®€å†æ‘˜è¦
        resume_summary = user_info.resume_summary.get("summary", "æ— ç®€å†ä¿¡æ¯")
        
        # å½“å‰é—®é¢˜
        current_question = None
        if current_index < len(questions):
            current_question = questions[current_index]
        
        # å¯¹è¯å†å²
        conversation_history = state["conversation_history"]
        
        context = f"""
ã€é¢è¯•ä¿¡æ¯ã€‘
- å€™é€‰äººå§“å: {user_info.name}
- åº”è˜å²—ä½: {user_info.target_position}
- æŠ€æœ¯é¢†åŸŸ: {user_info.target_field}

ã€ç®€å†æ‘˜è¦ã€‘
{resume_summary}

ã€å½“å‰é—®é¢˜ã€‘
"""
        
        if current_question:
            context += f"é—®é¢˜ {current_index + 1}: {current_question.text}\n"
            context += f"é—®é¢˜ç±»å‹: {current_question.type.value}\n"
            context += f"è€ƒå¯Ÿé‡ç‚¹: {', '.join(current_question.expected_keywords)}\n"
        else:
            context += "æ‰€æœ‰é¢„è®¾é—®é¢˜å·²å®Œæˆï¼Œå¯ä»¥è¿›è¡Œæ€»ç»“æˆ–é¢å¤–æé—®ã€‚\n"
        
        # æ·»åŠ å¯¹è¯å†å²
        if conversation_history:
            context += "\nã€å¯¹è¯å†å²ã€‘\n"
            for i, turn in enumerate(conversation_history[-3:]):  # åªæ˜¾ç¤ºæœ€è¿‘3è½®
                context += f"Q{i+1}: {turn.question}\n"
                context += f"A{i+1}: {turn.answer[:200]}...\n\n"
        
        return context
    
    def _should_ask_follow_up(self, answer: str, question_keywords: List[str]) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦è¿½é—®"""
        
        # æ£€æŸ¥å›ç­”é•¿åº¦
        if len(answer.strip()) < 50:
            return True
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®è¯
        answer_lower = answer.lower()
        keyword_matches = sum(1 for keyword in question_keywords 
                            if keyword.lower() in answer_lower)
        
        # å¦‚æœå…³é”®è¯åŒ¹é…åº¦ä½ï¼Œéœ€è¦è¿½é—®
        if len(question_keywords) > 0 and keyword_matches / len(question_keywords) < 0.3:
            return True
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…·ä½“ç»†èŠ‚
        detail_indicators = ["å…·ä½“", "æ¯”å¦‚", "ä¾‹å¦‚", "å®ç°", "ä½¿ç”¨", "é‡‡ç”¨", "è´Ÿè´£"]
        if not any(indicator in answer for indicator in detail_indicators):
            return True
        
        return False
    
    def _generate_follow_up_question(
        self, 
        original_question: str, 
        answer: str, 
        context: str
    ) -> Optional[str]:
        """ç”Ÿæˆè¿½é—®é—®é¢˜ - ä½¿ç”¨LangChainæµå¼å¤„ç†"""
        
        try:
            # ä½¿ç”¨LangChainçš„è¿½é—®é“¾
            response = self.followup_chain.invoke({
                "context": context,
                "original_question": original_question,
                "answer": answer
            })
            
            if "æ— éœ€è¿½é—®" in response or "ä¸éœ€è¦è¿½é—®" in response:
                return None
            
            return response.strip()
            
        except Exception as e:
            print(f"ç”Ÿæˆè¿½é—®é—®é¢˜å¤±è´¥: {str(e)}")
            return None
    
    def ask_question(self, state: InterviewState) -> Dict[str, Any]:
        """æå‡ºé—®é¢˜ - ä½¿ç”¨LangChainæµå¼å¤„ç†"""
        
        try:
            questions = state["questions"]
            current_index = state["current_question_index"]
            
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰é—®é¢˜
            if current_index >= len(questions):
                return {
                    "question": "æ„Ÿè°¢æ‚¨çš„æ—¶é—´ï¼Œé¢è¯•é—®é¢˜å·²ç»å…¨éƒ¨å®Œæˆã€‚è¯·é—®æ‚¨è¿˜æœ‰ä»€ä¹ˆæƒ³äº†è§£çš„å—ï¼Ÿ",
                    "question_id": "final",
                    "is_final": True
                }
            
            # è·å–å½“å‰é—®é¢˜
            current_question = questions[current_index]
            
            # æ„å»ºä¸Šä¸‹æ–‡
            context = self._build_interview_context(state)
            
            # ä½¿ç”¨LangChainçš„é—®é¢˜ç”Ÿæˆé“¾
            response = self.question_chain.invoke({
                "context": context,
                "current_question": current_question.text
            })
            
            return {
                "question": response.strip(),
                "question_id": current_question.id,
                "question_type": current_question.type.value,
                "expected_keywords": current_question.expected_keywords,
                "is_final": False
            }
            
        except Exception as e:
            error_msg = f"ç”Ÿæˆé—®é¢˜å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            
            # è¿”å›å¤‡ç”¨é—®é¢˜
            return {
                "question": "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹æ‚¨çš„æŠ€æœ¯èƒŒæ™¯å’Œé¡¹ç›®ç»éªŒã€‚",
                "question_id": "backup",
                "question_type": "behavioral",
                "expected_keywords": [],
                "is_final": False
            }
    
    def process_answer(
        self, 
        state: InterviewState, 
        question_data: Dict[str, Any], 
        answer: str
    ) -> Dict[str, Any]:
        """å¤„ç†å€™é€‰äººçš„å›ç­”"""
        
        try:
            # è®°å½•å¯¹è¯
            conversation_turn = ConversationTurn(
                question_id=question_data["question_id"],
                question=question_data["question"],
                answer=answer,
                timestamp=time.time()
            )
            
            state["conversation_history"].append(conversation_turn)
            
            # åˆ¤æ–­æ˜¯å¦éœ€è¦è¿½é—®
            should_follow_up = self._should_ask_follow_up(
                answer, 
                question_data.get("expected_keywords", [])
            )
            
            follow_up_question = None
            if should_follow_up and not question_data.get("is_final", False):
                context = self._build_interview_context(state)
                follow_up_question = self._generate_follow_up_question(
                    question_data["question"],
                    answer,
                    context
                )
            
            result = {
                "answer_recorded": True,
                "follow_up_question": follow_up_question,
                "should_continue": True
            }
            
            # å¦‚æœæ²¡æœ‰è¿½é—®ï¼Œç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªé—®é¢˜
            if not follow_up_question:
                state["current_question_index"] += 1
                
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰é—®é¢˜å·²å®Œæˆ
                if state["current_question_index"] >= len(state["questions"]):
                    result["should_continue"] = False
                    result["interview_completed"] = True
            
            return result
            
        except Exception as e:
            error_msg = f"å¤„ç†å›ç­”å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            state["errors"].append(error_msg)
            
            return {
                "answer_recorded": False,
                "follow_up_question": None,
                "should_continue": False,
                "error": error_msg
            }
    
    def conduct_interview(self, state: InterviewState) -> InterviewState:
        """æ‰§è¡Œå®Œæ•´çš„é¢è¯•æµç¨‹ - ä½¿ç”¨LangChainæµå¼å¤„ç†"""
        
        print("ğŸ¤ å¼€å§‹æ¨¡æ‹Ÿé¢è¯•...")
        print("=" * 50)
        
        # å¼€å§‹å½•åˆ¶éŸ³è§†é¢‘
        try:
            session_id = state.get("session_id", "unknown")
            video_path, audio_path = self.media_recorder.start_recording(session_id)
            state["video_path"] = video_path
            state["audio_path"] = audio_path
            print("ğŸ¥ éŸ³è§†é¢‘å½•åˆ¶å·²å¯åŠ¨")
        except Exception as e:
            print(f"âš ï¸ éŸ³è§†é¢‘å½•åˆ¶å¯åŠ¨å¤±è´¥: {e}")
            state["video_path"] = None
            state["audio_path"] = None
        
        try:
            while True:
                # 1. æå‡ºé—®é¢˜
                question_data = self.ask_question(state)
                
                # ä½¿ç”¨LangChainæµå¼è¾“å‡ºé¢è¯•å®˜é—®é¢˜
                print(f"\nğŸ¤µ é¢è¯•å®˜: ", end="", flush=True)
                self._stream_question(question_data['question'])
                print()
                
                # 2. ç­‰å¾…ç”¨æˆ·è¾“å…¥å›ç­”
                answer = input("\nğŸ‘¤ æ‚¨çš„å›ç­”: ").strip()
                
                if not answer:
                    print("è¯·æä¾›æ‚¨çš„å›ç­”ã€‚")
                    continue
                
                # æ£€æŸ¥æ˜¯å¦è¦ç»ˆæ­¢é¢è¯•
                if answer.lower() in ["ç»ˆæ­¢é¢è¯•", "ç»“æŸé¢è¯•", "åœæ­¢é¢è¯•", "quit", "exit", "stop"]:
                    print("\nâ¹ï¸ ç”¨æˆ·ä¸»åŠ¨ç»ˆæ­¢é¢è¯•")
                    state["stage"] = InterviewStage.ANALYSIS
                    state["errors"].append("ç”¨æˆ·ä¸»åŠ¨ç»ˆæ­¢é¢è¯•")
                    return state
                
                # 3. å¤„ç†å›ç­”
                result = self.process_answer(state, question_data, answer)
                
                if not result["answer_recorded"]:
                    print(f"âŒ {result.get('error', 'å¤„ç†å›ç­”æ—¶å‡ºé”™')}")
                    continue
                
                # 4. æ£€æŸ¥æ˜¯å¦æœ‰è¿½é—®
                if result.get("follow_up_question"):
                    # ä½¿ç”¨LangChainæµå¼è¾“å‡ºè¿½é—®é—®é¢˜
                    print(f"\nğŸ¤µ é¢è¯•å®˜: ", end="", flush=True)
                    self._stream_question(result['follow_up_question'])
                    print()
                    
                    # ç­‰å¾…è¿½é—®å›ç­”
                    follow_up_answer = input("\nğŸ‘¤ æ‚¨çš„å›ç­”: ").strip()
                    
                    # æ£€æŸ¥æ˜¯å¦è¦ç»ˆæ­¢é¢è¯•
                    if follow_up_answer.lower() in ["ç»ˆæ­¢é¢è¯•", "ç»“æŸé¢è¯•", "åœæ­¢é¢è¯•", "quit", "exit", "stop"]:
                        print("\nâ¹ï¸ ç”¨æˆ·ä¸»åŠ¨ç»ˆæ­¢é¢è¯•")
                        state["stage"] = InterviewStage.ANALYSIS
                        state["errors"].append("ç”¨æˆ·ä¸»åŠ¨ç»ˆæ­¢é¢è¯•")
                        return state
                    
                    if follow_up_answer:
                        # è®°å½•è¿½é—®å¯¹è¯
                        follow_up_turn = ConversationTurn(
                            question_id=f"{question_data['question_id']}_followup",
                            question=result['follow_up_question'],
                            answer=follow_up_answer,
                            timestamp=time.time()
                        )
                        state["conversation_history"].append(follow_up_turn)
                        
                        # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªé—®é¢˜
                        state["current_question_index"] += 1
                
                # 5. æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if not result.get("should_continue", True):
                    break
                
                # 6. æ£€æŸ¥æ˜¯å¦æ‰€æœ‰é—®é¢˜å®Œæˆ
                if state["current_question_index"] >= len(state["questions"]):
                    break
            
            # é¢è¯•å®Œæˆ
            state["stage"] = InterviewStage.ANALYSIS
            print("\nâœ… é¢è¯•å®Œæˆï¼æ­£åœ¨è¿›è¡Œåˆ†æ...")
            
            # åœæ­¢å½•åˆ¶
            self.media_recorder.stop_recording()
            
            return state
            
        except KeyboardInterrupt:
            print("\n\nâ¹ï¸ é¢è¯•è¢«ä¸­æ–­")
            state["errors"].append("é¢è¯•è¢«ç”¨æˆ·ä¸­æ–­")
            # åœæ­¢å½•åˆ¶
            self.media_recorder.stop_recording()
            return state
        
        except Exception as e:
            error_msg = f"é¢è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"
            print(f"âŒ {error_msg}")
            state["errors"].append(error_msg)
            # åœæ­¢å½•åˆ¶
            self.media_recorder.stop_recording()
            return state
    
    def _stream_question(self, question: str):
        """ä½¿ç”¨LangChainæµå¼è¾“å‡ºé—®é¢˜"""
        try:
            # åˆ›å»ºå¸¦æµå¼å›è°ƒçš„LLM
            streaming_llm = self.llm.bind(callbacks=[self.streaming_handler])
            
            # ç›´æ¥è¾“å‡ºé—®é¢˜ï¼ˆæ¨¡æ‹Ÿæµå¼æ•ˆæœï¼‰
            for char in question:
                print(char, end="", flush=True)
                time.sleep(0.02)  # ç¨å¾®å¿«ä¸€ç‚¹çš„æ‰“å­—æ•ˆæœ
                
        except Exception as e:
            # å¦‚æœæµå¼è¾“å‡ºå¤±è´¥ï¼Œå›é€€åˆ°æ™®é€šè¾“å‡º
            print(question, end="", flush=True)


def create_interviewer_agent() -> InterviewerAgent:
    """åˆ›å»ºé¢è¯•å®˜æ™ºèƒ½ä½“å®ä¾‹"""
    return InterviewerAgent() 