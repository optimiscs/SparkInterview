"""
åŸºäºLangGraphçš„æ™ºèƒ½é¢è¯•å®˜ - ä½¿ç”¨æœ€æ–°LangGraph API
å……åˆ†åˆ©ç”¨LangGraphåº“å°è£…å¥½çš„åŠŸèƒ½ï¼Œç¡®ä¿æ¥å£çœŸå®æœ‰æ•ˆ
"""
import asyncio
import json
import logging
import re
import sqlite3
from datetime import datetime
from typing import Dict, Any, List, Optional, TypedDict, Annotated
from operator import add
from pathlib import Path

# LangChain/LangGraph imports
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage
from langchain_core.tools import tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# LangGraphå¯¼å…¥ - ä½¿ç”¨æœ€æ–°API
try:
    from langgraph.graph import StateGraph, END, START
    from langgraph.graph.message import add_messages
    from langgraph.prebuilt import ToolNode, tools_condition
    
    # æ£€æŸ¥ç‚¹ä¿å­˜å™¨ - æ¡ä»¶å¯¼å…¥
    SqliteSaver = None
    try:
        from langgraph.checkpoint.sqlite import SqliteSaver
    except ImportError:
        pass  # SQLiteæ£€æŸ¥ç‚¹ä¿å­˜å™¨ä¸å¯ç”¨
    
    LANGGRAPH_AVAILABLE = True
    print("âœ… LangGraphå¯¼å…¥æˆåŠŸ")
    
except ImportError as e:
    print(f"âŒ LangGraphå¯¼å…¥å¤±è´¥: {e}")
    print("è¯·å®‰è£…æ­£ç¡®ç‰ˆæœ¬çš„LangGraph: pip install langgraph>=0.2.0")
    LANGGRAPH_AVAILABLE = False
    
    # é™çº§å®ç°
    class StateGraph:
        def __init__(self, state_type):
            self.state_type = state_type
        def add_node(self, name, func): pass
        def add_edge(self, start, end): pass
        def add_conditional_edges(self, start, condition, mapping): pass
        def add_entrypoint(self, node): pass
        def compile(self, **kwargs):
            return SimpleWorkflow()
    
    class SimpleWorkflow:
        async def ainvoke(self, state, config=None):
            return {"success": False, "error": "LangGraph not available"}
    
    class ToolNode:
        def __init__(self, tools): pass
        async def ainvoke(self, state): return state
    
    def tools_condition(state): return END
    
    END = "END"
    START = "START"

# ç°æœ‰æ¨¡å‹å’Œå·¥å…·
from src.models.spark_client import create_spark_model
from src.tools.mcp_database_tool import MCPIntegrationTool
from src.tools.redis_cache_manager import get_cache_manager, set_interview_stage, get_interview_stage, clear_session_cache
from src.tools.chat_message_history_manager import (
    get_message_history_manager, 
    get_session_history, 
    add_user_message, 
    add_ai_message, 
    get_conversation_context,
    clear_session_messages
)
from src.tools.langchain_mcp_tools import (
    EmotionAnalysisTool,
    StructuredInfoExtractionTool,
    DatabaseUpdateTool,
    QuestionGenerationTool,
    EmotionalSupportTool,
    UserProfileQueryTool
)

# ç®€å†ç›¸å…³å¯¼å…¥
import httpx
import aiohttp
from typing import Optional, List

logger = logging.getLogger(__name__)


class InterviewState(TypedDict):
    """é¢è¯•çŠ¶æ€å®šä¹‰"""
    # æ¶ˆæ¯å†å²
    messages: Annotated[List, add_messages]
    
    # ç”¨æˆ·ä¿¡æ¯
    user_id: str
    session_id: str
    user_name: str
    target_position: str
    
    # ç”¨æˆ·ç”»åƒ
    user_profile: Dict[str, Any]
    missing_info: List[str]
    completeness_score: float
    user_emotion: str
    
    # å†³ç­–ä¿¡æ¯
    current_decision: Dict[str, Any]
    should_continue: bool
    
    # æå–çš„ä¿¡æ¯
    extracted_info: Dict[str, Any]
    
    # é¢è¯•è¿›åº¦
    interview_stage: str
    question_count: int
    
    # é¢è¯•é˜¶æ®µæ§åˆ¶ - ç”¨äºæ§åˆ¶æ˜¯å¦è¿˜èƒ½è¿›å…¥ä¿¡æ¯æ”¶é›†é˜¶æ®µ
    formal_interview_started: bool


# ==================== LangChainå·¥å…·å®šä¹‰ - ä½¿ç”¨LangGraphæœ€ä½³å®è·µ ====================

@tool("analyze_user_emotion")
async def analyze_user_emotion(message: str) -> str:
    """åˆ†æç”¨æˆ·æƒ…ç»ªçŠ¶æ€
    
    Args:
        message: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯å†…å®¹
        
    Returns:
        str: æƒ…ç»ªçŠ¶æ€ (neutral, anxious, confident, confused)
    """
    if not message:
        return "neutral"
        
    message_lower = message.lower()
    
    # åŸºäºå…³é”®è¯çš„ç®€å•æƒ…æ„Ÿåˆ†æ
    anxiety_keywords = ["ç´§å¼ ", "æ‹…å¿ƒ", "å®³æ€•", "ç„¦è™‘", "ä¸å®‰", "å‹åŠ›"]
    confidence_keywords = ["å…´å¥‹", "æœŸå¾…", "è‡ªä¿¡", "é«˜å…´", "å‡†å¤‡å¥½", "æ²¡é—®é¢˜"]
    confusion_keywords = ["å›°æƒ‘", "ä¸æ‡‚", "ä¸æ¸…æ¥š", "ä¸æ˜ç™½", "ä¸å¤ªç†è§£"]
    
    if any(word in message_lower for word in anxiety_keywords):
        return "anxious"
    elif any(word in message_lower for word in confidence_keywords):
        return "confident"
    elif any(word in message_lower for word in confusion_keywords):
        return "confused"
    else:
        return "neutral"


@tool("extract_structured_info")
async def extract_structured_info(message: str, missing_fields: List[str]) -> Dict[str, Any]:
    """ä»ç”¨æˆ·æ¶ˆæ¯ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯
    
    Args:
        message: ç”¨æˆ·è¾“å…¥æ¶ˆæ¯
        missing_fields: ç¼ºå¤±çš„å­—æ®µåˆ—è¡¨
        
    Returns:
        Dict: æå–åˆ°çš„ç»“æ„åŒ–ä¿¡æ¯
    """
    extracted = {}
    if not message or not missing_fields:
        return extracted
        
    message_lower = message.lower()
    
    # æå–å·¥ä½œå¹´é™
    if "work_years" in missing_fields:
        import re
        year_patterns = [
            r'(\d+)\s*å¹´.*?ç»éªŒ',
            r'å·¥ä½œ.*?(\d+)\s*å¹´', 
            r'(\d+)\s*å¹´.*?å·¥ä½œ',
            r'æœ‰.*?(\d+)\s*å¹´.*?ç»éªŒ',
            r'(\d+)\s*å¹´å·¥ä½œ'
        ]
        for pattern in year_patterns:
            match = re.search(pattern, message_lower)
            if match:
                years = int(match.group(1))
                if 0 <= years <= 50:  # åˆç†èŒƒå›´æ£€æŸ¥
                    extracted["work_years"] = years
                break
    
    # æå–æ•™è‚²æ°´å¹³
    if "education_level" in missing_fields:
        education_map = {
            "åšå£«": "åšå£«",
            "phd": "åšå£«", 
            "ç¡•å£«": "ç¡•å£«",
            "ç ”ç©¶ç”Ÿ": "ç¡•å£«",
            "master": "ç¡•å£«",
            "æœ¬ç§‘": "æœ¬ç§‘",
            "å¤§å­¦": "æœ¬ç§‘",
            "bachelor": "æœ¬ç§‘"
        }
        for keyword, level in education_map.items():
            if keyword in message_lower:
                extracted["education_level"] = level
                break
    
    # æå–å…¬å¸ä¿¡æ¯
    if "current_company" in missing_fields:
        # æ›´ç²¾ç¡®çš„å…¬å¸åæå–
        company_patterns = [
            r'åœ¨([^ï¼Œã€‚ï¼ï¼Ÿ\s]{2,20}(?:å…¬å¸|ä¼ä¸š|é›†å›¢|ç§‘æŠ€|æœ‰é™))',
            r'([^ï¼Œã€‚ï¼ï¼Ÿ\s]{2,20}(?:å…¬å¸|ä¼ä¸š|é›†å›¢|ç§‘æŠ€|æœ‰é™))',
            r'å·¥ä½œ.*?([^ï¼Œã€‚ï¼ï¼Ÿ\s]{2,20}(?:å…¬å¸|ä¼ä¸š|é›†å›¢))'
        ]
        import re
        for pattern in company_patterns:
            match = re.search(pattern, message)
            if match:
                extracted["current_company"] = match.group(1)
                break
    
    # æå–æ¯•ä¸šå¹´ä»½
    if "graduation_year" in missing_fields:
        import re
        year_pattern = r'(20\d{2}|19\d{2})å¹´?.*?æ¯•ä¸š|æ¯•ä¸š.*?(20\d{2}|19\d{2})'
        match = re.search(year_pattern, message)
        if match:
            year = int(match.group(1) or match.group(2))
            if 1980 <= year <= datetime.now().year:
                extracted["graduation_year"] = year
    
    return extracted


@tool("update_user_database")
async def update_user_database(user_id: str, session_id: str, extracted_info: Dict[str, Any]) -> Dict[str, Any]:
    """æ›´æ–°ç”¨æˆ·æ•°æ®åº“ä¿¡æ¯
    
    Args:
        user_id: ç”¨æˆ·ID
        session_id: ä¼šè¯ID
        extracted_info: æå–çš„ä¿¡æ¯å­—å…¸
        
    Returns:
        Dict: æ›´æ–°ç»“æœ
    """
    try:
        if not extracted_info:
            return {"success": True, "updated_fields": [], "new_completeness": 0}
            
        mcp_tool = MCPIntegrationTool()
        result = await mcp_tool.intelligent_info_collection(
            user_id=user_id,
            session_id=session_id,
            conversation_history=[json.dumps(extracted_info)]
        )
        
        return {
            "success": True,
            "updated_fields": list(extracted_info.keys()),
            "new_completeness": result.get("current_completeness", 0),
            "message": f"æˆåŠŸæ›´æ–° {len(extracted_info)} ä¸ªå­—æ®µ"
        }
    except Exception as e:
        logger.error(f"æ•°æ®åº“æ›´æ–°å¤±è´¥: {e}")
        return {
            "success": False, 
            "error": str(e),
            "updated_fields": [],
            "new_completeness": 0
        }


@tool("generate_missing_info_question")
async def generate_missing_info_question(missing_info: List[str], user_name: str, target_position: str) -> str:
    """ç”Ÿæˆè¯¢é—®ç¼ºå¤±ä¿¡æ¯çš„é—®é¢˜
    
    Args:
        missing_info: ç¼ºå¤±ä¿¡æ¯åˆ—è¡¨
        user_name: ç”¨æˆ·å§“å
        target_position: ç›®æ ‡èŒä½
        
    Returns:
        str: ç”Ÿæˆçš„é—®é¢˜
    """
    if not missing_info:
        return f"å¾ˆå¥½ï¼{user_name}ï¼Œæ‚¨çš„ä¿¡æ¯å¾ˆå®Œæ•´ï¼Œè®©æˆ‘ä»¬å¼€å§‹æ­£å¼çš„é¢è¯•ç¯èŠ‚å§ï¼"
    
    # ä¿¡æ¯ä¼˜å…ˆçº§æ˜ å°„
    priority_map = {
        "work_years": 1,
        "education_level": 2, 
        "current_company": 3,
        "graduation_year": 4,
        "expected_salary": 5
    }
    
    # æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œé€‰æ‹©æœ€é‡è¦çš„ç¼ºå¤±ä¿¡æ¯
    sorted_missing = sorted(missing_info, key=lambda x: priority_map.get(x, 6))
    top_missing = sorted_missing[0]
    
    # ä¸ªæ€§åŒ–é—®é¢˜æ¨¡æ¿
    questions = {
        "work_years": f"åœ¨å¼€å§‹é¢è¯•ä¹‹å‰ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹æ‚¨çš„å·¥ä½œèƒŒæ™¯ã€‚{user_name}ï¼Œè¯·é—®æ‚¨æœ‰å¤šå°‘å¹´çš„{target_position}ç›¸å…³å·¥ä½œç»éªŒå‘¢ï¼Ÿ",
        "education_level": f"{user_name}ï¼Œä¸ºäº†æ›´å¥½åœ°äº†è§£æ‚¨çš„èƒŒæ™¯ï¼Œè¯·é—®æ‚¨çš„æœ€é«˜å­¦å†æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿæ˜¯æœ¬ç§‘ã€ç¡•å£«è¿˜æ˜¯åšå£«ï¼Ÿ",
        "current_company": f"è¯·é—®{user_name}ï¼Œæ‚¨ç›®å‰åœ¨å“ªå®¶å…¬å¸å·¥ä½œï¼Ÿå¦‚æœæ‚¨æ˜¯åº”å±Šæ¯•ä¸šç”Ÿï¼Œå¯ä»¥å‘Šè¯‰æˆ‘æ‚¨æœ€è¿‘çš„å®ä¹ ç»å†ã€‚",
        "graduation_year": f"{user_name}ï¼Œè¯·é—®æ‚¨æ˜¯å“ªä¸€å¹´æ¯•ä¸šçš„ï¼Ÿè¿™æœ‰åŠ©äºæˆ‘äº†è§£æ‚¨çš„èŒä¸šå‘å±•é˜¶æ®µã€‚",
        "expected_salary": f"å…³äºè–ªèµ„æœŸæœ›ï¼Œ{user_name}ï¼Œæ‚¨å¯¹{target_position}è¿™ä¸ªèŒä½æœ‰ä»€ä¹ˆæ ·çš„è–ªèµ„æœŸå¾…å‘¢ï¼Ÿ"
    }
    
    return questions.get(top_missing, f"{user_name}ï¼Œè¯·å‘Šè¯‰æˆ‘æ›´å¤šå…³äºæ‚¨çš„èƒŒæ™¯ä¿¡æ¯ï¼Œè¿™æ ·æˆ‘èƒ½ä¸ºæ‚¨æä¾›æ›´å¥½çš„é¢è¯•ä½“éªŒã€‚")


@tool("provide_emotional_support")
async def provide_emotional_support(user_emotion: str, user_name: str) -> str:
    """æ ¹æ®ç”¨æˆ·æƒ…ç»ªæä¾›ç›¸åº”çš„æƒ…æ„Ÿæ”¯æŒ
    
    Args:
        user_emotion: ç”¨æˆ·æƒ…ç»ªçŠ¶æ€
        user_name: ç”¨æˆ·å§“å
        
    Returns:
        str: æƒ…æ„Ÿæ”¯æŒå›åº”
    """
    support_responses = {
        "anxious": f"{user_name}ï¼Œæˆ‘èƒ½æ„Ÿè§‰åˆ°æ‚¨å¯èƒ½æœ‰ä¸€äº›ç´§å¼ ï¼Œè¿™æ˜¯å®Œå…¨æ­£å¸¸çš„ï¼é¢è¯•æœ¬èº«å°±æ˜¯ä¸€ä¸ªç›¸äº’äº†è§£çš„è¿‡ç¨‹ï¼Œä¸æ˜¯è€ƒè¯•ã€‚è®©æˆ‘ä»¬æ”¾æ¾å¿ƒæƒ…ï¼Œæ…¢æ…¢æ¥ï¼Œæˆ‘ä¼šè¥é€ ä¸€ä¸ªè½»æ¾å‹å¥½çš„æ°›å›´ã€‚",
        "confused": f"{user_name}ï¼Œå¦‚æœæœ‰ä»»ä½•ä¸æ¸…æ¥šçš„åœ°æ–¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚æˆ‘å¾ˆä¹æ„ä¸ºæ‚¨è§£é‡Šæˆ–è€…æ¢ä¸€ç§æ–¹å¼æ¥è®¨è®ºã€‚æ²Ÿé€šæ˜¯åŒå‘çš„ï¼Œæ‚¨çš„ç–‘é—®èƒ½å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°äº¤æµã€‚",
        "confident": f"å¾ˆæ£’ï¼Œ{user_name}ï¼æˆ‘èƒ½æ„Ÿå—åˆ°æ‚¨çš„è‡ªä¿¡å’Œç§¯ææ€åº¦ï¼Œè¿™å¾ˆæ£’ï¼ä¿æŒè¿™ç§çŠ¶æ€ï¼Œè®©æˆ‘ä»¬ç»§ç»­æˆ‘ä»¬çš„é¢è¯•å¯¹è¯ã€‚",
        "neutral": f"å¥½çš„ï¼Œ{user_name}ï¼Œè®©æˆ‘ä»¬ç»§ç»­æˆ‘ä»¬çš„é¢è¯•å¯¹è¯å§ã€‚"
    }
    
    return support_responses.get(user_emotion, f"å¾ˆå¥½ï¼Œ{user_name}ï¼Œè®©æˆ‘ä»¬ç»§ç»­æˆ‘ä»¬çš„é¢è¯•ã€‚")


# ==================== çœŸå®LangChainå·¥å…·é›†æˆ ====================

# åˆ›å»ºçœŸå®çš„LangChainå·¥å…·å®ä¾‹
def create_real_tools():
    """åˆ›å»ºçœŸå®çš„LangChain MCPå·¥å…·å®ä¾‹"""
    try:
        return [
            EmotionAnalysisTool(),
            StructuredInfoExtractionTool(),
            DatabaseUpdateTool(),
            QuestionGenerationTool(),
            EmotionalSupportTool(),
            UserProfileQueryTool()
        ]
    except Exception as e:
        logger.warning(f"çœŸå®å·¥å…·åˆ›å»ºå¤±è´¥: {e}ï¼Œä½¿ç”¨ç®€åŒ–å·¥å…·")
        # å¦‚æœçœŸå®å·¥å…·åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–çš„@toolè£…é¥°å™¨ç‰ˆæœ¬
        return [
            analyze_user_emotion,
            extract_structured_info, 
            update_user_database,
            generate_missing_info_question,
            provide_emotional_support
        ]

# åˆ›å»ºå·¥å…·åˆ—è¡¨
interview_tools = create_real_tools()

# ä½¿ç”¨LangGraphå†…ç½®çš„ToolNode
tool_node = ToolNode(interview_tools) if LANGGRAPH_AVAILABLE else None


class LangGraphInterviewAgent:
    """åŸºäºLangGraphçš„æ™ºèƒ½é¢è¯•å®˜ - ä½¿ç”¨æœ€æ–°APIå’Œæœ€ä½³å®è·µ"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ™ºèƒ½ä½“ï¼Œç¡®ä¿æ­£ç¡®é…ç½®LangGraphç»„ä»¶"""
        try:
            # ä½¿ç”¨Redisç¼“å­˜ç®¡ç†å™¨ - æ›´ä¸“ä¸šçš„ç¼“å­˜è§£å†³æ–¹æ¡ˆ
            self.cache_manager = get_cache_manager()
            # ä½¿ç”¨LangChainæ¶ˆæ¯å†å²ç®¡ç†å™¨ - æŒä¹…åŒ–å¯¹è¯å†å²
            self.message_history_manager = get_message_history_manager()
            # ä½¿ç”¨çœŸå®çš„æ˜Ÿç«ChatModelï¼Œé€‚åˆé¢è¯•å¯¹è¯åœºæ™¯
            self.model = create_spark_model(model_type="chat", temperature=0.7)
            self.mcp_tool = MCPIntegrationTool()
            
            logger.info("âœ… çœŸå®æ˜Ÿç«ChatModelåˆå§‹åŒ–æˆåŠŸ")
            logger.info(f"âœ… Redisç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–: {self.cache_manager.health_check()}")
            logger.info("âœ… LangChainæ¶ˆæ¯å†å²ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
            checkpoint_dir = Path("data/sqlite")
            checkpoint_dir.mkdir(parents=True, exist_ok=True)
            
            # ä½¿ç”¨æ­£ç¡®çš„æ£€æŸ¥ç‚¹ä¿å­˜å™¨ - ä¼˜å…ˆä½¿ç”¨å†…å­˜ï¼Œé¿å…SQLiteç‰ˆæœ¬é—®é¢˜
            if LANGGRAPH_AVAILABLE:
                try:
                    # å°è¯•ä½¿ç”¨MemorySaver - æœ€ç¨³å®šçš„æ–¹å¼
                    from langgraph.checkpoint.memory import MemorySaver
                    self.checkpointer = MemorySaver()
                    logger.info("âœ… ä½¿ç”¨å†…å­˜æ£€æŸ¥ç‚¹ä¿å­˜å™¨")
                except ImportError:
                    if SqliteSaver:
                        try:
                            # å¦‚æœæ²¡æœ‰MemorySaverï¼Œå°è¯•ä½¿ç”¨SQLite
                            checkpoint_db = str(checkpoint_dir / "interview_checkpoints.db")
                            self.checkpointer = SqliteSaver.from_conn_string(f"sqlite:///{checkpoint_db}")
                            logger.info("âœ… ä½¿ç”¨SQLiteæ£€æŸ¥ç‚¹ä¿å­˜å™¨")
                        except Exception as sqlite_error:
                            logger.warning(f"SQLiteä¿å­˜å™¨åˆå§‹åŒ–å¤±è´¥: {sqlite_error}")
                            self.checkpointer = None
                    else:
                        logger.warning("SQLiteä¿å­˜å™¨ä¸å¯ç”¨")
                        self.checkpointer = None
            else:
                self.checkpointer = None
                
            # æ„å»ºå¹¶ç¼–è¯‘å·¥ä½œæµ
            self.workflow = self._build_workflow()
            
            if LANGGRAPH_AVAILABLE:
                self.app = self.workflow.compile(checkpointer=self.checkpointer)
            else:
                self.app = self.workflow.compile()
                
            logger.info("âœ… LangGraphæ™ºèƒ½é¢è¯•å®˜åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½ä½“åˆå§‹åŒ–å¤±è´¥: {e}")
            # åˆ›å»ºé™çº§ç‰ˆæœ¬
            self.app = None
            self.checkpointer = None
    
    def _build_workflow(self) -> StateGraph:
        """æ„å»ºLangGraphå·¥ä½œæµ - ä½¿ç”¨æœ€æ–°APIå’Œæœ€ä½³å®è·µ"""
        workflow = StateGraph(InterviewState)
        
        # æ ¸å¿ƒå¤„ç†èŠ‚ç‚¹
        workflow.add_node("perceive", self._perceive_node)          # æ„ŸçŸ¥ç”¨æˆ·çŠ¶æ€
        workflow.add_node("decide", self._decide_node)              # æ™ºèƒ½å†³ç­–
        workflow.add_node("agent", self._agent_node)                # æ™ºèƒ½ä½“å“åº”ç”Ÿæˆ
        workflow.add_node("tools", tool_node)                       # å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹ - ä½¿ç”¨LangGraphå†…ç½®ToolNode
        workflow.add_node("process_tools", self._process_tools_node) # å¤„ç†å·¥å…·ç»“æœ
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.add_edge(START, "perceive")
        
        # æ„å»ºå·¥ä½œæµè·¯å¾„
        workflow.add_edge("perceive", "decide")                     # æ„ŸçŸ¥ â†’ å†³ç­–
        workflow.add_edge("decide", "agent")                        # å†³ç­– â†’ æ™ºèƒ½ä½“ç”Ÿæˆå“åº”
        
        # æ¡ä»¶è¾¹ï¼šæ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
        workflow.add_conditional_edges(
            "agent",
            tools_condition,                                        # ä½¿ç”¨LangGraphå†…ç½®æ¡ä»¶æ£€æŸ¥
            {
                "tools": "tools",                                   # éœ€è¦å·¥å…· â†’ å·¥å…·èŠ‚ç‚¹
                END: END                                            # ä¸éœ€è¦å·¥å…· â†’ ç»“æŸ
            }
        )
        
        # å·¥å…·æ‰§è¡Œåå¤„ç†ç»“æœ
        workflow.add_edge("tools", "process_tools")
        workflow.add_edge("process_tools", "agent")                 # å¤„ç†å®Œå·¥å…·ç»“æœ â†’ å†æ¬¡ç”Ÿæˆå“åº”
        
        return workflow
    
    async def _perceive_node(self, state: InterviewState) -> InterviewState:
        """ğŸ§  æ„ŸçŸ¥èŠ‚ç‚¹ï¼šç®€å•çš„æƒ…ç»ªåˆ†æï¼Œå®Œæ•´åº¦ä»ç”¨æˆ·ç”»åƒä¸­è·å–"""
        logger.info("ğŸ§  æ‰§è¡Œæ„ŸçŸ¥èŠ‚ç‚¹...")
        
        try:
            # è·å–æœ€æ–°ç”¨æˆ·æ¶ˆæ¯
            user_message = ""
            if state["messages"]:
                last_message = state["messages"][-1]
                if isinstance(last_message, HumanMessage):
                    user_message = last_message.content
            
            # ç®€åŒ–æƒ…ç»ªåˆ†æ - åŸºäºå…³é”®è¯
            user_emotion = "neutral"
            if user_message:
                message_lower = user_message.lower()
                if any(word in message_lower for word in ["ç´§å¼ ", "æ‹…å¿ƒ", "å®³æ€•", "ç„¦è™‘", "ä¸å®‰"]):
                    user_emotion = "anxious"
                elif any(word in message_lower for word in ["å…´å¥‹", "è‡ªä¿¡", "é«˜å…´", "æœŸå¾…"]):
                    user_emotion = "confident"
                elif any(word in message_lower for word in ["å›°æƒ‘", "ä¸æ‡‚", "ä¸æ¸…æ¥š", "ä¸æ˜ç™½"]):
                    user_emotion = "confused"
            
            # ä»ç”¨æˆ·ç”»åƒä¸­è·å–å®Œæ•´åº¦ä¿¡æ¯ï¼ˆæ¥è‡ªæ™ºèƒ½åˆ†æAPIï¼‰
            completeness_score = state["user_profile"].get("completeness_score", state.get("completeness_score", 0.0))
            missing_info = state["user_profile"].get("missing_info", state.get("missing_info", []))
            
            # æ›´æ–°çŠ¶æ€
            state["missing_info"] = missing_info
            state["completeness_score"] = completeness_score
            state["user_emotion"] = user_emotion
            
            logger.info(f"   æ„ŸçŸ¥ç»“æœ: å®Œæ•´åº¦={completeness_score:.1%}, æƒ…ç»ª={user_emotion}, ç¼ºå¤±={len(missing_info)}é¡¹")
            
            return state
            
        except Exception as e:
            logger.error(f"æ„ŸçŸ¥èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤çŠ¶æ€
            state["missing_info"] = []
            state["completeness_score"] = 0.5
            state["user_emotion"] = "neutral"
            return state
    
    async def _decide_node(self, state: InterviewState) -> InterviewState:
        """ğŸ¤– å†³ç­–èŠ‚ç‚¹ï¼šè°ƒç”¨æ™ºèƒ½å†³ç­–APIè¿›è¡Œç­–ç•¥åˆ¶å®š"""
        logger.info("ğŸ¤– æ‰§è¡Œå†³ç­–èŠ‚ç‚¹...")
        
        try:
            # è·å–æœ€æ–°ç”¨æˆ·æ¶ˆæ¯
            latest_user_message = ""
            if state["messages"]:
                last_message = state["messages"][-1]
                if isinstance(last_message, HumanMessage):
                    latest_user_message = last_message.content
            
            # è°ƒç”¨æ™ºèƒ½å†³ç­–API
            decision_result = await self._call_interview_decision_api(
                user_name=state["user_name"],
                target_position=state["target_position"],
                user_emotion=state["user_emotion"],
                completeness_score=state["completeness_score"],
                missing_info=state["missing_info"],
                formal_interview_started=state.get("formal_interview_started", False),
                question_count=state["question_count"],
                latest_user_message=latest_user_message
            )
            
            if decision_result.get("success"):
                # ä½¿ç”¨æ™ºèƒ½å†³ç­–ç»“æœ
                decision = {
                    "action_type": decision_result.get("action_type", "conduct_interview"),
                    "priority": decision_result.get("priority", 1),
                    "reasoning": decision_result.get("reasoning", "AIæ™ºèƒ½å†³ç­–"),
                    "suggested_response": decision_result.get("suggested_response", "")
                }
                
                # å¦‚æœå†³ç­–æ˜¯è¿›å…¥æ­£å¼é¢è¯•ï¼Œæ›´æ–°çŠ¶æ€
                if decision["action_type"] == "conduct_interview" and not state.get("formal_interview_started"):
                    state["formal_interview_started"] = True
                    set_interview_stage(state["session_id"], True)
                    logger.info("   ğŸš€ æ™ºèƒ½å†³ç­–ï¼šè¿›å…¥æ­£å¼é¢è¯•é˜¶æ®µ")
                
            else:
                # é™çº§åˆ°ç®€å•è§„åˆ™
                logger.warning(f"âš ï¸ æ™ºèƒ½å†³ç­–å¤±è´¥ï¼Œä½¿ç”¨é™çº§è§„åˆ™: {decision_result.get('error')}")
                
                if state["user_emotion"] == "anxious":
                    action_type = "provide_emotional_support"
                    reasoning = "ç”¨æˆ·æƒ…ç»ªç´§å¼ ï¼Œä¼˜å…ˆæä¾›æƒ…æ„Ÿæ”¯æŒ"
                elif not state.get("formal_interview_started", False) and state["completeness_score"] < 0.5:
                    action_type = "collect_info"
                    reasoning = "ä¿¡æ¯ä¸å®Œæ•´ï¼Œéœ€è¦æ”¶é›†åŸºç¡€ä¿¡æ¯"
                elif state["question_count"] >= 3:
                    action_type = "end_interview"
                    reasoning = "é—®é¢˜å……åˆ†ï¼Œå¯ä»¥ç»“æŸé¢è¯•"
                else:
                    action_type = "conduct_interview"
                    reasoning = "ç»§ç»­æ­£å¸¸é¢è¯•æµç¨‹"
                
                decision = {
                    "action_type": action_type,
                    "priority": 1,
                    "reasoning": reasoning,
                    "suggested_response": ""
                }
            
            state["current_decision"] = decision
            logger.info(f"   å†³ç­–: {decision['action_type']} - {decision['reasoning']}")
            
            return state
            
        except Exception as e:
            logger.error(f"å†³ç­–èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {e}")
            # é»˜è®¤å†³ç­–
            state["current_decision"] = {
                "action_type": "conduct_interview",
                "priority": 2,
                "reasoning": "å†³ç­–å¤±è´¥ï¼Œé»˜è®¤ç»§ç»­é¢è¯•"
            }
            return state
    
    async def _agent_node(self, state: InterviewState) -> InterviewState:
        """ğŸ¤– æ™ºèƒ½ä½“èŠ‚ç‚¹ï¼šä½¿ç”¨çœŸå®å¤§æ¨¡å‹ç”Ÿæˆæ™ºèƒ½å›å¤"""
        logger.info("ğŸ¤– æ‰§è¡Œæ™ºèƒ½ä½“èŠ‚ç‚¹ï¼ˆçœŸå®å¤§æ¨¡å‹ï¼‰...")
        
        try:
            # è·å–å†³ç­–ä¿¡æ¯
            decision = state.get("current_decision", {})
            action_type = decision.get("action_type", "conduct_interview")
            
            # æ„å»ºæ™ºèƒ½çš„ç³»ç»Ÿæç¤º
            system_prompt = self._build_system_prompt(state, action_type)
            
            # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨ç»™ChatModel
            messages = [SystemMessage(content=system_prompt)]
            
            # æ·»åŠ æœ€è¿‘çš„å¯¹è¯å†å²ï¼ˆæœ€å¤š5æ¡ï¼‰
            recent_messages = state["messages"][-50:] if state["messages"] else []
            messages.extend(recent_messages)
            
            # è°ƒç”¨çœŸå®çš„æ˜Ÿç«ChatModel
            logger.info(f"ğŸ§  è°ƒç”¨æ˜Ÿç«å¤§æ¨¡å‹ï¼Œç­–ç•¥: {action_type}")
            chat_result = await self.model._agenerate(messages)
            
            # æå–AIå›å¤
            ai_message = chat_result.generations[0].message
            
            # æ ¹æ®éœ€è¦ï¼Œå¯èƒ½éœ€è¦è°ƒç”¨å·¥å…·æ¥å¢å¼ºå›å¤
            enhanced_message = await self._enhance_with_tools(ai_message, state, action_type)
            
            # æ·»åŠ åˆ°æ¶ˆæ¯å†å²
            state["messages"].append(enhanced_message)
            
            # æ›´æ–°é—®é¢˜è®¡æ•°
            if action_type == "conduct_interview":
                state["question_count"] += 1
            
            logger.info(f"   âœ… çœŸå®å¤§æ¨¡å‹å›å¤: {enhanced_message.content[:50]}...")
            
            return state
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½ä½“èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            # ç”Ÿæˆå®‰å…¨çš„é™çº§å›å¤
            fallback_content = f"æ„Ÿè°¢æ‚¨çš„åˆ†äº«ï¼Œ{state['user_name']}ã€‚è®©æˆ‘ä»¬ç»§ç»­é¢è¯•ï¼Œè¯·å‘Šè¯‰æˆ‘æ›´å¤šå…³äºæ‚¨åœ¨{state['target_position']}æ–¹é¢çš„ç»éªŒã€‚"
            fallback_response = AIMessage(content=fallback_content)
            state["messages"].append(fallback_response)
            return state
    
    def _build_system_prompt(self, state: InterviewState, action_type: str) -> str:
        """æ„å»ºæ™ºèƒ½çš„ç³»ç»Ÿæç¤ºï¼Œç”¨äºçœŸå®å¤§æ¨¡å‹"""
        formal_started = state.get("formal_interview_started", False)
        
        base_prompt = f"""ä½ æ˜¯ä¸€åèµ„æ·±çš„AIé¢è¯•å®˜ï¼Œæ­£åœ¨ä¸º{state["target_position"]}èŒä½è¿›è¡Œä¸“ä¸šé¢è¯•ã€‚

é¢è¯•å¯¹è±¡ï¼š{state["user_name"]}
ç›®æ ‡èŒä½ï¼š{state["target_position"]}
å½“å‰ç­–ç•¥ï¼š{action_type}
é¢è¯•é˜¶æ®µï¼š{"æ­£å¼é¢è¯•é˜¶æ®µ" if formal_started else "ä¿¡æ¯æ”¶é›†é˜¶æ®µ"}

å€™é€‰äººçŠ¶æ€åˆ†æï¼š
- ä¿¡æ¯å®Œæ•´åº¦ï¼š{state["completeness_score"]:.1%}
- æƒ…ç»ªçŠ¶æ€ï¼š{state["user_emotion"]}
- ç¼ºå¤±ä¿¡æ¯ï¼š{state["missing_info"]}
- å·²è¿›è¡Œé—®é¢˜æ•°ï¼š{state["question_count"]}

**é‡è¦è§„åˆ™ï¼š**
1. å›å¤å¿…é¡»æ§åˆ¶åœ¨100å­—ä»¥å†…ï¼Œç®€æ´æ˜äº†
2. ä¸€æ¬¡åªé—®ä¸€ä¸ªé—®é¢˜
3. ä½¿ç”¨ä¸“ä¸šä½†å‹å¥½çš„è¯­è°ƒ
4. é¿å…å†—é•¿çš„è§£é‡Šå’Œé“ºå«

"""
        
        # æ ¹æ®ç­–ç•¥æ·»åŠ å…·ä½“æŒ‡å¯¼
        strategy_instructions = {
            "provide_emotional_support": """
å½“å‰ç­–ç•¥ï¼šæƒ…æ„Ÿæ”¯æŒï¼ˆé™åˆ¶80å­—å†…ï¼‰
ç”¨æˆ·æ˜¾ç¤ºå‡ºç´§å¼ æˆ–å›°æƒ‘æƒ…ç»ªï¼Œè¯·ï¼š
1. ç®€æ´åœ°æä¾›æ¸©æš–ç†è§£çš„å›åº”
2. å¿«é€Ÿç¼“è§£ç´§å¼ æƒ…ç»ª
3. ä¸€å¥è¯é¼“åŠ±ï¼Œç„¶åç›´æ¥è¿‡æ¸¡åˆ°é¢è¯•å†…å®¹
ç¤ºä¾‹ï¼š"æˆ‘ç†è§£æ‚¨çš„ç´§å¼ ï¼Œè¿™å¾ˆæ­£å¸¸ã€‚è®©æˆ‘ä»¬æ”¾æ¾å¿ƒæƒ…ï¼Œä»ä¸€ä¸ªç®€å•é—®é¢˜å¼€å§‹å§ã€‚"
""",
            
            "collect_info": """
å½“å‰ç­–ç•¥ï¼šä¿¡æ¯æ”¶é›†ï¼ˆé™åˆ¶60å­—å†…ï¼‰
ç”¨æˆ·åŸºç¡€ä¿¡æ¯ä¸å®Œæ•´ï¼Œè¯·ï¼š
1. ç›´æ¥è¯¢é—®ä¸€ä¸ªç¼ºå¤±çš„å…³é”®ä¿¡æ¯
2. è¯­è¨€ç®€æ´ï¼Œé¿å…è§£é‡Šè¿‡å¤š
3. ä¸€æ¬¡åªé—®ä¸€ä¸ªå…·ä½“é—®é¢˜
ç¤ºä¾‹ï¼š"è¯·é—®æ‚¨æœ‰å¤šå°‘å¹´ç›¸å…³å·¥ä½œç»éªŒï¼Ÿ" æˆ– "æ‚¨çš„æœ€é«˜å­¦å†æ˜¯ï¼Ÿ"
""",
            
            "conduct_interview": """
å½“å‰ç­–ç•¥ï¼šæ­£å¸¸é¢è¯•ï¼ˆé™åˆ¶80å­—å†…ï¼‰
ä¿¡æ¯ç›¸å¯¹å®Œæ•´ï¼Œè¿›è¡Œä¸“ä¸šé¢è¯•ï¼š
1. æå‡ºä¸€ä¸ªå…·ä½“ã€æœ‰é’ˆå¯¹æ€§çš„é—®é¢˜
2. é—®é¢˜è¦æœ‰æ·±åº¦ä½†è¡¨è¿°ç®€æ´
3. å¯é€‚å½“ä½¿ç”¨STARåŸåˆ™å¼•å¯¼
ç¤ºä¾‹ï¼š"è¯·ç®€è¿°æ‚¨æœ€æœ‰æˆå°±æ„Ÿçš„é¡¹ç›®åŠæ‚¨çš„å…·ä½“è´¡çŒ®ï¼Ÿ"
""",
            
            "end_interview": """
å½“å‰ç­–ç•¥ï¼šç»“æŸé¢è¯•ï¼ˆé™åˆ¶100å­—å†…ï¼‰
å·²æ”¶é›†è¶³å¤Ÿä¿¡æ¯ï¼Œè¯·ï¼š
1. ç®€æ´æ„Ÿè°¢å€™é€‰äººå‚ä¸
2. ä¸€å¥è¯æ€»ç»“äº®ç‚¹
3. è¯´æ˜åç»­æµç¨‹
ç¤ºä¾‹ï¼š"æ„Ÿè°¢æ‚¨çš„åˆ†äº«ï¼æ‚¨åœ¨é¡¹ç›®ç®¡ç†æ–¹é¢çš„ç»éªŒå¾ˆå‡ºè‰²ã€‚æˆ‘ä»¬ä¼šåœ¨3ä¸ªå·¥ä½œæ—¥å†…ç»™æ‚¨åé¦ˆã€‚"
"""
        }
        
        instruction = strategy_instructions.get(action_type, "è¯·è¿›è¡Œä¸“ä¸šçš„é¢è¯•å¯¹è¯ã€‚")
        
        return base_prompt + instruction
    
    async def _enhance_with_tools(self, ai_message: AIMessage, state: InterviewState, action_type: str) -> AIMessage:
        """ä½¿ç”¨çœŸå®å·¥å…·å¢å¼ºAIå›å¤"""
        try:
            # æ ¹æ®ç­–ç•¥å†³å®šæ˜¯å¦éœ€è¦å·¥å…·å¢å¼º
            if action_type == "collect_info" and state["missing_info"]:
                # ä½¿ç”¨çœŸå®çš„ä¿¡æ¯æå–å·¥å…·
                extraction_tool = next((tool for tool in interview_tools if tool.name == "extract_structured_info"), None)
                if extraction_tool:
                    # è·å–ç”¨æˆ·çš„æœ€æ–°æ¶ˆæ¯
                    user_messages = [msg for msg in state["messages"] if isinstance(msg, HumanMessage)]
                    if user_messages:
                        latest_user_msg = user_messages[-1].content
                        
                        # è°ƒç”¨çœŸå®å·¥å…·æå–ä¿¡æ¯
                        extracted = await extraction_tool._arun(
                            message=latest_user_msg,
                            missing_fields=state["missing_info"]
                        )
                        
                        if extracted:
                            logger.info(f"ğŸ”§ å·¥å…·æå–ä¿¡æ¯: {extracted}")
                            # æ›´æ–°çŠ¶æ€ä¸­çš„æå–ä¿¡æ¯
                            state["extracted_info"] = extracted
                            
                            # ä½¿ç”¨æ•°æ®åº“æ›´æ–°å·¥å…·
                            db_tool = next((tool for tool in interview_tools if tool.name == "update_user_database"), None)
                            if db_tool:
                                await db_tool._arun(
                                    user_id=state["user_id"],
                                    session_id=state["session_id"],
                                    extracted_info=extracted
                                )
            
            return ai_message
            
        except Exception as e:
            logger.error(f"å·¥å…·å¢å¼ºå¤±è´¥: {e}")
            return ai_message
    
    async def _generate_emotional_support(self, state: InterviewState) -> str:
        """ç”Ÿæˆæƒ…æ„Ÿæ”¯æŒå›å¤"""
        user_emotion = state["user_emotion"]
        user_name = state["user_name"]
        
        support_messages = {
            "anxious": f"{user_name}ï¼Œæˆ‘èƒ½æ„Ÿè§‰åˆ°æ‚¨å¯èƒ½æœ‰äº›ç´§å¼ ï¼Œè¿™å®Œå…¨æ­£å¸¸ï¼é¢è¯•æ˜¯ä¸€ä¸ªç›¸äº’äº†è§£çš„è¿‡ç¨‹ã€‚è¯·æ”¾æ¾å¿ƒæƒ…ï¼Œæˆ‘ä»¬æ…¢æ…¢æ¥ï¼Œä¸ç”¨ç€æ€¥ã€‚",
            "confused": f"{user_name}ï¼Œå¦‚æœæœ‰ä»»ä½•ä¸æ¸…æ¥šçš„åœ°æ–¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚æˆ‘ä»¬å¯ä»¥æ¢ä¸ªè§’åº¦è®¨è®ºï¼Œæˆ–è€…æˆ‘å¯ä»¥æä¾›æ›´å¤šèƒŒæ™¯ä¿¡æ¯ã€‚",
            "confident": f"å¾ˆæ£’ï¼Œ{user_name}ï¼æˆ‘èƒ½æ„Ÿå—åˆ°æ‚¨çš„è‡ªä¿¡å’Œç§¯ææ€åº¦ã€‚ä¿æŒè¿™ç§çŠ¶æ€ï¼Œè®©æˆ‘ä»¬ç»§ç»­é¢è¯•ã€‚"
        }
        
        return support_messages.get(user_emotion, f"å¾ˆå¥½ï¼Œ{user_name}ï¼Œè®©æˆ‘ä»¬ç»§ç»­é¢è¯•å¯¹è¯å§ã€‚")
    
    async def _generate_info_question(self, state: InterviewState) -> str:
        """ç”Ÿæˆä¿¡æ¯æ”¶é›†é—®é¢˜"""
        missing_info = state["missing_info"]
        user_name = state["user_name"]
        target_position = state["target_position"]
        
        if not missing_info:
            return f"å¾ˆå¥½ï¼Œ{user_name}ï¼Œæ‚¨çš„ä¿¡æ¯å¾ˆå®Œæ•´ã€‚è®©æˆ‘ä»¬å¼€å§‹æ­£å¼çš„é¢è¯•ç¯èŠ‚å§ï¼"
        
        # ä¼˜å…ˆçº§å­—æ®µæ˜ å°„
        field_questions = {
            "work_years": f"åœ¨å¼€å§‹é¢è¯•å‰ï¼Œæˆ‘æƒ³äº†è§£æ‚¨çš„å·¥ä½œèƒŒæ™¯ã€‚{user_name}ï¼Œè¯·é—®æ‚¨æœ‰å¤šå°‘å¹´çš„{target_position}ç›¸å…³å·¥ä½œç»éªŒå‘¢ï¼Ÿ",
            "education_level": f"{user_name}ï¼Œè¯·é—®æ‚¨çš„æœ€é«˜å­¦å†æ˜¯ä»€ä¹ˆï¼Ÿæœ¬ç§‘ã€ç¡•å£«è¿˜æ˜¯åšå£«ï¼Ÿ",
            "current_company": f"è¯·é—®{user_name}ï¼Œæ‚¨ç›®å‰åœ¨å“ªå®¶å…¬å¸å·¥ä½œï¼Ÿå¦‚æœæ˜¯åº”å±Šç”Ÿï¼Œå¯ä»¥åˆ†äº«ä¸€ä¸‹æœ€è¿‘çš„å®ä¹ ç»å†ã€‚",
            "graduation_year": f"{user_name}ï¼Œè¯·é—®æ‚¨æ˜¯å“ªä¸€å¹´æ¯•ä¸šçš„ï¼Ÿè¿™æœ‰åŠ©äºæˆ‘äº†è§£æ‚¨çš„èŒä¸šå‘å±•é˜¶æ®µã€‚"
        }
        
        # é€‰æ‹©ä¼˜å…ˆçº§æœ€é«˜çš„é—®é¢˜
        priority_order = ["work_years", "education_level", "current_company", "graduation_year"]
        for field in priority_order:
            if field in missing_info:
                return field_questions.get(field, "è¯·å‘Šè¯‰æˆ‘æ›´å¤šå…³äºæ‚¨çš„èƒŒæ™¯ä¿¡æ¯ã€‚")
        
        return f"{user_name}ï¼Œè¯·å‘Šè¯‰æˆ‘æ›´å¤šå…³äºæ‚¨çš„èƒŒæ™¯ï¼Œè¿™æ ·æˆ‘èƒ½ä¸ºæ‚¨æä¾›æ›´å¥½çš„é¢è¯•ä½“éªŒã€‚"
    
    async def _generate_interview_question(self, state: InterviewState) -> str:
        """ç”Ÿæˆé¢è¯•é—®é¢˜ - ç®€åŒ–å®ç°"""
        try:
            # æ„å»ºé¢è¯•é—®é¢˜æ¨¡æ¿
            user_name = state["user_name"]
            target_position = state["target_position"]
            question_count = state["question_count"]
            
            # æ ¹æ®é—®é¢˜æ•°é‡é€‰æ‹©ä¸åŒç±»å‹çš„é—®é¢˜
            if question_count == 0:
                return f"{user_name}ï¼Œè¯·æ‚¨å…ˆç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±ï¼ŒåŒ…æ‹¬æ‚¨çš„æ•™è‚²èƒŒæ™¯å’Œå·¥ä½œç»å†ã€‚"
            elif question_count == 1:
                return f"å¾ˆå¥½ï¼è¯·é—®æ‚¨ä¸ºä»€ä¹ˆé€‰æ‹©åº”è˜{target_position}è¿™ä¸ªèŒä½ï¼Ÿæ‚¨è§‰å¾—è‡ªå·±æœ€å¤§çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ"
            elif question_count == 2:
                return f"è¯·æè¿°ä¸€ä¸ªæ‚¨æœ€æœ‰æˆå°±æ„Ÿçš„é¡¹ç›®æˆ–å·¥ä½œç»å†ï¼Œæ‚¨åœ¨å…¶ä¸­æ‹…ä»»äº†ä»€ä¹ˆè§’è‰²ï¼Ÿ"
            elif question_count == 3:
                return "è¯·è°ˆè°ˆæ‚¨åœ¨å›¢é˜Ÿåˆä½œä¸­é‡åˆ°è¿‡çš„æŒ‘æˆ˜ï¼Œä»¥åŠæ‚¨æ˜¯å¦‚ä½•è§£å†³çš„ï¼Ÿ"
            elif question_count == 4:
                return f"å¯¹äº{target_position}è¿™ä¸ªèŒä½ï¼Œæ‚¨è®¤ä¸ºæœ€é‡è¦çš„æŠ€èƒ½æ˜¯ä»€ä¹ˆï¼Ÿæ‚¨åœ¨è¿™æ–¹é¢æœ‰ä»€ä¹ˆç»éªŒï¼Ÿ"
            else:
                return f"æœ€åä¸€ä¸ªé—®é¢˜ï¼Œ{user_name}ï¼Œæ‚¨å¯¹æˆ‘ä»¬å…¬å¸æˆ–è¿™ä¸ªèŒä½è¿˜æœ‰ä»€ä¹ˆæƒ³äº†è§£çš„å—ï¼Ÿ"
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆé¢è¯•é—®é¢˜å¤±è´¥: {e}")
            return f"{state['user_name']}ï¼Œè¯·ç»§ç»­å‘Šè¯‰æˆ‘å…³äºæ‚¨çš„å·¥ä½œç»éªŒå§ã€‚"
    
    def _generate_interview_summary(self, state: InterviewState) -> str:
        """ç”Ÿæˆé¢è¯•æ€»ç»“"""
        user_name = state["user_name"]
        target_position = state["target_position"]
        completeness = state["completeness_score"]
        
        return f"æ„Ÿè°¢æ‚¨å‚åŠ ä»Šå¤©çš„é¢è¯•ï¼Œ{user_name}ï¼é€šè¿‡æˆ‘ä»¬çš„å¯¹è¯ï¼Œæˆ‘å¯¹æ‚¨ç”³è¯·{target_position}èŒä½æœ‰äº†å¾ˆå¥½çš„äº†è§£ã€‚æ‚¨çš„ä¿¡æ¯å®Œæ•´åº¦è¾¾åˆ°äº†{completeness:.1%}ï¼Œè¡¨ç°å¾—å¾ˆæ£’ã€‚æˆ‘ä»¬ä¼šå°½å¿«ç»™æ‚¨åé¦ˆï¼Œç¥æ‚¨æ±‚èŒé¡ºåˆ©ï¼"
    
    def _get_strategy_instruction(self, action_type: str, state: InterviewState) -> str:
        """æ ¹æ®ç­–ç•¥ç±»å‹ç”Ÿæˆå…·ä½“æŒ‡ä»¤"""
        instructions = {
            "provide_emotional_support": f"ç”¨æˆ·æ˜¾ç¤ºå‡º{state['user_emotion']}æƒ…ç»ªï¼Œè¯·æä¾›æ¸©æš–çš„æƒ…æ„Ÿæ”¯æŒï¼Œç¼“è§£ç´§å¼ æƒ…ç»ªï¼Œç„¶åå¯ä»¥ä½¿ç”¨provide_emotional_supportå·¥å…·ã€‚",
            "collect_info": f"ç”¨æˆ·ç¼ºå¤±{len(state['missing_info'])}é¡¹åŸºç¡€ä¿¡æ¯ï¼Œè¯·å‹å¥½åœ°è¯¢é—®ç¼ºå¤±çš„ä¿¡æ¯ï¼Œå¯ä»¥ä½¿ç”¨generate_missing_info_questionå·¥å…·ç”Ÿæˆåˆé€‚çš„é—®é¢˜ã€‚",
            "conduct_interview": "ä¿¡æ¯ç›¸å¯¹å®Œæ•´ï¼Œè¯·è¿›è¡Œæ­£å¸¸çš„é¢è¯•å¯¹è¯ï¼Œæå‡ºä¸“ä¸šçš„é¢è¯•é—®é¢˜ï¼Œè¯„ä¼°å€™é€‰äººçš„èƒ½åŠ›ã€‚",
            "end_interview": "é¢è¯•é—®é¢˜å·²ç»å……åˆ†ï¼Œè¯·æ€»ç»“é¢è¯•å¹¶ç»™å‡ºç§¯æçš„ç»“æŸè¯­ã€‚"
        }
        
        return instructions.get(action_type, "è¯·è¿›è¡Œä¸“ä¸šçš„é¢è¯•å¯¹è¯ã€‚")
    
    async def _process_tools_node(self, state: InterviewState) -> InterviewState:
        """ğŸ”§ å¤„ç†å·¥å…·è°ƒç”¨ç»“æœ"""
        logger.info("ğŸ”§ å¤„ç†å·¥å…·ç»“æœ...")
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·æ¶ˆæ¯
            tool_messages = [msg for msg in state["messages"] if isinstance(msg, ToolMessage)]
            
            if tool_messages:
                latest_tool_msg = tool_messages[-1]
                logger.info(f"   å¤„ç†å·¥å…·ç»“æœ: {latest_tool_msg.content[:50]}...")
                
                # å¦‚æœå·¥å…·è¿”å›äº†æå–çš„ä¿¡æ¯ï¼Œæ›´æ–°ç”¨æˆ·æ¡£æ¡ˆ
                if "extract_structured_info" in latest_tool_msg.name:
                    try:
                        extracted_data = json.loads(latest_tool_msg.content)
                        if extracted_data and isinstance(extracted_data, dict):
                            # æ›´æ–°ç”¨æˆ·æ¡£æ¡ˆ
                            basic_info = state["user_profile"].get("basic_info", {})
                            for key, value in extracted_data.items():
                                basic_info[key] = value
                            
                            state["user_profile"]["basic_info"] = basic_info
                            state["extracted_info"] = extracted_data
                            
                            logger.info(f"   æ›´æ–°æ¡£æ¡ˆ: {list(extracted_data.keys())}")
                    except json.JSONDecodeError:
                        logger.warn("å·¥å…·è¿”å›ç»“æœä¸æ˜¯æœ‰æ•ˆJSON")
            
            return state
            
        except Exception as e:
            logger.error(f"å¤„ç†å·¥å…·ç»“æœå¤±è´¥: {e}")
            return state
    
    # æ—§èŠ‚ç‚¹å·²åˆ é™¤ï¼Œç°åœ¨ä½¿ç”¨ç®€åŒ–çš„LangGraphå·¥ä½œæµ
    
    async def process_message_via_langgraph(self, user_id: str, session_id: str, user_name: str, 
                                           target_position: str, user_message: str, user_profile: Dict) -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ - ç»Ÿä¸€ä½¿ç”¨LangGraphå·¥ä½œæµï¼Œæ¶ˆé™¤å¹¶è¡Œé€»è¾‘"""
        
        try:
            logger.info(f"ğŸ”„ LangGraphå¤„ç†æ¶ˆæ¯: {user_message[:50]}...")
            
            # 0. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°LangChainæ¶ˆæ¯å†å²
            add_user_message(session_id, user_message)
            logger.debug(f"ğŸ“ ç”¨æˆ·æ¶ˆæ¯å·²ä¿å­˜åˆ°SQLite: {session_id}")
            
            # 1. æ„å»ºçŠ¶æ€å¹¶é€šè¿‡LangGraphå·¥ä½œæµå¤„ç†
            state = InterviewState(
                messages=[HumanMessage(content=user_message)],
                user_id=user_id,
                session_id=session_id,
                user_name=user_name,
                target_position=target_position,
                user_profile=user_profile,
                missing_info=user_profile.get("missing_info", []),
                completeness_score=user_profile.get("completeness_score", 0.0),
                user_emotion="neutral",
                current_decision={},
                should_continue=True,
                extracted_info={},
                interview_stage="active",
                question_count=len([msg for msg in get_conversation_context(session_id) if isinstance(msg, AIMessage)]),
                formal_interview_started=user_profile.get("formal_interview_started", False)
            )
            
            # 2. é€šè¿‡LangGraphåº”ç”¨å¤„ç†
            if self.app:
                config = {"configurable": {"thread_id": session_id}}
                result = await self.app.ainvoke(state, config)
                
                # 3. æå–ç»“æœ
                if result and result.get("messages"):
                    last_message = result["messages"][-1]
                    if isinstance(last_message, AIMessage):
                        response = last_message.content
                        
                        # ä¿å­˜AIå›å¤åˆ°å†å²
                        add_ai_message(session_id, response)
                        logger.debug(f"ğŸ“ AIå›å¤å·²ä¿å­˜åˆ°SQLite: {session_id}")
                        
                        return {
                            "success": True,
                            "response": response,
                            "user_profile": result.get("user_profile", user_profile),
                            "completeness_score": result.get("completeness_score", 0.0),
                            "missing_info": result.get("missing_info", []),
                            "user_emotion": result.get("user_emotion", "neutral"),
                            "decision": result.get("current_decision", {}),
                            "extracted_info": result.get("extracted_info", {}),
                            "interview_stage": "active"
                        }
            
            # é™çº§å¤„ç†
            raise Exception("LangGraphå·¥ä½œæµå¤„ç†å¤±è´¥")
            
        except Exception as e:
            logger.error(f"âŒ LangGraphæ¶ˆæ¯å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            # é™çº§åˆ°ç®€å•å›å¤
            fallback_response = f"æ„Ÿè°¢æ‚¨çš„åˆ†äº«ï¼Œ{user_name}ã€‚è®©æˆ‘ä»¬ç»§ç»­é¢è¯•ï¼Œè¯·å‘Šè¯‰æˆ‘æ›´å¤šå…³äºæ‚¨åœ¨{target_position}æ–¹é¢çš„ç»éªŒå’Œæƒ³æ³•ã€‚"
            
            return {
                "success": False,
                "error": str(e),
                "response": fallback_response,
                "user_profile": user_profile,
                "interview_stage": "active",
                "fallback_mode": True
            }
    
    async def start_interview(self, user_id: str, session_id: str, user_name: str,
                             target_position: str, target_field: str, resume_text: str = "") -> Dict[str, Any]:
        """å¼€å§‹é¢è¯•çš„å…¥å£æ–¹æ³• - è°ƒç”¨æ™ºèƒ½ç®€å†åˆ†æAPI"""
        
        try:
            # ä½¿ç”¨Redisåˆå§‹åŒ–ä¼šè¯çŠ¶æ€ï¼ˆè‡ªåŠ¨TTLç®¡ç†ï¼‰
            set_interview_stage(session_id, False)
            logger.info(f"ğŸ¯ Redisåˆå§‹åŒ–ä¼šè¯çŠ¶æ€: {session_id} (TTL: 4å°æ—¶)")
            
            # åˆå§‹åŒ–LangChainæ¶ˆæ¯å†å²ï¼ˆSQLiteæŒä¹…åŒ–ï¼‰
            session_history = get_session_history(session_id)
            logger.info(f"ğŸ“š åˆå§‹åŒ–SQLiteæ¶ˆæ¯å†å²: {session_id}")
            
            # ğŸ¯ è·å–ç”¨æˆ·ç®€å†ä¿¡æ¯
            logger.info(f"ğŸ“„ å¼€å§‹è·å–ç”¨æˆ·ç®€å†: {user_id}")
            resume_data = await self._get_user_resume(user_id)
            
            # ğŸš€ ä¼˜å…ˆä½¿ç”¨é¢„ç”Ÿæˆçš„ç”»åƒæ•°æ®
            user_profile = None
            welcome_message = None
            formal_started = False
            
            if resume_data and resume_data.get("resume_id"):
                resume_id = resume_data["resume_id"]
                logger.info(f"ğŸ§  å°è¯•è·å–é¢„ç”Ÿæˆç”»åƒ: {resume_id}")
                
                pre_generated_profile = await self._get_pre_generated_profile(resume_id)
                
                if pre_generated_profile:
                    logger.info(f"âœ… ä½¿ç”¨é¢„ç”Ÿæˆç”»åƒæ•°æ®: {resume_id}")
                    
                    # ä½¿ç”¨é¢„ç”Ÿæˆç”»åƒæ„å»ºç”¨æˆ·èµ„æ–™
                    user_profile = self._build_user_profile_from_pregenerated(
                        pre_generated_profile, user_name, target_position, target_field
                    )
                    
                    # ä½¿ç”¨ä¸ªæ€§åŒ–æ¬¢è¿è¯­
                    personalized_welcome = pre_generated_profile.get("personalized_welcome", {})
                    welcome_message = personalized_welcome.get("greeting")
                    
                    if not welcome_message:
                        # é™çº§åˆ°ç”ŸæˆåŸºç¡€æ¬¢è¿è¯­
                        welcome_message = self._generate_fallback_welcome(user_name, target_position, pre_generated_profile)
                    
                    # æ ¹æ®ç»éªŒæ°´å¹³åˆ¤æ–­æ˜¯å¦ç›´æ¥è¿›å…¥æ­£å¼é¢è¯•
                    experience_level = pre_generated_profile.get("experience_level", {})
                    completeness_score = pre_generated_profile.get("basic_info_completeness", {}).get("score", 0.5)
                    
                    # å¦‚æœä¿¡æ¯å®Œæ•´åº¦è¾ƒé«˜ä¸”æœ‰ä¸€å®šç»éªŒï¼Œç›´æ¥è¿›å…¥æ­£å¼é¢è¯•
                    if completeness_score >= 0.7 and experience_level.get("level") in ["junior", "mid_level", "senior"]:
                        formal_started = True
                        
                else:
                    logger.info(f"ğŸ“ æœªæ‰¾åˆ°é¢„ç”Ÿæˆç”»åƒï¼Œä½¿ç”¨åŸºç¡€åˆ†æ: {resume_id}")
            
            # å¦‚æœæ²¡æœ‰é¢„ç”Ÿæˆç”»åƒæˆ–ç®€å†ï¼Œé™çº§åˆ°åŸºç¡€é€»è¾‘
            if not user_profile:
                logger.info(f"ğŸ”„ é™çº§åˆ°åŸºç¡€ç”¨æˆ·ç”»åƒç”Ÿæˆ")
                user_profile = self._create_default_profile(user_name, target_position, target_field)
                
                if resume_data:
                    # åŸºäºç®€å†æ•°æ®åšç®€å•åˆ†æ
                    basic_analysis = self._analyze_resume_basic(resume_data, target_position)
                    user_profile.update(basic_analysis)
                    
                    welcome_message = self._generate_welcome_from_resume(user_name, target_position, resume_data)
                else:
                    welcome_message = f"æ‚¨å¥½ {user_name}ï¼æˆ‘æ˜¯æ‚¨çš„AIé¢è¯•å®˜ï¼Œå¾ˆé«˜å…´è§åˆ°æ‚¨ã€‚æˆ‘çœ‹åˆ°æ‚¨åº”è˜çš„æ˜¯{target_position}èŒä½ï¼Œè®©æˆ‘ä»¬å¼€å§‹é¢è¯•å§ï¼è¯·å…ˆç®€å•ä»‹ç»ä¸€ä¸‹æ‚¨è‡ªå·±ã€‚"
            
            # æ›´æ–°é¢è¯•çŠ¶æ€
            user_profile["formal_interview_started"] = formal_started
            if formal_started:
                set_interview_stage(session_id, True)
                logger.info(f"ğŸš€ æ™ºèƒ½åˆ†æåˆ¤æ–­ï¼šç›´æ¥è¿›å…¥æ­£å¼é¢è¯•é˜¶æ®µ")
            else:
                logger.info(f"ğŸ“ æ™ºèƒ½åˆ†æåˆ¤æ–­ï¼šéœ€è¦ä¿¡æ¯æ”¶é›†é˜¶æ®µ")
            
            # ä¿å­˜ç³»ç»Ÿåˆå§‹åŒ–æ¶ˆæ¯å’ŒAIæ¬¢è¿æ¶ˆæ¯åˆ°å†å²
            system_init_message = f"é¢è¯•ä¼šè¯å¼€å§‹ - ç”¨æˆ·: {user_name}, èŒä½: {target_position}, é¢†åŸŸ: {target_field}, ç®€å†çŠ¶æ€: {'æœ‰ç®€å†' if resume_data else 'æ— ç®€å†'}"
            session_history.add_message(SystemMessage(content=system_init_message))
            session_history.add_message(AIMessage(content=welcome_message))
            logger.debug(f"ğŸ“ åˆå§‹æ¶ˆæ¯å·²ä¿å­˜åˆ°SQLite: {session_id}")
            
            logger.info(f"âœ… æ™ºèƒ½é¢è¯•ä¼šè¯å¯åŠ¨: {session_id} - {user_name} ({target_position})")
            
            # æå–å®Œæ•´åº¦å’Œç¼ºå¤±ä¿¡æ¯
            completeness_score = 0.0
            missing_info = []
            
            if user_profile:
                # ä»ç”¨æˆ·ç”»åƒä¸­æå–å®Œæ•´åº¦ä¿¡æ¯
                completeness_score = user_profile.get("completeness_score", 0.0)
                missing_info = user_profile.get("missing_info", [])
                
                # å¦‚æœæ˜¯é¢„ç”Ÿæˆç”»åƒï¼Œä»basic_info_completenessä¸­æå–
                if "basic_info_completeness" in user_profile:
                    completeness_score = user_profile["basic_info_completeness"].get("score", 0.0)
                    missing_info = user_profile["basic_info_completeness"].get("missing_fields", [])
            
            return {
                "success": True,
                "session_id": session_id,
                "welcome_message": welcome_message,
                "user_profile": user_profile,
                "interview_stage": "active",
                "has_resume": resume_data is not None,
                "formal_interview_started": formal_started,
                "completeness_score": completeness_score,
                "missing_info": missing_info
            }
            
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨é¢è¯•å¤±è´¥: {e}")
            # é™çº§åˆ°åŸºç¡€ç‰ˆæœ¬
            basic_profile = {
                "basic_info": {
                    "name": user_name,
                    "target_position": target_position,
                    "target_field": target_field
                },
                "formal_interview_started": False
            }
            fallback_welcome = f"æ‚¨å¥½ {user_name}ï¼æˆ‘æ˜¯æ‚¨çš„AIé¢è¯•å®˜ï¼Œå¾ˆé«˜å…´è§åˆ°æ‚¨ã€‚æˆ‘çœ‹åˆ°æ‚¨åº”è˜çš„æ˜¯{target_position}èŒä½ï¼Œè®©æˆ‘ä»¬å¼€å§‹é¢è¯•å§ï¼è¯·å…ˆç®€å•ä»‹ç»ä¸€ä¸‹æ‚¨è‡ªå·±ã€‚"
            
            return {
                "success": False,
                "error": str(e),
                "session_id": session_id,
                "welcome_message": fallback_welcome,
                "user_profile": basic_profile,
                "interview_stage": "introduction",
                "has_resume": False,
                "formal_interview_started": False,
                "completeness_score": 0.0,
                "missing_info": []
            }
    
    def _create_default_profile(self, user_name: str, target_position: str, target_field: str = "") -> Dict[str, Any]:
        """åˆ›å»ºé»˜è®¤ç”¨æˆ·ç”»åƒ"""
        return {
            "basic_info": {
                "name": user_name,
                "target_position": target_position,
                "target_field": target_field or "æŠ€æœ¯",
                "work_years": None,
                "current_company": None,
                "education_level": None,
                "graduation_year": None,
                "expected_salary": None,
            },
            "technical_skills": {},
            "completeness_score": 0.2,
            # åˆå§‹åŒ–æ­£å¼é¢è¯•æœªå¼€å§‹
            "formal_interview_started": False
        }
    
    async def _get_user_resume(self, user_id: str) -> Optional[Dict]:
        """è·å–ç”¨æˆ·çš„æœ€æ–°ç®€å†ä¿¡æ¯"""
        try:
            # è°ƒç”¨ç®€å†ç³»ç»ŸAPIè·å–ç”¨æˆ·æœ€æ–°ç®€å†
            async with aiohttp.ClientSession() as session:
                async with session.get(f"http://localhost:8000/api/v1/resume/user-latest/{user_id}") as response:
                    if response.status == 200:
                        result = await response.json()
                        if result.get("success"):
                            logger.info(f"âœ… è·å–ç”¨æˆ·ç®€å†æˆåŠŸ: {user_id}")
                            return result.get("data")
                        else:
                            logger.warning(f"âš ï¸ ç”¨æˆ·æš‚æ— ç®€å†: {user_id} - {result.get('message')}")
                            return None
                    else:
                        logger.error(f"âŒ è·å–ç”¨æˆ·ç®€å†å¤±è´¥: {user_id} - HTTP {response.status}")
                        return None
        except Exception as e:
            logger.error(f"âŒ è·å–ç”¨æˆ·ç®€å†å¼‚å¸¸: {user_id} - {e}")
            return None
    
    async def _get_pre_generated_profile(self, resume_id: str) -> Optional[Dict]:
        """è·å–é¢„ç”Ÿæˆçš„ç”¨æˆ·ç”»åƒ"""
        try:
            # è°ƒç”¨ç®€å†ç³»ç»ŸAPIè·å–é¢„ç”Ÿæˆç”»åƒ
            async with aiohttp.ClientSession() as session:
                async with session.get(f"http://localhost:8000/api/v1/resume/profile/{resume_id}") as response:
                    if response.status == 200:
                        result = await response.json()
                        if result.get("success") and result.get("status") == "completed":
                            logger.info(f"âœ… è·å–é¢„ç”Ÿæˆç”»åƒæˆåŠŸ: {resume_id}")
                            return result.get("data")
                        elif result.get("status") == "processing":
                            logger.info(f"â³ ç”»åƒç”Ÿæˆä¸­: {resume_id}")
                            return None
                        elif result.get("status") == "failed":
                            logger.warning(f"âš ï¸ ç”»åƒç”Ÿæˆå¤±è´¥: {resume_id} - {result.get('error')}")
                            return None
                        else:
                            logger.info(f"ğŸ“ ç”»åƒå°šæœªç”Ÿæˆ: {resume_id}")
                            return None
                    else:
                        logger.warning(f"âš ï¸ è·å–ç”»åƒå¤±è´¥: {resume_id} - HTTP {response.status}")
                        return None
        except Exception as e:
            logger.warning(f"âš ï¸ è·å–é¢„ç”Ÿæˆç”»åƒå¼‚å¸¸: {resume_id} - {e}")
            return None
    
    def _build_user_profile_from_pregenerated(self, pre_generated_profile: Dict, 
                                            user_name: str, target_position: str, target_field: str) -> Dict:
        """ä»é¢„ç”Ÿæˆç”»åƒæ„å»ºç”¨æˆ·èµ„æ–™"""
        try:
            # åŸºç¡€ä¿¡æ¯å®Œæ•´åº¦
            basic_completeness = pre_generated_profile.get("basic_info_completeness", {})
            completeness_score = basic_completeness.get("score", 0.0)
            missing_fields = basic_completeness.get("missing_fields", [])
            
            # æŠ€èƒ½åŒ¹é…ä¿¡æ¯
            skill_matching = pre_generated_profile.get("skill_matching", {})
            
            # ç»éªŒç­‰çº§
            experience_level = pre_generated_profile.get("experience_level", {})
            
            # æ„å»ºå…¼å®¹çš„ç”¨æˆ·ç”»åƒæ ¼å¼
            user_profile = {
                "basic_info": {
                    "name": user_name,
                    "target_position": target_position,
                    "target_field": target_field,
                    "work_years": experience_level.get("years_estimated", 0),
                    "experience_level": experience_level.get("level", "fresh_graduate")
                },
                "technical_skills": skill_matching.get("matched_skills", []),
                "completeness_score": completeness_score,
                "missing_info": missing_fields,
                "formal_interview_started": False,
                
                # ä¿ç•™å®Œæ•´çš„é¢„ç”Ÿæˆç”»åƒæ•°æ®
                "basic_info_completeness": basic_completeness,
                "skill_matching": skill_matching,
                "experience_level": experience_level,
                "personality_traits": pre_generated_profile.get("personality_traits", {}),
                "interview_strategy": pre_generated_profile.get("interview_strategy", {}),
                "personalized_welcome": pre_generated_profile.get("personalized_welcome", {}),
                "metadata": pre_generated_profile.get("metadata", {})
            }
            
            logger.info(f"âœ… é¢„ç”Ÿæˆç”»åƒè½¬æ¢å®Œæˆ: å®Œæ•´åº¦={completeness_score:.1%}, ç»éªŒ={experience_level.get('level')}")
            return user_profile
            
        except Exception as e:
            logger.error(f"âŒ é¢„ç”Ÿæˆç”»åƒè½¬æ¢å¤±è´¥: {e}")
            return self._create_default_profile(user_name, target_position, target_field)
    
    def _generate_fallback_welcome(self, user_name: str, target_position: str, pre_generated_profile: Dict) -> str:
        """ç”Ÿæˆé™çº§æ¬¢è¿è¯­"""
        try:
            # å°è¯•ä»é¢„ç”Ÿæˆç”»åƒæå–å…³é”®ä¿¡æ¯
            experience_level = pre_generated_profile.get("experience_level", {})
            personality_traits = pre_generated_profile.get("personality_traits", {})
            
            welcome_parts = [f"æ‚¨å¥½ {user_name}ï¼æˆ‘æ˜¯æ‚¨çš„AIé¢è¯•å®˜ï¼Œå¾ˆé«˜å…´è§åˆ°æ‚¨ã€‚"]
            
            # æ ¹æ®ç»éªŒç­‰çº§ä¸ªæ€§åŒ–
            level = experience_level.get("level", "")
            if level == "fresh_graduate":
                welcome_parts.append(f"ä½œä¸º{target_position}çš„å€™é€‰äººï¼Œæˆ‘ç›¸ä¿¡æ‚¨æœ‰å¾ˆå¤šæ–°é²œçš„æƒ³æ³•å’Œå­¦ä¹ çƒ­æƒ…ã€‚")
            elif level in ["junior", "mid_level"]:
                welcome_parts.append(f"çœ‹åˆ°æ‚¨åœ¨{target_position}é¢†åŸŸå·²æœ‰ä¸€å®šç»éªŒï¼ŒæœŸå¾…äº†è§£æ‚¨çš„é¡¹ç›®ç»å†ã€‚")
            elif level == "senior":
                welcome_parts.append(f"ä½œä¸ºèµ„æ·±çš„{target_position}ä¸“ä¸šäººå£«ï¼Œæˆ‘å¾ˆæœŸå¾…å¬åˆ°æ‚¨çš„æ·±åº¦è§è§£ã€‚")
            else:
                welcome_parts.append(f"æˆ‘çœ‹åˆ°æ‚¨åº”è˜çš„æ˜¯{target_position}èŒä½ã€‚")
            
            # æ·»åŠ ä¼˜åŠ¿ç‰¹ç‚¹
            strengths = personality_traits.get("strengths", [])
            if strengths:
                welcome_parts.append(f"è®©æˆ‘ä»¬åœ¨è½»æ¾æ„‰å¿«çš„æ°›å›´ä¸­å¼€å§‹äº¤æµï¼Œå±•ç°æ‚¨{strengths[0] if strengths else 'ä¸“ä¸š'}çš„ä¸€é¢å§ï¼")
            else:
                welcome_parts.append("è®©æˆ‘ä»¬å¼€å§‹ä»Šå¤©çš„é¢è¯•äº¤æµå§ï¼")
            
            return "".join(welcome_parts)
            
        except Exception as e:
            logger.warning(f"âš ï¸ ç”Ÿæˆé™çº§æ¬¢è¿è¯­å¤±è´¥: {e}")
            return f"æ‚¨å¥½ {user_name}ï¼æˆ‘æ˜¯æ‚¨çš„AIé¢è¯•å®˜ï¼Œå¾ˆé«˜å…´è§åˆ°æ‚¨ã€‚æˆ‘çœ‹åˆ°æ‚¨åº”è˜çš„æ˜¯{target_position}èŒä½ï¼Œè®©æˆ‘ä»¬å¼€å§‹é¢è¯•å§ï¼"
    
    def _analyze_resume_basic(self, resume_data: Dict, target_position: str) -> Dict:
        """åŸºç¡€ç®€å†åˆ†æ"""
        try:
            basic_info = resume_data.get("basic_info", {})
            education = resume_data.get("education", {})
            projects = resume_data.get("projects", [])
            skills = resume_data.get("skills", {})
            
            # è®¡ç®—å®Œæ•´åº¦
            required_fields = ["name", "phone", "email"]
            completed_fields = [field for field in required_fields if basic_info.get(field)]
            completeness_score = len(completed_fields) / len(required_fields)
            missing_fields = [field for field in required_fields if field not in completed_fields]
            
            # æå–æŠ€èƒ½
            all_skills = []
            if isinstance(skills, dict):
                for skill_category in skills.values():
                    if isinstance(skill_category, str):
                        all_skills.extend(skill_category.split(','))
                    elif isinstance(skill_category, list):
                        all_skills.extend(skill_category)
            
            # ç»éªŒåˆ¤æ–­
            if not projects:
                experience_level = "fresh_graduate"
                years_estimated = 0
            elif len(projects) <= 2:
                experience_level = "junior"
                years_estimated = 1
            else:
                experience_level = "mid_level"
                years_estimated = 2
            
            return {
                "completeness_score": completeness_score,
                "missing_info": missing_fields,
                "technical_skills": all_skills[:10],  # é™åˆ¶æŠ€èƒ½æ•°é‡
                "experience_level": experience_level,
                "years_estimated": years_estimated,
                "project_count": len(projects),
                "education_background": education.get("school", "")
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ åŸºç¡€ç®€å†åˆ†æå¤±è´¥: {e}")
            return {
                "completeness_score": 0.5,
                "missing_info": [],
                "technical_skills": [],
                "experience_level": "unknown"
            }
    
    def _generate_welcome_from_resume(self, user_name: str, target_position: str, resume_data: Dict) -> str:
        """ä»ç®€å†ç”Ÿæˆæ¬¢è¿è¯­"""
        try:
            education = resume_data.get("education", {})
            projects = resume_data.get("projects", [])
            
            welcome_parts = [f"æ‚¨å¥½ {user_name}ï¼æˆ‘æ˜¯æ‚¨çš„AIé¢è¯•å®˜ï¼Œå¾ˆé«˜å…´è§åˆ°æ‚¨ã€‚"]
            
            # æåŠæ•™è‚²èƒŒæ™¯
            if education.get("school"):
                welcome_parts.append(f"æˆ‘çœ‹åˆ°æ‚¨æ¥è‡ª{education['school']}")
                if education.get("major"):
                    welcome_parts.append(f"ï¼Œ{education['major']}ä¸“ä¸šçš„èƒŒæ™¯")
                welcome_parts.append("ã€‚")
            
            # æåŠé¡¹ç›®ç»å†
            if projects:
                welcome_parts.append(f"æ‚¨çš„{len(projects)}ä¸ªé¡¹ç›®ç»å†å¾ˆç²¾å½©")
                if projects[0].get("name"):
                    welcome_parts.append(f"ï¼Œç‰¹åˆ«æ˜¯ã€Š{projects[0]['name']}ã€‹é¡¹ç›®")
                welcome_parts.append("ã€‚")
            
            welcome_parts.append(f"ä½œä¸º{target_position}å€™é€‰äººï¼Œæˆ‘å¾ˆæœŸå¾…äº†è§£æ‚¨çš„æƒ³æ³•å’Œç»å†ã€‚è®©æˆ‘ä»¬å¼€å§‹ä»Šå¤©çš„äº¤æµå§ï¼")
            
            return "".join(welcome_parts)
            
        except Exception as e:
            logger.warning(f"âš ï¸ ä»ç®€å†ç”Ÿæˆæ¬¢è¿è¯­å¤±è´¥: {e}")
            return f"æ‚¨å¥½ {user_name}ï¼æˆ‘æ˜¯æ‚¨çš„AIé¢è¯•å®˜ï¼Œå¾ˆé«˜å…´è§åˆ°æ‚¨ã€‚æˆ‘çœ‹åˆ°æ‚¨åº”è˜çš„æ˜¯{target_position}èŒä½ï¼Œè®©æˆ‘ä»¬å¼€å§‹é¢è¯•å§ï¼"
    
    async def _call_resume_analysis_api(self, user_name: str, target_position: str, 
                                      target_field: str, resume_data: Optional[Dict]) -> Dict:
        """è°ƒç”¨æ™ºèƒ½ç®€å†åˆ†æAPI"""
        try:
            async with aiohttp.ClientSession() as session:
                request_data = {
                    "user_name": user_name,
                    "target_position": target_position,
                    "target_field": target_field,
                    "resume_data": resume_data
                }
                
                async with session.post(
                    "http://localhost:8000/api/v1/resume/analyze-profile",
                    json=request_data
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        logger.info(f"âœ… æ™ºèƒ½ç®€å†åˆ†ææˆåŠŸ: {user_name}")
                        return result
                    else:
                        error_text = await response.text()
                        logger.error(f"âŒ æ™ºèƒ½ç®€å†åˆ†æå¤±è´¥: HTTP {response.status} - {error_text}")
                        return {"success": False, "error": f"HTTP {response.status}"}
                        
        except Exception as e:
            logger.error(f"âŒ è°ƒç”¨æ™ºèƒ½ç®€å†åˆ†æAPIå¼‚å¸¸: {e}")
            return {"success": False, "error": str(e)}
    
    async def _call_interview_decision_api(self, user_name: str, target_position: str,
                                         user_emotion: str, completeness_score: float,
                                         missing_info: List[str], formal_interview_started: bool,
                                         question_count: int, latest_user_message: str = "") -> Dict:
        """è°ƒç”¨æ™ºèƒ½é¢è¯•å†³ç­–API"""
        try:
            async with aiohttp.ClientSession() as session:
                request_data = {
                    "user_name": user_name,
                    "target_position": target_position,
                    "user_emotion": user_emotion,
                    "completeness_score": completeness_score,
                    "missing_info": missing_info,
                    "formal_interview_started": formal_interview_started,
                    "question_count": question_count,
                    "latest_user_message": latest_user_message
                }
                
                async with session.post(
                    "http://localhost:8000/api/v1/resume/interview-decision",
                    json=request_data
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        logger.info(f"âœ… æ™ºèƒ½å†³ç­–æˆåŠŸ: {result.get('action_type')} for {user_name}")
                        return result
                    else:
                        error_text = await response.text()
                        logger.error(f"âŒ æ™ºèƒ½å†³ç­–å¤±è´¥: HTTP {response.status} - {error_text}")
                        return {"success": False, "error": f"HTTP {response.status}"}
                        
        except Exception as e:
            logger.error(f"âŒ è°ƒç”¨æ™ºèƒ½å†³ç­–APIå¼‚å¸¸: {e}")
            return {"success": False, "error": str(e)}
    

    

    

    
    # ä¸ªæ€§åŒ–æ¬¢è¿æ¶ˆæ¯ç”Ÿæˆå·²ç§»è‡³æ™ºèƒ½APIï¼Œç®€åŒ–ä»£ç 
    
    # ==================== ç®€åŒ–çš„è¾…åŠ©æ–¹æ³• ====================
    
    async def _analyze_emotion(self, message: str) -> str:
        """åˆ†æç”¨æˆ·æƒ…ç»ª - ç®€åŒ–å®ç°"""
        if not message:
            return "neutral"
            
        message_lower = message.lower()
        
        # åŸºäºå…³é”®è¯çš„æƒ…æ„Ÿåˆ†æ
        if any(word in message_lower for word in ["ç´§å¼ ", "æ‹…å¿ƒ", "å®³æ€•", "ç„¦è™‘", "ä¸å®‰"]):
            return "anxious"
        elif any(word in message_lower for word in ["å…´å¥‹", "æœŸå¾…", "è‡ªä¿¡", "é«˜å…´", "æ²¡é—®é¢˜"]):
            return "confident"
        elif any(word in message_lower for word in ["å›°æƒ‘", "ä¸æ‡‚", "ä¸æ¸…æ¥š", "ä¸æ˜ç™½"]):
            return "confused"
        else:
            return "neutral"
    

    

    

    
    # ç®€åŒ–çš„è¾…åŠ©æ–¹æ³•å·²ç§»é™¤ï¼Œç°åœ¨ä¸»è¦é€šè¿‡æ™ºèƒ½APIå’Œå¤§æ¨¡å‹ç”Ÿæˆå†…å®¹
    
    # ==================== æ™ºèƒ½APIé›†æˆ ====================
    # å·¥å…·æ–¹æ³•å·²ç§»é™¤ï¼Œç°åœ¨é€šè¿‡æ™ºèƒ½APIå’ŒLangGraphå·¥ä½œæµç»Ÿä¸€å¤„ç†
    
    # ç§»é™¤å¤æ‚çš„æ•°æ®åº“æ–¹æ³• - Redisç¼“å­˜ç®¡ç†å™¨å·²ç»å¤„ç†äº†æ‰€æœ‰æŒä¹…åŒ–éœ€æ±‚
    
    def clear_session_state(self, session_id: str):
        """æ¸…ç†ä¼šè¯çŠ¶æ€ç¼“å­˜ï¼ˆä½¿ç”¨Redisï¼‰"""
        result = clear_session_cache(session_id)
        logger.info(f"ğŸ§¹ å·²æ¸…ç†Redisä¼šè¯çŠ¶æ€: {session_id} -> {result}")
        return result
    
    def clear_session_messages(self, session_id: str):
        """æ¸…ç†ä¼šè¯æ¶ˆæ¯å†å²ï¼ˆSQLiteï¼‰"""
        result = clear_session_messages(session_id)
        logger.info(f"ğŸ§¹ å·²æ¸…ç†SQLiteæ¶ˆæ¯å†å²: {session_id} -> {result}")
        return result
    
    def get_session_messages(self, session_id: str, limit: int = None) -> List[Dict]:
        """è·å–ä¼šè¯çš„æ¶ˆæ¯å†å²ï¼ˆç”¨äºå‰ç«¯å±•ç¤ºï¼‰"""
        try:
            # è·å–æ¶ˆæ¯å†å²
            messages = get_conversation_context(session_id, max_messages=limit or 50)
            
            # è½¬æ¢ä¸ºå‰ç«¯å‹å¥½çš„æ ¼å¼
            formatted_messages = []
            for msg in messages:
                if isinstance(msg, SystemMessage):
                    # ç³»ç»Ÿæ¶ˆæ¯é€šå¸¸ä¸æ˜¾ç¤ºç»™ç”¨æˆ·
                    continue
                elif isinstance(msg, HumanMessage):
                    formatted_messages.append({
                        "role": "user",
                        "content": msg.content,
                        "timestamp": datetime.now().isoformat()  # SQLiteæ²¡æœ‰è‡ªåŠ¨æ—¶é—´æˆ³ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
                    })
                elif isinstance(msg, AIMessage):
                    formatted_messages.append({
                        "role": "assistant", 
                        "content": msg.content,
                        "timestamp": datetime.now().isoformat()
                    })
            
            logger.debug(f"ğŸ“– æ ¼å¼åŒ–æ¶ˆæ¯å†å²: {session_id} - {len(formatted_messages)}æ¡æ¶ˆæ¯")
            return formatted_messages
            
        except Exception as e:
            logger.error(f"âŒ è·å–ä¼šè¯æ¶ˆæ¯å¤±è´¥: {e}")
            return []
    
    def get_message_history_summary(self, session_id: str) -> Dict:
        """è·å–æ¶ˆæ¯å†å²æ‘˜è¦"""
        try:
            summary = self.message_history_manager.get_session_summary(session_id)
            logger.debug(f"ğŸ“Š æ¶ˆæ¯å†å²æ‘˜è¦: {session_id} - {summary}")
            return summary
        except Exception as e:
            logger.error(f"âŒ è·å–æ¶ˆæ¯æ‘˜è¦å¤±è´¥: {e}")
            return {"session_id": session_id, "error": str(e)}
    
    def get_session_count(self) -> int:
        """è·å–å½“å‰ç¼“å­˜çš„ä¼šè¯æ•°é‡"""
        return self.cache_manager.get_session_count()
    
    def get_cache_health(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜å¥åº·çŠ¶æ€"""
        return self.cache_manager.health_check()
    
    async def end_interview_and_generate_report(self, user_id: str, session_id: str, 
                                              user_name: str, target_position: str) -> Dict[str, Any]:
        """ç»“æŸé¢è¯•å¹¶ç”ŸæˆæŠ¥å‘Š"""
        try:
            logger.info(f"ğŸ å¼€å§‹ç»“æŸé¢è¯•æµç¨‹: {session_id}")
            
            # 1. ç”Ÿæˆé¢è¯•æ€»ç»“æ¶ˆæ¯
            summary_message = await self._generate_interview_summary_with_context(
                session_id, user_name, target_position
            )
            
            # 2. ä¿å­˜æ€»ç»“æ¶ˆæ¯åˆ°å†å²
            add_ai_message(session_id, summary_message)
            
            # 3. ç”Ÿæˆé¢è¯•æŠ¥å‘Š
            report_result = await self.generate_interview_report(
                user_id, session_id, user_name, target_position
            )
            
            # 4. æ›´æ–°RedisçŠ¶æ€ - æ ‡è®°é¢è¯•å·²ç»“æŸ
            set_interview_stage(session_id, True)  # å¯ä»¥è€ƒè™‘æ·»åŠ æ–°çš„çŠ¶æ€ç±»å‹
            
            return {
                "success": True,
                "summary_message": summary_message,
                "report_id": report_result.get("report_id"),
                "report_data": report_result.get("report_data")
            }
            
        except Exception as e:
            logger.error(f"âŒ ç»“æŸé¢è¯•æµç¨‹å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "summary_message": f"æ„Ÿè°¢{user_name}å‚åŠ é¢è¯•ï¼Œç”±äºæŠ€æœ¯é—®é¢˜æ— æ³•ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šã€‚"
            }
    
    async def generate_interview_report(self, user_id: str, session_id: str, 
                                      user_name: str, target_position: str) -> Dict[str, Any]:
        """åŸºäºä¼šè¯å†å²ç”Ÿæˆé¢è¯•æŠ¥å‘Š"""
        try:
            logger.info(f"ğŸ“Š å¼€å§‹ç”Ÿæˆé¢è¯•æŠ¥å‘Š: {session_id}")
            
            # 1. è·å–å®Œæ•´çš„ä¼šè¯å†å²
            conversation_history = get_conversation_context(session_id, max_messages=100)
            
            if len(conversation_history) < 2:
                return {
                    "success": False,
                    "error": "ä¼šè¯å†å²ä¸è¶³ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š"
                }
            
            # 2. ä½¿ç”¨å¤§æ¨¡å‹åˆ†æä¼šè¯å†å²ç”ŸæˆæŠ¥å‘Š
            report_data = await self._analyze_conversation_for_report(
                conversation_history, user_name, target_position
            )
            
            # 3. ç”ŸæˆæŠ¥å‘ŠIDå¹¶ä¿å­˜åˆ°æ•°æ®åº“
            report_id = f"report_{session_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # 4. ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“ï¼ˆä½¿ç”¨ç°æœ‰çš„æŒä¹…åŒ–ç³»ç»Ÿï¼‰
            await self._save_report_to_database(report_id, session_id, user_id, report_data)
            
            logger.info(f"âœ… é¢è¯•æŠ¥å‘Šç”Ÿæˆå®Œæˆ: {report_id}")
            
            return {
                "success": True,
                "report_id": report_id,
                "report_data": report_data
            }
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆé¢è¯•æŠ¥å‘Šå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _generate_interview_summary_with_context(self, session_id: str, user_name: str, target_position: str) -> str:
        """åŸºäºä¼šè¯ä¸Šä¸‹æ–‡ç”Ÿæˆé¢è¯•æ€»ç»“"""
        try:
            # è·å–ä¼šè¯å†å²
            conversation_history = get_conversation_context(session_id, max_messages=20)
            
            # æ„å»ºæ€»ç»“æç¤º
            summary_prompt = f"""ä½ æ˜¯ä¸€åä¸“ä¸šçš„é¢è¯•å®˜ï¼Œéœ€è¦ä¸º{user_name}çš„{target_position}é¢è¯•åšæ€»ç»“ã€‚

è¯·åŸºäºä»¥ä¸‹å¯¹è¯å†å²ï¼Œç”Ÿæˆä¸€ä¸ªä¸“ä¸šã€ç§¯æçš„é¢è¯•ç»“æŸè¯­ï¼ˆé™åˆ¶150å­—å†…ï¼‰ï¼š

è¦æ±‚ï¼š
1. æ„Ÿè°¢å€™é€‰äººçš„å‚ä¸
2. ç®€è¦æ€»ç»“é¢è¯•äº®ç‚¹
3. è¯´æ˜åç»­æµç¨‹
4. ç»™å‡ºç§¯ææ­£é¢çš„ç»“æŸè¯­

å¯¹è¯å†å²ï¼š
{self._format_conversation_for_summary(conversation_history)}

è¯·ç”Ÿæˆç®€æ´ã€ä¸“ä¸šçš„é¢è¯•ç»“æŸè¯­ï¼š"""
            
            # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆæ€»ç»“
            messages = [SystemMessage(content=summary_prompt)]
            chat_result = await self.model._agenerate(messages)
            summary = chat_result.generations[0].message.content
            
            logger.info(f"âœ… é¢è¯•æ€»ç»“ç”ŸæˆæˆåŠŸ: {summary[:50]}...")
            return summary
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆé¢è¯•æ€»ç»“å¤±è´¥: {e}")
            # é™çº§åˆ°ç®€å•æ€»ç»“
            return f"æ„Ÿè°¢{user_name}å‚åŠ ä»Šå¤©çš„{target_position}é¢è¯•ï¼æ‚¨çš„è¡¨ç°å¾ˆå‡ºè‰²ï¼Œæˆ‘ä»¬ä¼šåœ¨3ä¸ªå·¥ä½œæ—¥å†…ç»™æ‚¨åé¦ˆã€‚ç¥æ‚¨æ±‚èŒé¡ºåˆ©ï¼"
    
    async def _analyze_conversation_for_report(self, conversation_history: List, user_name: str, target_position: str) -> Dict[str, Any]:
        """ä½¿ç”¨å¤§æ¨¡å‹åˆ†æä¼šè¯å†å²ç”ŸæˆæŠ¥å‘Šæ•°æ®"""
        try:
            # æ„å»ºåˆ†ææç¤º
            analysis_prompt = f"""ä½ æ˜¯ä¸€åèµ„æ·±çš„HRä¸“å®¶å’Œé¢è¯•å®˜ï¼Œéœ€è¦åŸºäºé¢è¯•å¯¹è¯ç”Ÿæˆè¯¦ç»†çš„é¢è¯•è¯„ä¼°æŠ¥å‘Šã€‚

å€™é€‰äººä¿¡æ¯ï¼š
- å§“åï¼š{user_name}  
- åº”è˜èŒä½ï¼š{target_position}

é¢è¯•å¯¹è¯å†å²ï¼š
{self._format_conversation_for_analysis(conversation_history)}

**é‡è¦è¦æ±‚ï¼š**
1. è¯·ä¸¥æ ¼åŸºäºé¢è¯•å¯¹è¯å†…å®¹è¿›è¡ŒçœŸå®è¯„ä¼°ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•é¢„è®¾å€¼
2. æ‰€æœ‰è¯„åˆ†å¿…é¡»å®¢è§‚åæ˜ å€™é€‰äººçš„å®é™…è¡¨ç°
3. åªè¿”å›JSONæ ¼å¼æ•°æ®ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—
4. å¦‚æœæŸé¡¹èƒ½åŠ›åœ¨å¯¹è¯ä¸­æœªä½“ç°ï¼Œç»™äºˆåˆç†çš„ä¸­æ€§è¯„åˆ†

è¯·åˆ†æé¢è¯•å¯¹è¯ï¼Œè¿”å›æ ‡å‡†JSONæ ¼å¼çš„è¯„ä¼°æŠ¥å‘Šï¼š

{{
    "basic_info": {{
        "candidate_name": "å€™é€‰äººå§“å",
        "position": "åº”è˜èŒä½",
        "interview_time": "é¢è¯•æ—¶é—´(YYYY-MM-DD HH:MMæ ¼å¼)",
        "duration_minutes": "é¢è¯•æ—¶é•¿(æ ¹æ®å¯¹è¯è½®æ•°ä¼°ç®—ï¼Œä¸€èˆ¬15-60åˆ†é’Ÿ)",
        "overall_grade": "ç»¼åˆç­‰çº§(Aä¼˜ç§€/Bè‰¯å¥½/Cä¸­ç­‰/Då¾…æå‡)",
        "overall_score": "æ€»åˆ†(0-100åˆ†ï¼ŒåŸºäºå„é¡¹èƒ½åŠ›ç»¼åˆè®¡ç®—)"
    }},
    "core_competencies": {{
        "overall_score": "æ€»åˆ†(ä¸basic_infoä¸­çš„overall_scoreä¸€è‡´)",
        "detailed_scores": {{
            "professional_knowledge": {{
                "score": "ä¸“ä¸šçŸ¥è¯†è¯„åˆ†(0-100)",
                "level": "èƒ½åŠ›ç­‰çº§(ä¼˜ç§€/è‰¯å¥½/ä¸­ç­‰/å¾…æå‡)",
                "description": "åŸºäºå¯¹è¯å†…å®¹çš„å…·ä½“è¯„ä»·"
            }},
            "skill_matching": {{
                "score": "æŠ€èƒ½åŒ¹é…åº¦è¯„åˆ†(0-100)",
                "level": "åŒ¹é…ç¨‹åº¦ç­‰çº§",
                "description": "æŠ€èƒ½ä¸ç›®æ ‡èŒä½çš„åŒ¹é…åº¦è¯„ä»·"
            }},
            "language_expression": {{
                "score": "è¯­è¨€è¡¨è¾¾èƒ½åŠ›è¯„åˆ†(0-100)",
                "level": "è¡¨è¾¾èƒ½åŠ›ç­‰çº§",
                "description": "è¯­è¨€è¡¨è¾¾ã€é€»è¾‘æ€§ã€æ¡ç†æ€§è¯„ä»·"
            }},
            "logical_thinking": {{
                "score": "é€»è¾‘æ€ç»´èƒ½åŠ›è¯„åˆ†(0-100)",
                "level": "æ€ç»´èƒ½åŠ›ç­‰çº§",
                "description": "åˆ†æé—®é¢˜ã€é€»è¾‘æ¨ç†èƒ½åŠ›è¯„ä»·"
            }},
            "innovation_ability": {{
                "score": "åˆ›æ–°èƒ½åŠ›è¯„åˆ†(0-100)",
                "level": "åˆ›æ–°èƒ½åŠ›ç­‰çº§",
                "description": "åˆ›æ–°æ€ç»´ã€è§£å†³é—®é¢˜èƒ½åŠ›è¯„ä»·"
            }},
            "stress_resistance": {{
                "score": "åº”å˜æŠ—å‹èƒ½åŠ›è¯„åˆ†(0-100)",
                "level": "æŠ—å‹èƒ½åŠ›ç­‰çº§",
                "description": "é¢è¯•è¡¨ç°ç¨³å®šæ€§ã€åº”å˜èƒ½åŠ›è¯„ä»·"
            }}
        }}
    }},
    "strengths_weaknesses": {{
        "strengths": [
            {{
                "title": "ä¼˜åŠ¿èƒ½åŠ›æ ‡é¢˜",
                "description": "åŸºäºå¯¹è¯å†…å®¹çš„è¯¦ç»†ä¼˜åŠ¿æè¿°"
            }}
        ],
        "weaknesses": [
            {{
                "title": "å¾…æå‡èƒ½åŠ›æ ‡é¢˜",
                "description": "åŸºäºå¯¹è¯å†…å®¹çš„å…·ä½“æ”¹è¿›å»ºè®®"
            }}
        ]
    }},
    "improvement_suggestions": {{
        "learning_resources": [
            {{
                "title": "å­¦ä¹ èµ„æºæ ‡é¢˜",
                "description": "å…·ä½“çš„å­¦ä¹ èµ„æºæè¿°",
                "type": "èµ„æºç±»å‹(book/video/course/platform)"
            }}
        ],
        "improvement_methods": [
            {{
                "title": "æå‡æ–¹æ³•æ ‡é¢˜",
                "description": "å…·ä½“çš„èƒ½åŠ›æå‡æ–¹æ³•å»ºè®®"
            }}
        ],
        "learning_path": [
            {{
                "stage": "å­¦ä¹ é˜¶æ®µåºå·(1,2,3...)",
                "title": "å­¦ä¹ é˜¶æ®µæ ‡é¢˜",
                "duration": "å»ºè®®å­¦ä¹ æ—¶é•¿(å¦‚: 2-4å‘¨, 1ä¸ªæœˆ)",
                "description": "è¯¥é˜¶æ®µçš„å…·ä½“å­¦ä¹ å†…å®¹å’Œç›®æ ‡"
            }}
        ]
    }},
    "related_assessments": [
        {{
            "title": "ç›¸å…³æµ‹è¯„æ ‡é¢˜",
            "description": "æµ‹è¯„å†…å®¹æè¿°",
            "url": "./assessment-options.html",
            "rating": "æ¨èæ˜Ÿçº§(1-5)",
            "duration_minutes": "é¢„è®¡ç”¨æ—¶(åˆ†é’Ÿ)"
        }}
    ]
}}

**è¯·åŸºäºçœŸå®é¢è¯•å¯¹è¯è¿›è¡Œå®¢è§‚è¯„ä¼°ï¼Œæ‰€æœ‰æ•°å€¼å’Œè¯„ä»·éƒ½å¿…é¡»æœ‰æ ¹æ®ã€‚ç›´æ¥è¿”å›JSONæ•°æ®ï¼š**"""
            
            # è°ƒç”¨å¤§æ¨¡å‹åˆ†æ
            messages = [SystemMessage(content=analysis_prompt)]
            chat_result = await self.model._agenerate(messages)
            analysis_result = chat_result.generations[0].message.content
            
            # è°ƒè¯•è¾“å‡ºï¼šæ‰“å°å¤§æ¨¡å‹åŸå§‹è¿”å›å†…å®¹
            logger.info(f"ğŸ” å¤§æ¨¡å‹åŸå§‹è¿”å›å†…å®¹:")
            logger.info("=" * 50)
            logger.info(analysis_result)
            logger.info("=" * 50)
            
            # å°è¯•æ¸…ç†å’Œè§£æJSON
            try:
                # å°è¯•æå–JSONéƒ¨åˆ†ï¼ˆå¯èƒ½åŒ…å«å…¶ä»–æ–‡æœ¬ï¼‰
                cleaned_result = self._extract_json_from_text(analysis_result)
                if cleaned_result:
                    report_data = json.loads(cleaned_result)
                    logger.info("âœ… å¤§æ¨¡å‹æŠ¥å‘Šåˆ†ææˆåŠŸ")
                    return report_data
                else:
                    raise json.JSONDecodeError("æ— æ³•æå–æœ‰æ•ˆJSON", analysis_result, 0)
                
            except json.JSONDecodeError as e:
                logger.warning(f"âš ï¸ å¤§æ¨¡å‹è¿”å›éJSONæ ¼å¼ï¼ŒJSONè§£æé”™è¯¯: {e}")
                logger.warning(f"ğŸ“ åŸå§‹è¿”å›å†…å®¹ï¼ˆå‰200å­—ç¬¦ï¼‰: {analysis_result[:200]}...")
                # é™çº§åˆ°ç®€åŒ–æŠ¥å‘Š
                return self._generate_fallback_report(user_name, target_position, len(conversation_history))
                
        except Exception as e:
            logger.error(f"âŒ å¤§æ¨¡å‹åˆ†æå¤±è´¥: {e}")
            # é™çº§åˆ°ç®€åŒ–æŠ¥å‘Š
            return self._generate_fallback_report(user_name, target_position, len(conversation_history))
    
    def _format_conversation_for_summary(self, conversation_history: List) -> str:
        """æ ¼å¼åŒ–å¯¹è¯å†å²ç”¨äºæ€»ç»“"""
        formatted_lines = []
        for msg in conversation_history[-10:]:  # åªä½¿ç”¨æœ€è¿‘10æ¡æ¶ˆæ¯
            if isinstance(msg, HumanMessage):
                formatted_lines.append(f"å€™é€‰äºº: {msg.content}")
            elif isinstance(msg, AIMessage):
                formatted_lines.append(f"é¢è¯•å®˜: {msg.content}")
        
        return "\n".join(formatted_lines)
    
    def _format_conversation_for_analysis(self, conversation_history: List) -> str:
        """æ ¼å¼åŒ–å¯¹è¯å†å²ç”¨äºåˆ†æ"""
        formatted_lines = []
        for i, msg in enumerate(conversation_history):
            if isinstance(msg, HumanMessage):
                formatted_lines.append(f"Q{(i//2)+1} å€™é€‰äººå›ç­”: {msg.content}")
            elif isinstance(msg, AIMessage):
                formatted_lines.append(f"Q{(i//2)+1} é¢è¯•å®˜æé—®: {msg.content}")
        
        return "\n".join(formatted_lines)
    
    def _extract_json_from_text(self, text: str) -> Optional[str]:
        """ä»æ–‡æœ¬ä¸­æå–JSONéƒ¨åˆ†"""
        try:
            # æ–¹æ³•1ï¼šæŸ¥æ‰¾JSONä»£ç å—
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', text, re.DOTALL)
            if json_match:
                return json_match.group(1)
            
            # æ–¹æ³•2ï¼šæŸ¥æ‰¾å•ç‹¬çš„JSONä»£ç å—  
            json_match = re.search(r'```\s*(\{.*?\})\s*```', text, re.DOTALL)
            if json_match:
                return json_match.group(1)
            
            # æ–¹æ³•3ï¼šæŸ¥æ‰¾çº¯JSONï¼ˆä»¥{å¼€å¤´ï¼Œä»¥}ç»“å°¾ï¼‰
            json_match = re.search(r'(\{.*?\})', text, re.DOTALL)
            if json_match:
                potential_json = json_match.group(1)
                # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆJSON
                try:
                    json.loads(potential_json)
                    return potential_json
                except json.JSONDecodeError:
                    pass
            
            # æ–¹æ³•4ï¼šæŸ¥æ‰¾å¤šè¡ŒJSONï¼ˆæ›´å®½æ¾çš„æ¨¡å¼ï¼‰
            lines = text.split('\n')
            json_lines = []
            in_json = False
            brace_count = 0
            
            for line in lines:
                stripped = line.strip()
                if stripped.startswith('{') and not in_json:
                    in_json = True
                    brace_count = 0
                
                if in_json:
                    json_lines.append(line)
                    brace_count += stripped.count('{') - stripped.count('}')
                    
                    if brace_count == 0 and stripped.endswith('}'):
                        # JSONç»“æŸ
                        potential_json = '\n'.join(json_lines)
                        try:
                            json.loads(potential_json)
                            return potential_json
                        except json.JSONDecodeError:
                            json_lines = []
                            in_json = False
            
            return None
            
        except Exception as e:
            logger.warning(f"âš ï¸ JSONæå–å¤±è´¥: {e}")
            return None
    
    def _generate_fallback_report(self, user_name: str, target_position: str, message_count: int) -> Dict[str, Any]:
        """ç”Ÿæˆé™çº§ç‰ˆæœ¬çš„æŠ¥å‘Š - åŸºäºåŸºç¡€æ•°æ®çš„çœŸå®è¯„ä¼°"""
        
        # åŸºäºæ¶ˆæ¯æ•°é‡å’ŒèŒä½ç±»å‹çš„åŠ¨æ€è¯„ä¼°
        estimated_duration = max(15, min(60, message_count * 3))  # æ›´å‡†ç¡®çš„æ—¶é•¿ä¼°ç®—
        
        # åŸºäºé¢è¯•è½®æ•°çš„åŸºç¡€è¯„åˆ† (é¿å…å›ºå®šå€¼)
        base_score = min(85, max(60, 50 + message_count * 5))  # æ ¹æ®äº¤äº’æ¬¡æ•°åŠ¨æ€è¯„åˆ†
        
        # èŒä½ç›¸å…³çš„æŠ€èƒ½é‡ç‚¹è¯„ä¼°
        position_skills = {
            "ç®—æ³•å·¥ç¨‹å¸ˆ": {"professional_knowledge": 5, "logical_thinking": 5, "innovation_ability": 4},
            "å‰ç«¯å¼€å‘": {"professional_knowledge": 4, "language_expression": 4, "innovation_ability": 5},
            "åç«¯å¼€å‘": {"professional_knowledge": 5, "logical_thinking": 4, "stress_resistance": 4},
            "äº§å“ç»ç†": {"language_expression": 5, "logical_thinking": 4, "innovation_ability": 5}
        }
        
        skill_weights = position_skills.get(target_position, {
            "professional_knowledge": 4, "language_expression": 4, 
            "logical_thinking": 4, "innovation_ability": 3, 
            "skill_matching": 4, "stress_resistance": 4
        })
        
        # åŠ¨æ€ç”Ÿæˆå„é¡¹è¯„åˆ†
        scores = {}
        for skill, weight in skill_weights.items():
            # åŸºäºæƒé‡å’Œäº¤äº’è´¨é‡ç”Ÿæˆåˆ†æ•°
            score_variance = (weight - 3) * 3  # æƒé‡è¶Šé«˜ï¼Œåˆ†æ•°åå‘è¶Šé«˜
            scores[skill] = min(95, max(55, base_score + score_variance + (message_count % 10 - 5)))
        
        # ç¡®ä¿æ‰€æœ‰å…­é¡¹èƒ½åŠ›éƒ½æœ‰è¯„åˆ†
        all_skills = ["professional_knowledge", "skill_matching", "language_expression", 
                     "logical_thinking", "innovation_ability", "stress_resistance"]
        
        for skill in all_skills:
            if skill not in scores:
                scores[skill] = base_score + (hash(user_name + skill) % 20 - 10)  # åŸºäºç”¨æˆ·åçš„ä¼ªéšæœºè°ƒæ•´
        
        # è®¡ç®—ç»¼åˆåˆ†æ•°
        overall_score = int(sum(scores.values()) / len(scores))
        overall_grade = "A" if overall_score >= 90 else "B" if overall_score >= 80 else "C" if overall_score >= 70 else "D"
        
        return {
            "basic_info": {
                "candidate_name": user_name,
                "position": target_position,
                "interview_time": datetime.now().strftime('%Y-%m-%d %H:%M'),
                "duration_minutes": estimated_duration,
                "overall_grade": overall_grade,
                "overall_score": overall_score
            },
            "core_competencies": {
                "overall_score": overall_score,
                "detailed_scores": {
                    "professional_knowledge": {
                        "score": int(scores["professional_knowledge"]), 
                        "level": self._get_level_by_score(scores["professional_knowledge"]),
                        "description": f"åœ¨{target_position}ç›¸å…³ä¸“ä¸šçŸ¥è¯†æ–¹é¢è¡¨ç°å‡ºä¸€å®šçš„ç†è§£å’Œåº”ç”¨èƒ½åŠ›"
                    },
                    "skill_matching": {
                        "score": int(scores["skill_matching"]), 
                        "level": self._get_level_by_score(scores["skill_matching"]),
                        "description": f"ä¸ªäººæŠ€èƒ½ä¸{target_position}èŒä½è¦æ±‚çš„åŒ¹é…ç¨‹åº¦"
                    },
                    "language_expression": {
                        "score": int(scores["language_expression"]), 
                        "level": self._get_level_by_score(scores["language_expression"]),
                        "description": "åœ¨é¢è¯•è¿‡ç¨‹ä¸­çš„è¯­è¨€è¡¨è¾¾æ¸…æ™°åº¦å’Œé€»è¾‘æ€§è¡¨ç°"
                    },
                    "logical_thinking": {
                        "score": int(scores["logical_thinking"]), 
                        "level": self._get_level_by_score(scores["logical_thinking"]),
                        "description": "åˆ†æé—®é¢˜å’Œé€»è¾‘æ¨ç†èƒ½åŠ›åœ¨å›ç­”ä¸­çš„ä½“ç°"
                    },
                    "innovation_ability": {
                        "score": int(scores["innovation_ability"]), 
                        "level": self._get_level_by_score(scores["innovation_ability"]),
                        "description": "åˆ›æ–°æ€ç»´å’Œè§£å†³é—®é¢˜çš„ç‹¬ç‰¹è§è§£"
                    },
                    "stress_resistance": {
                        "score": int(scores["stress_resistance"]), 
                        "level": self._get_level_by_score(scores["stress_resistance"]),
                        "description": "é¢è¯•è¿‡ç¨‹ä¸­çš„ç¨³å®šæ€§å’Œåº”å˜èƒ½åŠ›è¡¨ç°"
                    }
                }
            },
            "strengths_weaknesses": {
                "strengths": [
                    {"title": "ç§¯æå‚ä¸", "description": f"åœ¨é¢è¯•è¿‡ç¨‹ä¸­å±•ç°å‡ºè‰¯å¥½çš„æ²Ÿé€šæ„æ„¿å’Œ{target_position}ç›¸å…³çš„ä¸“ä¸šç´ å…»"},
                    {"title": "è¡¨è¾¾æ¸…æ™°", "description": "èƒ½å¤Ÿæœ‰æ¡ç†åœ°ç»„ç»‡è¯­è¨€ï¼Œå›ç­”é—®é¢˜æ—¶é€»è¾‘ç›¸å¯¹æ¸…æ¥š"}
                ],
                "weaknesses": [
                    {"title": "æ·±åº¦å±•ç¤º", "description": "å»ºè®®åœ¨å›ç­”æ—¶æä¾›æ›´å¤šå…·ä½“æ¡ˆä¾‹å’ŒæŠ€æœ¯ç»†èŠ‚ï¼Œå¢å¼ºè¯´æœåŠ›"},
                    {"title": "ç»“æ„åŒ–è¡¨è¾¾", "description": "å¯ä»¥å°è¯•ä½¿ç”¨STARæ³•åˆ™ç­‰ç»“æ„åŒ–æ–¹æ³•æ¥ç»„ç»‡å›ç­”"}
                ]
            },
            "improvement_suggestions": {
                "learning_resources": [
                    {"title": f"{target_position}ä¸“ä¸šæŠ€èƒ½æå‡", "description": f"é’ˆå¯¹{target_position}å²—ä½çš„æ ¸å¿ƒæŠ€èƒ½è¿›è¡Œç³»ç»Ÿå­¦ä¹ ", "type": "course"},
                    {"title": "é¢è¯•æŠ€å·§è®­ç»ƒ", "description": "å­¦ä¹ STARæ³•åˆ™ã€é—®é¢˜åˆ†ææ¡†æ¶ç­‰é¢è¯•è¡¨è¾¾æŠ€å·§", "type": "book"},
                    {"title": "è¡Œä¸šçŸ¥è¯†æ›´æ–°", "description": f"å…³æ³¨{target_position}é¢†åŸŸçš„æœ€æ–°å‘å±•è¶‹åŠ¿å’ŒæŠ€æœ¯åŠ¨æ€", "type": "platform"}
                ],
                "improvement_methods": [
                    {"title": "ç»“æ„åŒ–è¡¨è¾¾è®­ç»ƒ", "description": "ç»ƒä¹ ä½¿ç”¨STARæ³•åˆ™å’Œé‡‘å­—å¡”åŸç†ç»„ç»‡å›ç­”é€»è¾‘"},
                    {"title": "ä¸“ä¸šçŸ¥è¯†æ·±åŒ–", "description": f"åŠ å¼º{target_position}ç›¸å…³çš„æ ¸å¿ƒæŠ€èƒ½å’Œç†è®ºçŸ¥è¯†"},
                    {"title": "æ¨¡æ‹Ÿé¢è¯•ç»ƒä¹ ", "description": "å¤šå‚åŠ æ¨¡æ‹Ÿé¢è¯•ï¼Œæå‡å®æˆ˜ç»éªŒå’Œä¸´åœºåº”å˜èƒ½åŠ›"}
                ],
                "learning_path": [
                    {"stage": 1, "title": "åŸºç¡€æŠ€èƒ½å·©å›º", "duration": "2-4å‘¨", "description": f"é‡ç‚¹æå‡{target_position}çš„æ ¸å¿ƒä¸“ä¸šæŠ€èƒ½"},
                    {"stage": 2, "title": "è¡¨è¾¾èƒ½åŠ›ä¼˜åŒ–", "duration": "2-3å‘¨", "description": "ç»ƒä¹ ç»“æ„åŒ–è¡¨è¾¾å’Œé¢è¯•æŠ€å·§"},
                    {"stage": 3, "title": "å®æˆ˜èƒ½åŠ›æå‡", "duration": "æŒç»­è¿›è¡Œ", "description": "é€šè¿‡é¡¹ç›®å®è·µå’Œæ¨¡æ‹Ÿé¢è¯•æå‡ç»¼åˆèƒ½åŠ›"}
                ]
            },
            "related_assessments": [
                {"title": f"{target_position}æ·±åº¦æµ‹è¯„", "description": f"æ›´æ·±å…¥çš„{target_position}ä¸“ä¸šèƒ½åŠ›è¯„ä¼°", "url": "./technical-assessment-detail.html", "rating": 4, "duration_minutes": 60},
                {"title": "é€»è¾‘æ€ç»´æµ‹è¯•", "description": "è¯„ä¼°åˆ†æé—®é¢˜å’Œé€»è¾‘æ¨ç†èƒ½åŠ›", "url": "./logical-thinking-report.html", "rating": 4, "duration_minutes": 45},
                {"title": "æ²Ÿé€šåä½œè¯„ä¼°", "description": "è¯„ä¼°å›¢é˜Ÿåä½œå’Œæ²Ÿé€šè¡¨è¾¾èƒ½åŠ›", "url": "./communication-assessment.html", "rating": 3, "duration_minutes": 30}
            ]
        }
    
    def _get_level_by_score(self, score: float) -> str:
        """æ ¹æ®åˆ†æ•°è·å–ç­‰çº§"""
        if score >= 90:
            return "ä¼˜ç§€"
        elif score >= 80:
            return "è‰¯å¥½" 
        elif score >= 70:
            return "ä¸­ç­‰"
        else:
            return "å¾…æå‡"
    
    async def _save_report_to_database(self, report_id: str, session_id: str, user_id: str, report_data: Dict[str, Any]):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“"""
        try:
            # ä½¿ç”¨SessionManagerç›´æ¥ä¿å­˜æŠ¥å‘Š
            from src.database.session_manager import get_session_manager
            session_mgr = get_session_manager()
            
            success = session_mgr.save_report(report_id, session_id, user_id, report_data)
            if success:
                logger.info(f"ğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜åˆ°æ•°æ®åº“: {report_id}")
            else:
                logger.error(f"âŒ æŠ¥å‘Šä¿å­˜å¤±è´¥: {report_id}")
                
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“å¼‚å¸¸: {e}")
            # é™çº§åˆ°MCPå·¥å…·ä¿å­˜ï¼ˆå…¼å®¹æ€§ï¼‰
            try:
                if self.mcp_tool:
                    await self.mcp_tool.intelligent_info_collection(
                        user_id=user_id,
                        session_id=session_id,
                        conversation_history=[json.dumps({
                            "type": "interview_report",
                            "report_id": report_id,
                            "report_data": report_data,
                            "created_at": datetime.now().isoformat()
                        })]
                    )
                    logger.info(f"ğŸ’¾ æŠ¥å‘Šå·²é™çº§ä¿å­˜åˆ°MCP: {report_id}")
            except Exception as fallback_error:
                logger.error(f"âŒ MCPé™çº§ä¿å­˜ä¹Ÿå¤±è´¥: {fallback_error}")
    
    async def get_report_data(self, report_id: str) -> Optional[Dict[str, Any]]:
        """ä»æ•°æ®åº“è·å–æŠ¥å‘Šæ•°æ®"""
        try:
            # ä¼˜å…ˆä»SessionManagerè·å–
            from src.database.session_manager import get_session_manager
            session_mgr = get_session_manager()
            
            report = session_mgr.get_report(report_id)
            if report:
                logger.info(f"ğŸ“Š ä»æ•°æ®åº“è·å–æŠ¥å‘ŠæˆåŠŸ: {report_id}")
                return report["report_data"]
            
            logger.warning(f"âš ï¸ æŠ¥å‘Šä¸å­˜åœ¨äºæ•°æ®åº“: {report_id}")
            
            # é™çº§åˆ°MCPå·¥å…·æŸ¥è¯¢ï¼ˆå…¼å®¹æ€§ï¼‰
            if self.mcp_tool:
                try:
                    result = await self.mcp_tool.intelligent_info_collection(
                        user_id="",
                        session_id="",
                        conversation_history=[f"æŸ¥è¯¢æŠ¥å‘Š: {report_id}"]
                    )
                    
                    if result and isinstance(result, dict):
                        logger.info(f"ğŸ“Š ä»MCPè·å–æŠ¥å‘ŠæˆåŠŸ: {report_id}")
                        return result
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ MCPæŸ¥è¯¢ä¹Ÿå¤±è´¥: {e}")
                    
        except Exception as e:
            logger.error(f"âŒ è·å–æŠ¥å‘Šæ•°æ®å¼‚å¸¸: {e}")
        
        return None
    
    async def _generate_ai_response_with_llm(self, user_message: str, user_name: str, target_position: str,
                                           user_emotion: str, missing_info: List[str], 
                                           completeness_score: float, decision: Dict[str, Any], session_id: str) -> str:
        """ä½¿ç”¨çœŸå®æ˜Ÿç«å¤§æ¨¡å‹ç”Ÿæˆæ™ºèƒ½å›å¤"""
        try:
            # æ„å»ºæ™ºèƒ½çš„ç³»ç»Ÿæç¤º
            system_prompt = self._build_real_system_prompt(
                user_name, target_position, user_emotion, 
                missing_info, completeness_score, decision
            )
            
            # ä»LangChainæ¶ˆæ¯å†å²è·å–å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘10æ¡æ¶ˆæ¯ï¼‰
            conversation_context = get_conversation_context(session_id, max_messages=10)
            
            # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨ï¼šç³»ç»Ÿæç¤º + å¯¹è¯å†å²ä¸Šä¸‹æ–‡ + å½“å‰ç”¨æˆ·æ¶ˆæ¯
            messages = [SystemMessage(content=system_prompt)]
            
            # æ·»åŠ å†å²å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆæ’é™¤ç³»ç»Ÿæ¶ˆæ¯ï¼Œé¿å…é‡å¤ï¼‰
            context_messages = [msg for msg in conversation_context if not isinstance(msg, SystemMessage)]
            if context_messages:
                messages.extend(context_messages)
                logger.debug(f"ğŸ§  åŠ è½½å¯¹è¯ä¸Šä¸‹æ–‡: {len(context_messages)}æ¡å†å²æ¶ˆæ¯")
            
            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¦‚æœä¸åœ¨å†å²ä¸­ï¼‰
            if not context_messages or context_messages[-1].content != user_message:
                messages.append(HumanMessage(content=user_message))
            
            # è°ƒç”¨çœŸå®çš„æ˜Ÿç«ChatModel
            logger.info(f"ğŸ§  è°ƒç”¨æ˜Ÿç«å¤§æ¨¡å‹ï¼Œç­–ç•¥: {decision['action_type']}")
            chat_result = await self.model._agenerate(messages)
            
            # æå–AIå›å¤
            ai_message = chat_result.generations[0].message
            response = ai_message.content
            
            # ä½¿ç”¨å·¥å…·å¢å¼ºå›å¤ï¼ˆå¦‚æœéœ€è¦ï¼‰
            enhanced_response = await self._enhance_response_with_tools(
                response, decision, missing_info, user_name, target_position
            )
            
            logger.info(f"âœ… çœŸå®å¤§æ¨¡å‹å›å¤: {enhanced_response[:50]}...")
            return enhanced_response
            
        except Exception as e:
            logger.error(f"çœŸå®å¤§æ¨¡å‹ç”Ÿæˆå¤±è´¥ï¼Œé™çº§åˆ°ç®€åŒ–ç”Ÿæˆ: {e}")
            # é™çº§å¤„ç†
            if decision["action_type"] == "provide_emotional_support":
                return await self._generate_emotional_support_simple(user_emotion, user_name)
            elif decision["action_type"] == "collect_info":
                return await self._generate_info_question_simple(missing_info, user_name, target_position)
            elif decision["action_type"] == "end_interview":
                return self._generate_interview_summary_simple(user_name, target_position, completeness_score)
            else:
                return await self._generate_interview_question_simple(user_name, target_position)
    
    def _build_real_system_prompt(self, user_name: str, target_position: str, user_emotion: str,
                                missing_info: List[str], completeness_score: float, 
                                decision: Dict[str, Any]) -> str:
        """æ„å»ºçœŸå®å¤§æ¨¡å‹çš„ç³»ç»Ÿæç¤º"""
        action_type = decision.get("action_type", "conduct_interview")
        
        base_prompt = f"""ä½ æ˜¯ä¸€åèµ„æ·±çš„AIé¢è¯•å®˜ï¼Œæ­£åœ¨ä¸º{target_position}èŒä½è¿›è¡Œä¸“ä¸šé¢è¯•ã€‚

é¢è¯•å¯¹è±¡ï¼š{user_name}
ç›®æ ‡èŒä½ï¼š{target_position}
å½“å‰ç­–ç•¥ï¼š{action_type}

å€™é€‰äººçŠ¶æ€åˆ†æï¼š
- ä¿¡æ¯å®Œæ•´åº¦ï¼š{completeness_score:.1%}
- æƒ…ç»ªçŠ¶æ€ï¼š{user_emotion}
- ç¼ºå¤±ä¿¡æ¯ï¼š{missing_info}

**é‡è¦è§„åˆ™ï¼š**
1. å›å¤å¿…é¡»æ§åˆ¶åœ¨100å­—ä»¥å†…ï¼Œç®€æ´æ˜äº†
2. ä¸€æ¬¡åªé—®ä¸€ä¸ªé—®é¢˜
3. ä½¿ç”¨ä¸“ä¸šä½†å‹å¥½çš„è¯­è°ƒ
4. é¿å…å†—é•¿çš„è§£é‡Šå’Œé“ºå«

ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®å½“å‰ç­–ç•¥æä¾›ä¸“ä¸šã€ä¸ªæ€§åŒ–çš„å›å¤ã€‚

"""
        
        strategy_instructions = {
            "provide_emotional_support": f"""
å½“å‰ç­–ç•¥ï¼šæƒ…æ„Ÿæ”¯æŒï¼ˆé™åˆ¶80å­—å†…ï¼‰
{user_name}æ˜¾ç¤ºå‡º{user_emotion}æƒ…ç»ªï¼Œè¯·ï¼š
1. ç®€æ´åœ°æä¾›æ¸©æš–ç†è§£çš„å›åº”
2. å¿«é€Ÿç¼“è§£ç´§å¼ æƒ…ç»ª
3. ä¸€å¥è¯é¼“åŠ±ï¼Œç„¶åç›´æ¥è¿‡æ¸¡åˆ°é¢è¯•å†…å®¹
ç¤ºä¾‹ï¼š"æˆ‘ç†è§£æ‚¨çš„ç´§å¼ ï¼Œè¿™å¾ˆæ­£å¸¸ã€‚è®©æˆ‘ä»¬æ”¾æ¾å¿ƒæƒ…ï¼Œä»ä¸€ä¸ªç®€å•é—®é¢˜å¼€å§‹å§ã€‚"
""",
            
            "collect_info": f"""
å½“å‰ç­–ç•¥ï¼šä¿¡æ¯æ”¶é›†ï¼ˆé™åˆ¶60å­—å†…ï¼‰
{user_name}çš„ä¿¡æ¯ä¸å®Œæ•´ï¼ˆç¼ºå¤±ï¼š{missing_info}ï¼‰ï¼Œè¯·ï¼š
1. ç›´æ¥è¯¢é—®ä¸€ä¸ªç¼ºå¤±çš„å…³é”®ä¿¡æ¯
2. è¯­è¨€ç®€æ´ï¼Œé¿å…è§£é‡Šè¿‡å¤š
3. ä¸€æ¬¡åªé—®ä¸€ä¸ªå…·ä½“é—®é¢˜
ç¤ºä¾‹ï¼š"è¯·é—®æ‚¨æœ‰å¤šå°‘å¹´ç›¸å…³å·¥ä½œç»éªŒï¼Ÿ" æˆ– "æ‚¨çš„æœ€é«˜å­¦å†æ˜¯ï¼Ÿ"
""",
            
            "conduct_interview": f"""
å½“å‰ç­–ç•¥ï¼šæ­£å¸¸é¢è¯•ï¼ˆé™åˆ¶80å­—å†…ï¼‰
{user_name}çš„ä¿¡æ¯ç›¸å¯¹å®Œæ•´ï¼Œè¯·è¿›è¡Œä¸“ä¸šé¢è¯•ï¼š
1. æå‡ºä¸€ä¸ªå…·ä½“ã€æœ‰é’ˆå¯¹æ€§çš„é—®é¢˜
2. é—®é¢˜è¦æœ‰æ·±åº¦ä½†è¡¨è¿°ç®€æ´
3. å¯é€‚å½“ä½¿ç”¨STARåŸåˆ™å¼•å¯¼
ç¤ºä¾‹ï¼š"è¯·ç®€è¿°æ‚¨æœ€æœ‰æˆå°±æ„Ÿçš„é¡¹ç›®åŠæ‚¨çš„å…·ä½“è´¡çŒ®ï¼Ÿ"
""",
            
            "end_interview": f"""
å½“å‰ç­–ç•¥ï¼šç»“æŸé¢è¯•ï¼ˆé™åˆ¶100å­—å†…ï¼‰
å·²æ”¶é›†{user_name}çš„è¶³å¤Ÿä¿¡æ¯ï¼Œè¯·ï¼š
1. ç®€æ´æ„Ÿè°¢å€™é€‰äººå‚ä¸
2. ä¸€å¥è¯æ€»ç»“äº®ç‚¹
3. è¯´æ˜åç»­æµç¨‹
ç¤ºä¾‹ï¼š"æ„Ÿè°¢æ‚¨çš„åˆ†äº«ï¼æ‚¨åœ¨é¡¹ç›®ç®¡ç†æ–¹é¢çš„ç»éªŒå¾ˆå‡ºè‰²ã€‚æˆ‘ä»¬ä¼šåœ¨3ä¸ªå·¥ä½œæ—¥å†…ç»™æ‚¨åé¦ˆã€‚"
"""
        }
        
        instruction = strategy_instructions.get(action_type, "è¯·è¿›è¡Œä¸“ä¸šçš„é¢è¯•å¯¹è¯ã€‚")
        return base_prompt + instruction
    
    async def _enhance_response_with_tools(self, response: str, decision: Dict[str, Any], 
                                         missing_info: List[str], user_name: str, 
                                         target_position: str) -> str:
        """ä½¿ç”¨å·¥å…·å¢å¼ºAIå›å¤"""
        try:
            action_type = decision.get("action_type", "conduct_interview")
            
            # æ ¹æ®ç­–ç•¥ä½¿ç”¨ä¸åŒçš„å·¥å…·å¢å¼º
            if action_type == "provide_emotional_support":
                support_tool = next((tool for tool in interview_tools if tool.name == "provide_emotional_support"), None)
                if support_tool:
                    enhanced = await support_tool._arun(
                        base_response=response,
                        user_name=user_name,
                        emotion=decision.get("emotion", "neutral")
                    )
                    if enhanced:
                        return enhanced
            
            elif action_type == "collect_info" and missing_info:
                question_tool = next((tool for tool in interview_tools if tool.name == "generate_missing_info_question"), None)
                if question_tool:
                    enhanced = await question_tool._arun(
                        base_response=response,
                        missing_fields=missing_info[:1],  # åªå¤„ç†ç¬¬ä¸€ä¸ªç¼ºå¤±å­—æ®µ
                        target_position=target_position,
                        user_name=user_name
                    )
                    if enhanced:
                        return enhanced
            
            return response
            
        except Exception as e:
            logger.warning(f"å·¥å…·å¢å¼ºå¤±è´¥: {e}")
            return response


# åˆ›å»ºå…¨å±€å®ä¾‹ - ä½¿ç”¨try-catchç¡®ä¿ä¸ä¼šå› ä¸ºåˆå§‹åŒ–å¤±è´¥è€Œå´©æºƒ
_global_agent = None

def get_langgraph_agent():
    """è·å–LangGraphæ™ºèƒ½ä½“å®ä¾‹ï¼Œå»¶è¿Ÿåˆå§‹åŒ–"""
    global _global_agent
    
    if _global_agent is None:
        try:
            _global_agent = LangGraphInterviewAgent()
            logger.info("âœ… å…¨å±€LangGraphæ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ å…¨å±€æ™ºèƒ½ä½“åˆ›å»ºå¤±è´¥: {e}")
            _global_agent = False  # æ ‡è®°ä¸ºå¤±è´¥
    
    return _global_agent if _global_agent is not False else None

# å‘åå…¼å®¹çš„å…¨å±€å˜é‡
langgraph_agent = get_langgraph_agent()
