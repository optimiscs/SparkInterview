# -*- encoding:utf-8 -*-
"""
è®¯é£å®æ—¶è¯­éŸ³è¯†åˆ«ä»£ç†æœåŠ¡
åŸºäºWebSocketå®ç°å‰åç«¯è¯­éŸ³è¯†åˆ«é›†æˆ

éŸ³é¢‘è°ƒè¯•åŠŸèƒ½ï¼š
- è‡ªåŠ¨ä¿å­˜å‘é€ç»™è®¯é£çš„éŸ³é¢‘æµåˆ° data/debug_audio/ ç›®å½•
- æ”¯æŒPCMåŸå§‹æ ¼å¼å’ŒWAVæ ¼å¼
- ç”¨äºè°ƒè¯•è¯­éŸ³è¯†åˆ«æ¼å­—å’Œæœ«å°¾ç¼ºå­—é—®é¢˜

æ–‡ä»¶å‘½åæ ¼å¼ï¼š
- voice_debug_YYYYMMDD_HHMMSS_sessionid.pcm
- voice_debug_YYYYMMDD_HHMMSS_sessionid.wav
"""
import asyncio
import json
import logging
import hashlib
import hmac
import base64
import time
import os
from datetime import datetime
from typing import Dict, Optional, Any, List
from urllib.parse import quote
import websockets
from websockets.exceptions import ConnectionClosedError
from fastapi import APIRouter, WebSocket, WebSocketDisconnect, HTTPException, Depends
from fastapi.responses import JSONResponse

# éŸ³é¢‘å¤„ç†
try:
    import wave
    import audioop
    AUDIO_PROCESSING_AVAILABLE = True
except ImportError:
    AUDIO_PROCESSING_AVAILABLE = False
    logging.warning("éŸ³é¢‘å¤„ç†åº“ä¸å¯ç”¨ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½å—é™")

# LangGraphæ™ºèƒ½ä½“
from src.agents.langgraph_interview_agent import get_langgraph_agent

# è®¾ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)
# ä¸´æ—¶è®¾ç½®ä¸ºDEBUGçº§åˆ«ä»¥ä¾¿è°ƒè¯•è¯­éŸ³è¯†åˆ«é—®é¢˜
logger.setLevel(logging.DEBUG)

# éŸ³é¢‘åˆ†æå·¥å…·
try:
    import librosa
    import numpy as np
    from src.tools.multimodal_analyzer import AudioAnalyzer, create_multimodal_analyzer
    LIBROSA_AVAILABLE = True
    logger.info("âœ… LibrosaéŸ³é¢‘åˆ†æåº“å¯ç”¨")
except ImportError as e:
    logger.warning(f"âš ï¸ LibrosaéŸ³é¢‘åˆ†æåº“ä¸å¯ç”¨: {e}")
    LIBROSA_AVAILABLE = False

# ä¼šè¯ç®¡ç†å’ŒLangGraphèŠå¤©
try:
    from api.routers.langgraph_chat import active_sessions
    from src.database.session_manager import get_session_manager
    LANGGRAPH_CHAT_AVAILABLE = True
except ImportError as e:
    logger.warning(f"âš ï¸ LangGraphèŠå¤©æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    LANGGRAPH_CHAT_AVAILABLE = False

# è·¯ç”±å™¨
router = APIRouter(tags=["è¯­éŸ³è¯†åˆ«"])

# è®¯é£RTASRé…ç½®
XUNFEI_CONFIG = {
    "app_id": "015076e9",
    "api_key": "771f2107c79630c900476ea1de65540b",
    "base_url": "ws://rtasr.xfyun.cn/v1/ws",
    "sample_rate": 16000,
    "encoding": "pcm"
}

class XunfeiVoiceProxy:
    """è®¯é£è¯­éŸ³è¯†åˆ«ä»£ç†"""
    
    def __init__(self):
        self.app_id = XUNFEI_CONFIG["app_id"]
        self.api_key = XUNFEI_CONFIG["api_key"]
        self.base_url = XUNFEI_CONFIG["base_url"]
        
        # è¿æ¥ç®¡ç†
        self.xunfei_ws = None
        self.client_ws = None
        self.is_connected = False
        
        # è¯†åˆ«ç»“æœ - å‚è€ƒdemoå®ç°éæµå¼ç´¯ç§¯
        self.final_result = []  # å­˜å‚¨æœ€ç»ˆç¡®è®¤çš„ç»“æœï¼ˆtype="0"ï¼‰
        self.temp_result = ""   # å­˜å‚¨ä¸´æ—¶ç»“æœï¼ˆtype="1"ï¼‰
        self.recognized_text = ""
        self.session_id = None
        
        # éŸ³é¢‘ä¿å­˜åŠŸèƒ½
        self.audio_buffer = bytearray()  # æ‹¼æ¥æ‰€æœ‰éŸ³é¢‘æ•°æ®
        self.save_audio = True  # æ˜¯å¦ä¿å­˜éŸ³é¢‘ï¼ˆå¯é…ç½®ï¼‰
        self.audio_saved_path = None  # ä¿å­˜çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        
        # å®æ—¶éŸ³é¢‘åˆ†æåŠŸèƒ½
        self.realtime_analysis_enabled = True  # æ˜¯å¦å¯ç”¨å®æ—¶åˆ†æ
        self.analysis_buffer = bytearray()  # åˆ†æç”¨çš„éŸ³é¢‘ç¼“å†²åŒº
        self.analysis_buffer_size = 16000 * 2  # 2ç§’çš„éŸ³é¢‘æ•°æ® (16kHz * 2å­—èŠ‚/æ ·æœ¬ * 2ç§’)
        self.last_analysis_time = 0
        self.analysis_interval = 1.0  # åˆ†æé—´éš”ï¼ˆç§’ï¼‰
        self.voice_tone_history = []  # è¯­è°ƒå†å²è®°å½•
        self.max_history_length = 60  # æœ€å¤šä¿å­˜60ä¸ªå†å²ç‚¹ï¼ˆ1åˆ†é’Ÿï¼‰
        
        # å»¶æ—¶ç›‘æ§
        self.last_audio_send_time = None  # æœ€åä¸€æ¬¡å‘é€éŸ³é¢‘çš„æ—¶é—´
        self.first_audio_send_time = None  # ç¬¬ä¸€æ¬¡å‘é€éŸ³é¢‘çš„æ—¶é—´  
        self.audio_send_count = 0  # å‘é€çš„éŸ³é¢‘åŒ…è®¡æ•°
        self.result_receive_count = 0  # æ¥æ”¶åˆ°çš„ç»“æœè®¡æ•°
        
        logger.info("ğŸ“ è®¯é£è¯­éŸ³ä»£ç†åˆå§‹åŒ–å®Œæˆ")
    
    async def connect_xunfei(self):
        """è¿æ¥è®¯é£RTASRæœåŠ¡"""
        try:
            # ç”Ÿæˆè®¤è¯å‚æ•°
            ts = str(int(time.time()))
            signa = self._generate_signature(ts)
            
            # æ„å»ºWebSocket URL
            ws_url = f"{self.base_url}?appid={self.app_id}&ts={ts}&signa={quote(signa)}"
            
            logger.info("ğŸ”— è¿æ¥è®¯é£RTASRæœåŠ¡...")
            self.xunfei_ws = await websockets.connect(ws_url)
            self.is_connected = True
            
            logger.info("âœ… è®¯é£RTASRè¿æ¥æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ è¿æ¥è®¯é£RTASRå¤±è´¥: {e}")
            self.is_connected = False
            return False
    
    def _generate_signature(self, ts: str) -> str:
        """ç”Ÿæˆè®¯é£APIç­¾å"""
        try:
            # æ„å»ºåŸºç¡€å­—ç¬¦ä¸²
            base_string = self.app_id + ts
            
            # MD5å“ˆå¸Œ
            md5_hash = hashlib.md5(base_string.encode('utf-8')).hexdigest()
            
            # HMAC-SHA1ç­¾å
            signature = hmac.new(
                self.api_key.encode('utf-8'),
                md5_hash.encode('utf-8'),
                hashlib.sha1
            ).digest()
            
            # Base64ç¼–ç 
            return base64.b64encode(signature).decode('utf-8')
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆç­¾åå¤±è´¥: {e}")
            raise
    
    async def send_audio_data(self, audio_data: bytes):
        """å‘é€éŸ³é¢‘æ•°æ®åˆ°è®¯é£"""
        if not self.is_connected or not self.xunfei_ws:
            return False
        
        try:
            # è®°å½•å‘é€æ—¶é—´ï¼ˆç”¨äºå»¶æ—¶ç›‘æ§ï¼‰
            current_time = time.time()
            self.last_audio_send_time = current_time
            if self.first_audio_send_time is None:
                self.first_audio_send_time = current_time
                logger.info("â±ï¸ å¼€å§‹éŸ³é¢‘å‘é€è®¡æ—¶")
            
            self.audio_send_count += 1
            
            # éŸ³é¢‘è´¨é‡æ£€æµ‹
            audio_energy = self._calculate_audio_energy(audio_data)
            is_silence = audio_energy < 1000  # é™éŸ³é˜ˆå€¼
            
            # å‘é€åˆ°è®¯é£
            await self.xunfei_ws.send(audio_data)
            
            # è¯¦ç»†çš„éŸ³é¢‘å‘é€æ—¥å¿—
            if is_silence:
                logger.debug(f"ğŸ“¤ å‘é€éŸ³é¢‘æ•°æ®: {len(audio_data)} bytes [åŒ…#{self.audio_send_count}] ğŸ”‡ é™éŸ³ (èƒ½é‡: {audio_energy:.1f})")
            else:
                logger.debug(f"ğŸ“¤ å‘é€éŸ³é¢‘æ•°æ®: {len(audio_data)} bytes [åŒ…#{self.audio_send_count}] ğŸ”Š æœ‰å£° (èƒ½é‡: {audio_energy:.1f})")
            
            # æ¯5åŒ…ç»Ÿè®¡ä¸€æ¬¡ï¼ˆå°åŒ…æ¨¡å¼éœ€è¦æ›´é¢‘ç¹ç»Ÿè®¡ï¼‰
            if self.audio_send_count % 5 == 0:
                total_duration = (current_time - self.first_audio_send_time)
                logger.info(f"ğŸ“Š éŸ³é¢‘å‘é€ç»Ÿè®¡ - åŒ…æ•°: {self.audio_send_count}, æ—¶é•¿: {total_duration:.1f}s, å¹³å‡: {len(audio_data)/1024:.1f}KB/åŒ…")
                logger.info(f"ğŸ¯ æœŸæœ›å®æ—¶è¯†åˆ« - å°åŒ…æ¨¡å¼åº”è¯¥æ¯0.5ç§’äº§ç”Ÿè¯†åˆ«ç»“æœ")
            
            # ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°ç¼“å†²åŒºï¼ˆç”¨äºè°ƒè¯•ï¼‰
            if self.save_audio:
                self.audio_buffer.extend(audio_data)
                logger.debug(f"ğŸ’¾ ç´¯ç§¯éŸ³é¢‘æ•°æ®: {len(self.audio_buffer)} bytes")
            
            # æ·»åŠ åˆ°å®æ—¶åˆ†æç¼“å†²åŒº
            if self.realtime_analysis_enabled:
                self.analysis_buffer.extend(audio_data)
                
                # ä¿æŒåˆ†æç¼“å†²åŒºå¤§å°é™åˆ¶
                if len(self.analysis_buffer) > self.analysis_buffer_size:
                    # ä¿ç•™æœ€æ–°çš„æ•°æ®
                    excess = len(self.analysis_buffer) - self.analysis_buffer_size
                    self.analysis_buffer = self.analysis_buffer[excess:]
                
                # æ‰§è¡Œå®æ—¶åˆ†æå¹¶å‘é€ç»“æœ
                analysis_result = self._perform_realtime_analysis()
                if analysis_result and self.client_ws:
                    try:
                        # å¼‚æ­¥å‘é€åˆ†æç»“æœåˆ°å‰ç«¯
                        asyncio.create_task(self._send_voice_analysis_result(analysis_result))
                    except Exception as e:
                        logger.warning(f"âš ï¸ å‘é€è¯­è°ƒåˆ†æç»“æœå¤±è´¥: {e}")
            
            return True
            
        except (ConnectionClosedError, websockets.exceptions.ConnectionClosed):
            # è¿æ¥å·²å…³é—­ï¼Œé™é»˜å¤„ç†
            self.is_connected = False
            return False
        except Exception as e:
            # å…¶ä»–é”™è¯¯ï¼Œè®°å½•ä¸€æ¬¡åæ ‡è®°è¿æ¥æ–­å¼€
            if "1000" not in str(e):
                logger.warning(f"âš ï¸ éŸ³é¢‘å‘é€å¤±è´¥: {e}")
            self.is_connected = False
            return False
    
    async def send_end_signal(self):
        """å‘é€è¯†åˆ«ç»“æŸä¿¡å·"""
        if not self.is_connected or not self.xunfei_ws:
            return
        
        try:
            end_signal = json.dumps({"end": True})
            await self.xunfei_ws.send(end_signal)
            logger.info("ğŸ å‘é€è¯†åˆ«ç»“æŸä¿¡å·")
            
        except Exception as e:
            logger.error(f"âŒ å‘é€ç»“æŸä¿¡å·å¤±è´¥: {e}")
    
    async def receive_recognition_result(self):
        """æ¥æ”¶è¯†åˆ«ç»“æœ"""
        if not self.is_connected or not self.xunfei_ws:
            logger.debug("âš ï¸ è¿æ¥å·²æ–­å¼€ï¼Œæ— æ³•æ¥æ”¶ç»“æœ")
            return None
        
        try:
            # æ·»åŠ æ¥æ”¶çŠ¶æ€æ—¥å¿—
            logger.debug("ğŸ§ ç­‰å¾…è®¯é£è¿”å›æ•°æ®...")
            result = await self.xunfei_ws.recv()
            logger.debug(f"ğŸ” è®¯é£åŸå§‹æ•°æ®: {result}")
            
            # å¤„ç†å¤šä¸ªJSONå¯¹è±¡è¿æ¥çš„æƒ…å†µ
            parsed_result = self._parse_multiple_json_results(result)
            if parsed_result:
                logger.debug(f"âœ… è§£ææˆåŠŸ: {parsed_result.get('result_type', 'unknown')} - '{parsed_result.get('text', '')[:20]}...'")
            else:
                logger.debug("âš ï¸ è§£æç»“æœä¸ºç©º")
            
            return parsed_result
            
        except (ConnectionClosedError, websockets.exceptions.ConnectionClosed):
            # è¿æ¥å…³é—­ï¼Œè®°å½•æ—¥å¿—
            logger.info("ğŸ”Œ è®¯é£WebSocketè¿æ¥å·²å…³é—­")
            self.is_connected = False
            return None
        except Exception as e:
            # å…¶ä»–é”™è¯¯ï¼Œè¯¦ç»†è®°å½•ä¾¿äºè°ƒè¯•
            logger.warning(f"âš ï¸ æ¥æ”¶è®¯é£ç»“æœå¼‚å¸¸: {type(e).__name__}: {e}")
            if "1000" not in str(e):
                logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {e}")
            self.is_connected = False
            return None
    

    
    async def close_connection(self):
        """å…³é—­è¿æ¥"""
        self.is_connected = False
        
        # æ‰“å°æœ€ç»ˆå»¶æ—¶ç»Ÿè®¡
        if self.first_audio_send_time and self.last_audio_send_time:
            total_session_time = (self.last_audio_send_time - self.first_audio_send_time) * 1000
            logger.info(f"ğŸ“Š ä¼šè¯å»¶æ—¶ç»Ÿè®¡æ€»ç»“ - æ€»æ—¶é•¿: {total_session_time:.1f}ms | éŸ³é¢‘åŒ…æ€»æ•°: {self.audio_send_count} | è¯†åˆ«ç»“æœæ€»æ•°: {self.result_receive_count}")
        
        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        if self.save_audio and len(self.audio_buffer) > 0:
            await self._save_audio_to_file()
        
        # é‡ç½®å»¶æ—¶ç›‘æ§çŠ¶æ€
        self.last_audio_send_time = None
        self.first_audio_send_time = None
        self.audio_send_count = 0
        self.result_receive_count = 0
        
        if self.xunfei_ws:
            try:
                await self.xunfei_ws.close()
                logger.info("ğŸ”Œ è®¯é£è¿æ¥å·²å…³é—­")
            except:
                pass
            self.xunfei_ws = None
    
    async def _save_audio_to_file(self):
        """ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            # åˆ›å»ºä¿å­˜ç›®å½•
            save_dir = "data/debug_audio"
            os.makedirs(save_dir, exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            session_suffix = self.session_id[:8] if self.session_id else "unknown"
            
            # ä¿å­˜ä¸ºPCMåŸå§‹æ–‡ä»¶
            pcm_filename = f"voice_debug_{timestamp}_{session_suffix}.pcm"
            pcm_path = os.path.join(save_dir, pcm_filename)
            
            with open(pcm_path, 'wb') as f:
                f.write(self.audio_buffer)
            
            self.audio_saved_path = pcm_path
            logger.info(f"ğŸ’¾ åŸå§‹éŸ³é¢‘å·²ä¿å­˜: {pcm_path} ({len(self.audio_buffer)} bytes)")
            
            # å¦‚æœæœ‰waveåº“ï¼ŒåŒæ—¶ä¿å­˜ä¸ºWAVæ–‡ä»¶ï¼ˆä¾¿äºæ’­æ”¾ï¼‰
            if AUDIO_PROCESSING_AVAILABLE:
                wav_filename = f"voice_debug_{timestamp}_{session_suffix}.wav"
                wav_path = os.path.join(save_dir, wav_filename)
                
                with wave.open(wav_path, 'wb') as wav_file:
                    wav_file.setnchannels(1)  # å•å£°é“
                    wav_file.setsampwidth(2)  # 16ä½
                    wav_file.setframerate(16000)  # 16kHz
                    wav_file.writeframes(self.audio_buffer)
                
                logger.info(f"ğŸµ WAVéŸ³é¢‘å·²ä¿å­˜: {wav_path}")
                
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
    
    def enable_audio_saving(self, enabled: bool = True):
        """å¯ç”¨/ç¦ç”¨éŸ³é¢‘ä¿å­˜åŠŸèƒ½"""
        self.save_audio = enabled
        if enabled:
            logger.info("ğŸ’¾ éŸ³é¢‘ä¿å­˜åŠŸèƒ½å·²å¯ç”¨")
        else:
            logger.info("ğŸš« éŸ³é¢‘ä¿å­˜åŠŸèƒ½å·²ç¦ç”¨")
    
    def get_audio_info(self) -> Dict[str, Any]:
        """è·å–éŸ³é¢‘ä¿å­˜ä¿¡æ¯"""
        return {
            "save_enabled": self.save_audio,
            "buffer_size": len(self.audio_buffer),
            "saved_path": self.audio_saved_path
        }
    
    def get_final_text(self) -> str:
        """è·å–æœ€ç»ˆè¯†åˆ«æ–‡æœ¬"""
        # è¿”å›æœ€ç»ˆç»“æœ + å½“å‰ä¸´æ—¶ç»“æœ
        full_text = ''.join(self.final_result) + self.temp_result
        return full_text.strip()
    
    def _parse_multiple_json_results(self, raw_data: str) -> Optional[Dict]:
        """è§£æå¤šä¸ªJSONå¯¹è±¡è¿æ¥çš„æ•°æ®"""
        if not raw_data or not raw_data.strip():
            return None
        
        logger.debug(f"ğŸ” å¤„ç†åŸå§‹æ•°æ®: {raw_data}")
        
        # åˆ†å‰²å¤šä¸ªJSONå¯¹è±¡
        json_objects = self._split_json_objects(raw_data)
        
        last_result = None
        for json_str in json_objects:
            if json_str.strip():
                result = self._parse_single_xunfei_result(json_str)
                if result:
                    last_result = result
        
        return last_result
    
    def _split_json_objects(self, data: str) -> list:
        """åˆ†å‰²è¿æ¥çš„JSONå¯¹è±¡"""
        json_objects = []
        current_obj = ""
        brace_count = 0
        in_string = False
        escape_next = False
        
        for char in data:
            current_obj += char
            
            if escape_next:
                escape_next = False
                continue
                
            if char == '\\':
                escape_next = True
                continue
                
            if char == '"' and not escape_next:
                in_string = not in_string
                continue
                
            if not in_string:
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    
                    # å½“å¤§æ‹¬å·å¹³è¡¡æ—¶ï¼Œè¡¨ç¤ºä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
                    if brace_count == 0:
                        json_objects.append(current_obj.strip())
                        current_obj = ""
        
        # å¤„ç†å‰©ä½™çš„ä¸å®Œæ•´å¯¹è±¡
        if current_obj.strip():
            json_objects.append(current_obj.strip())
        
        logger.debug(f"ğŸ” åˆ†å‰²å¾—åˆ° {len(json_objects)} ä¸ªJSONå¯¹è±¡")
        return json_objects
    
    def _parse_single_xunfei_result(self, json_str: str) -> Optional[Dict]:
        """è§£æå•ä¸ªè®¯é£ç»“æœ - ä¿®å¤action/dataæ ¼å¼è§£æ"""
        try:
            # è®°å½•ç»“æœæ¥æ”¶æ—¶é—´ï¼ˆç”¨äºå»¶æ—¶è®¡ç®—ï¼‰
            receive_time = time.time()
            self.result_receive_count += 1
            
            data = json.loads(json_str)
            logger.debug(f"ğŸ” è§£æJSONå¯¹è±¡: {json.dumps(data, ensure_ascii=False)}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯è®¯é£çš„actionæ ¼å¼
            if "action" in data and data.get("action") == "result":
                # è§£ædataå­—æ®µä¸­çš„JSONå­—ç¬¦ä¸²
                data_str = data.get("data", "")
                if not data_str:
                    logger.debug("ğŸ” dataå­—æ®µä¸ºç©º")
                    return None
                
                try:
                    # äºŒæ¬¡è§£ædataå­—æ®µ
                    inner_data = json.loads(data_str)
                    logger.debug(f"ğŸ” è§£ædataå†…å®¹: {json.dumps(inner_data, ensure_ascii=False)}")
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«cnå­—æ®µ
                    cn = inner_data.get("cn", {})
                    if not cn:
                        logger.debug("ğŸ” cnå­—æ®µä¸ºç©º")
                        return None
                    
                    st = cn.get("st", {})
                    if not st:
                        logger.debug("ğŸ” stå­—æ®µä¸ºç©º")
                        return None
                    
                    # æå–æ–‡æœ¬å†…å®¹
                    temp_result = self._extract_text_from_rt(st.get("rt", []))
                    
                    # æ ¹æ®typeåˆ¤æ–­å¤„ç†é€»è¾‘
                    type_value = st.get("type")
                    logger.info(f"ğŸ¯ è¯†åˆ«ç»“æœ - ç±»å‹: {type_value}, æ–‡æœ¬: '{temp_result}'")
                    
                    if temp_result:  # åªè¦æœ‰æ–‡æœ¬å°±å¤„ç†
                        # è®¡ç®—å»¶æ—¶
                        self._calculate_and_log_latency(receive_time, type_value, temp_result)
                        
                        if type_value == "1":
                            # å®æ—¶è½¬å†™å†…å®¹ï¼ˆä¸´æ—¶ç»“æœï¼‰
                            self.temp_result = temp_result
                            self.recognized_text = ''.join(self.final_result) + self.temp_result
                            
                            logger.info(f"ğŸš€ æ”¶åˆ°å®æ—¶ç»“æœ: '{temp_result}' (ç´¯ç§¯: '{self.recognized_text}')")
                            
                            return {
                                "type": "result",
                                "text": temp_result,
                                "accumulated_text": self.recognized_text,
                                "is_final": False,
                                "result_type": "realtime"
                            }
                            
                        elif type_value == "0":
                            # å®Œæ•´è½¬å†™å†…å®¹ï¼ˆæœ€ç»ˆç»“æœï¼‰
                            self.final_result.append(temp_result)
                            self.temp_result = ""  # æ¸…ç©ºä¸´æ—¶ç»“æœ
                            self.recognized_text = ''.join(self.final_result)
                            
                            logger.info(f"ğŸ“ æœ€ç»ˆç»“æœç¡®è®¤: {temp_result} (ç´¯ç§¯: {self.recognized_text})")
                            
                            return {
                                "type": "result", 
                                "text": temp_result,
                                "accumulated_text": self.recognized_text,
                                "is_final": True,
                                "result_type": "final"
                            }
                    
                    return None
                    
                except json.JSONDecodeError as e:
                    logger.warning(f"âŒ è§£ædataå­—æ®µJSONå¤±è´¥: {e}")
                    return None
                    
            elif "cn" in data:
                # å…¼å®¹ç›´æ¥cnæ ¼å¼ï¼ˆå¤‡ç”¨ï¼‰
                cn = data.get("cn", {})
                st = cn.get("st", {})
                temp_result = self._extract_text_from_rt(st.get("rt", []))
                type_value = st.get("type")
                
                if temp_result:
                    logger.info(f"ğŸ¯ ç›´æ¥cnæ ¼å¼ - ç±»å‹: {type_value}, æ–‡æœ¬: '{temp_result}'")
                    # è®¡ç®—å»¶æ—¶ï¼ˆå…¼å®¹æ ¼å¼ï¼‰
                    self._calculate_and_log_latency(receive_time, type_value, temp_result)
                    
                    # å¤„ç†é€»è¾‘åŒä¸Š
                    if type_value == "1":
                        self.temp_result = temp_result
                        self.recognized_text = ''.join(self.final_result) + self.temp_result
                        return {
                            "type": "result",
                            "text": temp_result,
                            "accumulated_text": self.recognized_text,
                            "is_final": False,
                            "result_type": "realtime"
                        }
                    elif type_value == "0":
                        self.final_result.append(temp_result)
                        self.temp_result = ""
                        self.recognized_text = ''.join(self.final_result)
                        return {
                            "type": "result",
                            "text": temp_result,
                            "accumulated_text": self.recognized_text,
                            "is_final": True,
                            "result_type": "final"
                        }
            else:
                logger.debug("ğŸ” ä¸æ˜¯è®¯é£è¯†åˆ«ç»“æœæ ¼å¼")
                return None
            
        except json.JSONDecodeError as e:
            logger.warning(f"âŒ JSONè§£æå¤±è´¥: {e}, æ•°æ®: {json_str[:100]}...")
            return None
        except Exception as e:
            logger.warning(f"âš ï¸ è§£æè®¯é£ç»“æœå¼‚å¸¸: {e}")
            return None
    
    def _extract_text_from_rt(self, rt_array: list) -> str:
        """ä»rtæ•°ç»„ä¸­æå–æ–‡æœ¬ - æŒ‰ç…§demoçš„è§£æè·¯å¾„"""
        text_parts = []
        
        try:
            for rt_obj in rt_array:
                ws_arr = rt_obj.get("ws", [])
                for ws_obj in ws_arr:
                    cw_arr = ws_obj.get("cw", [])
                    for cw_obj in cw_arr:
                        w_str = cw_obj.get("w", "")
                        if w_str:
                            text_parts.append(w_str)
            
            result = ''.join(text_parts)
            logger.debug(f"ğŸ” ä»rtæ•°ç»„æå–æ–‡æœ¬: '{result}'")
            return result
            
        except Exception as e:
            logger.warning(f"âš ï¸ ä»rtæ•°ç»„æå–æ–‡æœ¬å¤±è´¥: {e}")
            return ""
    
    def _calculate_and_log_latency(self, receive_time: float, type_value: str, text: str):
        """è®¡ç®—å¹¶è®°å½•å»¶æ—¶"""
        try:
            if self.last_audio_send_time is None:
                logger.debug("âš ï¸ æ— éŸ³é¢‘å‘é€æ—¶é—´è®°å½•ï¼Œæ— æ³•è®¡ç®—å»¶æ—¶")
                return
            
            # è®¡ç®—ä»æœ€åä¸€æ¬¡å‘é€éŸ³é¢‘åˆ°æ”¶åˆ°ç»“æœçš„å»¶æ—¶
            latency_ms = (receive_time - self.last_audio_send_time) * 1000
            
            # è®¡ç®—ä»å¼€å§‹å½•éŸ³åˆ°ç°åœ¨çš„æ€»æ—¶é•¿
            total_duration_ms = 0
            if self.first_audio_send_time:
                total_duration_ms = (receive_time - self.first_audio_send_time) * 1000
            
            # æ ¹æ®ç»“æœç±»å‹é€‰æ‹©ä¸åŒçš„æ—¥å¿—çº§åˆ«
            if type_value == "0":  # æœ€ç»ˆç»“æœ
                logger.info(f"â±ï¸ æœ€ç»ˆç»“æœå»¶æ—¶: {latency_ms:.1f}ms | æ€»æ—¶é•¿: {total_duration_ms:.1f}ms | æ–‡æœ¬: '{text[:20]}...' | åŒ…è®¡æ•°: {self.audio_send_count} | ç»“æœè®¡æ•°: {self.result_receive_count}")
            else:  # å®æ—¶ç»“æœ
                logger.debug(f"â±ï¸ å®æ—¶ç»“æœå»¶æ—¶: {latency_ms:.1f}ms | æ€»æ—¶é•¿: {total_duration_ms:.1f}ms | æ–‡æœ¬: '{text[:20]}...' | åŒ…è®¡æ•°: {self.audio_send_count} | ç»“æœè®¡æ•°: {self.result_receive_count}")
            
            # ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ¯10ä¸ªç»“æœæ‰“å°ä¸€æ¬¡ç»Ÿè®¡ï¼‰
            if self.result_receive_count % 10 == 0:
                avg_latency = latency_ms  # ç®€åŒ–ï¼Œå®é™…å¯ä»¥ä¿å­˜å†å²æ•°æ®è®¡ç®—å¹³å‡å€¼
                logger.info(f"ğŸ“Š å»¶æ—¶ç»Ÿè®¡ - å½“å‰å»¶æ—¶: {latency_ms:.1f}ms | éŸ³é¢‘åŒ…: {self.audio_send_count} | è¯†åˆ«ç»“æœ: {self.result_receive_count}")
                
        except Exception as e:
            logger.warning(f"âš ï¸ è®¡ç®—å»¶æ—¶å¤±è´¥: {e}")
    
    def _perform_realtime_analysis(self) -> Optional[Dict[str, Any]]:
        """æ‰§è¡Œå®æ—¶éŸ³é¢‘åˆ†æ"""
        if not self.realtime_analysis_enabled or not LIBROSA_AVAILABLE:
            return None
            
        try:
            if len(self.analysis_buffer) < 16000:  # è‡³å°‘éœ€è¦0.5ç§’çš„æ•°æ®
                return None
            
            current_time = time.time()
            if current_time - self.last_analysis_time < self.analysis_interval:
                return None
            
            self.last_analysis_time = current_time
            
            # å°†PCMå­—èŠ‚æ•°æ®è½¬æ¢ä¸ºnumpyæ•°ç»„
            audio_samples = np.frombuffer(self.analysis_buffer, dtype=np.int16).astype(np.float32)
            audio_samples = audio_samples / 32768.0  # å½’ä¸€åŒ–åˆ°[-1, 1]
            
            # åˆ†æéŸ³é«˜ (åŸºé¢‘)
            pitch_result = self._analyze_realtime_pitch(audio_samples, 16000)
            
            # åˆ†æéŸ³é‡
            volume_result = self._analyze_realtime_volume(audio_samples)
            
            # åˆ†æè¯­é€Ÿ
            speech_rate = self._analyze_realtime_speech_rate(audio_samples, 16000)
            
            # æ„å»ºåˆ†æç»“æœ
            analysis_result = {
                'timestamp': current_time,
                'pitch': pitch_result,
                'volume': volume_result,
                'speech_rate': speech_rate,
                'buffer_length': len(audio_samples)
            }
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            self.voice_tone_history.append(analysis_result)
            
            # ä¿æŒå†å²è®°å½•é•¿åº¦é™åˆ¶
            if len(self.voice_tone_history) > self.max_history_length:
                self.voice_tone_history.pop(0)
            
            logger.debug(f"ğŸ¼ å®æ—¶éŸ³é¢‘åˆ†æ: éŸ³é«˜={pitch_result['mean']:.1f}Hz, éŸ³é‡={volume_result['mean']:.1f}dB, è¯­é€Ÿ={speech_rate:.1f}")
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"âŒ å®æ—¶éŸ³é¢‘åˆ†æå¤±è´¥: {e}")
            return None
    
    def _analyze_realtime_pitch(self, audio_samples: np.ndarray, sr: int) -> Dict[str, float]:
        """å®æ—¶åˆ†æéŸ³é«˜"""
        try:
            # ä½¿ç”¨ç®€åŒ–çš„éŸ³é«˜æ£€æµ‹ï¼ˆyinç®—æ³•çš„å¿«é€Ÿè¿‘ä¼¼ï¼‰
            f0 = librosa.pyin(audio_samples, fmin=80, fmax=400, sr=sr)[0]
            valid_f0 = f0[~np.isnan(f0)]
            
            if len(valid_f0) > 0:
                mean_pitch = float(np.mean(valid_f0))
                pitch_variance = float(np.var(valid_f0))
                pitch_range = float(np.max(valid_f0) - np.min(valid_f0))
            else:
                mean_pitch = 0.0
                pitch_variance = 0.0
                pitch_range = 0.0
                
            return {
                'mean': mean_pitch,
                'variance': pitch_variance,
                'range': pitch_range
            }
        except:
            return {'mean': 0.0, 'variance': 0.0, 'range': 0.0}
    
    def _analyze_realtime_volume(self, audio_samples: np.ndarray) -> Dict[str, float]:
        """å®æ—¶åˆ†æéŸ³é‡"""
        try:
            # è®¡ç®—RMS
            rms = np.sqrt(np.mean(audio_samples ** 2))
            db = 20 * np.log10(max(rms, 1e-10))  # é¿å…log(0)
            
            return {
                'mean': float(db),
                'rms': float(rms)
            }
        except:
            return {'mean': -60.0, 'rms': 0.0}
    
    def _analyze_realtime_speech_rate(self, audio_samples: np.ndarray, sr: int) -> float:
        """å®æ—¶åˆ†æè¯­é€Ÿ"""
        try:
            # ç®€åŒ–çš„è¯­é€Ÿæ£€æµ‹ï¼šæ£€æµ‹èƒ½é‡å³°å€¼
            hop_length = 512
            frame_length = 2048
            
            # è®¡ç®—çŸ­æ—¶èƒ½é‡
            energy = []
            for i in range(0, len(audio_samples) - frame_length, hop_length):
                frame = audio_samples[i:i + frame_length]
                energy.append(np.sum(frame ** 2))
            
            if len(energy) > 10:
                energy = np.array(energy)
                # æ£€æµ‹èƒ½é‡å³°å€¼ï¼ˆç®€åŒ–çš„è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰
                threshold = np.mean(energy) * 1.5
                peaks = np.sum(energy > threshold)
                
                # ä¼°ç®—è¯­é€Ÿ (æ¯åˆ†é’Ÿçš„éŸ³èŠ‚æ•°)
                duration_minutes = len(audio_samples) / sr / 60
                speech_rate = peaks / max(duration_minutes, 0.01)
                return float(min(speech_rate, 300))  # é™åˆ¶æœ€å¤§å€¼
            
            return 0.0
        except:
            return 0.0
    
    async def _send_voice_analysis_result(self, analysis_result: Dict[str, Any]):
        """å‘é€è¯­è°ƒåˆ†æç»“æœåˆ°å‰ç«¯"""
        try:
            if not self.client_ws:
                return
                
            # æ„å»ºå‘é€ç»™å‰ç«¯çš„æ•°æ®
            message = {
                "type": "voice_analysis",
                "data": {
                    "timestamp": analysis_result["timestamp"],
                    "pitch_mean": analysis_result["pitch"]["mean"],
                    "pitch_variance": analysis_result["pitch"]["variance"],
                    "pitch_range": analysis_result["pitch"]["range"],
                    "volume_mean": analysis_result["volume"]["mean"],
                    "volume_rms": analysis_result["volume"]["rms"],
                    "speech_rate": analysis_result["speech_rate"],
                    "session_id": self.session_id
                },
                "history": [
                    {
                        "timestamp": item["timestamp"],
                        "pitch_mean": item["pitch"]["mean"],
                        "volume_mean": item["volume"]["mean"],
                        "speech_rate": item["speech_rate"]
                    }
                    for item in self.voice_tone_history[-10:]  # åªå‘é€æœ€è¿‘10ä¸ªç‚¹
                ]
            }
            
            await self.client_ws.send_json(message)
            logger.debug(f"ğŸ“Š å‘é€è¯­è°ƒåˆ†æç»“æœ: éŸ³é«˜={analysis_result['pitch']['mean']:.1f}Hz")
            
        except Exception as e:
            logger.error(f"âŒ å‘é€è¯­è°ƒåˆ†æç»“æœå¤±è´¥: {e}")
    
    def get_voice_analysis_history(self) -> List[Dict[str, Any]]:
        """è·å–è¯­è°ƒåˆ†æå†å²è®°å½•"""
        return self.voice_tone_history.copy()
    
    def clear_voice_analysis_history(self):
        """æ¸…ç©ºè¯­è°ƒåˆ†æå†å²è®°å½•"""
        self.voice_tone_history.clear()
        self.analysis_buffer.clear()
        logger.info("ğŸ§¹ è¯­è°ƒåˆ†æå†å²è®°å½•å·²æ¸…ç©º")

    def _calculate_audio_energy(self, audio_data: bytes) -> float:
        """è®¡ç®—éŸ³é¢‘èƒ½é‡ï¼ˆç”¨äºæ£€æµ‹é™éŸ³ï¼‰"""
        try:
            if len(audio_data) < 2:
                return 0.0
            
            # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸º16ä½æ•´æ•°
            import struct
            samples = []
            for i in range(0, len(audio_data) - 1, 2):
                sample = struct.unpack('<h', audio_data[i:i+2])[0]  # å°ç«¯åº16ä½
                samples.append(sample)
            
            if not samples:
                return 0.0
            
            # è®¡ç®—RMSèƒ½é‡
            sum_of_squares = sum(sample * sample for sample in samples)
            rms = (sum_of_squares / len(samples)) ** 0.5
            
            return rms
            
        except Exception as e:
            logger.warning(f"âš ï¸ è®¡ç®—éŸ³é¢‘èƒ½é‡å¤±è´¥: {e}")
            return 0.0


class VoiceSessionManager:
    """è¯­éŸ³ä¼šè¯ç®¡ç†å™¨"""
    
    def __init__(self):
        self.active_sessions: Dict[str, XunfeiVoiceProxy] = {}
        self.session_metadata: Dict[str, Dict] = {}
        
    def create_session(self, session_id: str, user_id: str, interview_session_id: str) -> XunfeiVoiceProxy:
        """åˆ›å»ºè¯­éŸ³ä¼šè¯ - åŒæ­¥ç‰ˆæœ¬ï¼ˆå·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨create_session_asyncï¼‰"""
        logger.warning("âš ï¸ ä½¿ç”¨äº†åºŸå¼ƒçš„åŒæ­¥create_sessionæ–¹æ³•")
        
        # ç®€å•åˆ›å»ºï¼Œä¸å¤„ç†è¿æ¥é™åˆ¶
        proxy = XunfeiVoiceProxy()
        proxy.session_id = session_id
        
        self.active_sessions[session_id] = proxy
        self.session_metadata[session_id] = {
            "user_id": user_id,
            "interview_session_id": interview_session_id,
            "created_at": time.time(),
            "status": "created"
        }
        
        logger.info(f"ğŸ¤ åˆ›å»ºè¯­éŸ³ä¼šè¯: {session_id}")
        return proxy
    
    def get_user_active_session(self, user_id: str) -> Optional[XunfeiVoiceProxy]:
        """è·å–ç”¨æˆ·çš„æ´»è·ƒä¼šè¯"""
        for session_id, metadata in self.session_metadata.items():
            if metadata.get("user_id") == user_id:
                proxy = self.active_sessions.get(session_id)
                if proxy and proxy.is_connected:
                    return proxy
        return None
    
    async def cleanup_old_sessions(self):
        """æ¸…ç†æ—§çš„ä¼šè¯"""
        sessions_to_close = list(self.active_sessions.keys())
        for session_id in sessions_to_close:
            await self.close_session(session_id)
    
    async def create_session_async(self, session_id: str, user_id: str, interview_session_id: str) -> XunfeiVoiceProxy:
        """å¼‚æ­¥åˆ›å»ºè¯­éŸ³ä¼šè¯"""
        
        # é¦–å…ˆæ£€æŸ¥è¯¥ç”¨æˆ·æ˜¯å¦å·²æœ‰æ´»è·ƒä¼šè¯
        existing_session = self.get_user_active_session(user_id)
        if existing_session:
            logger.info(f"ğŸ”„ å¤ç”¨ç”¨æˆ·å·²æœ‰ä¼šè¯: {existing_session.session_id}")
            return existing_session
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡è¿æ¥é™åˆ¶ï¼ˆè®¯é£å…è´¹è´¦å·é™åˆ¶ï¼‰
        if len(self.active_sessions) >= 1:  # è®¯é£é€šå¸¸é™åˆ¶1ä¸ªè¿æ¥
            logger.warning("âš ï¸ è¾¾åˆ°è¿æ¥æ•°é™åˆ¶ï¼Œæ¸…ç†æ—§è¿æ¥")
            await self.cleanup_old_sessions()
        
        # åˆ›å»ºæ–°ä¼šè¯
        if session_id in self.active_sessions:
            logger.warning(f"âš ï¸ ä¼šè¯IDå†²çªï¼Œå¼ºåˆ¶æ¸…ç†: {session_id}")
            await self.close_session(session_id)
        
        proxy = XunfeiVoiceProxy()
        proxy.session_id = session_id
        
        self.active_sessions[session_id] = proxy
        self.session_metadata[session_id] = {
            "user_id": user_id,
            "interview_session_id": interview_session_id,
            "created_at": time.time(),
            "status": "created"
        }
        
        logger.info(f"ğŸ¤ åˆ›å»ºè¯­éŸ³ä¼šè¯: {session_id}")
        return proxy
    
    def get_session(self, session_id: str) -> Optional[XunfeiVoiceProxy]:
        """è·å–è¯­éŸ³ä¼šè¯"""
        return self.active_sessions.get(session_id)
    
    async def close_session(self, session_id: str):
        """å…³é—­è¯­éŸ³ä¼šè¯"""
        try:
            # å®‰å…¨åœ°è·å–å’Œåˆ é™¤ä¼šè¯
            proxy = self.active_sessions.pop(session_id, None)
            metadata = self.session_metadata.pop(session_id, None)
            
            if proxy:
                await proxy.close_connection()
                logger.info(f"ğŸ”š è¯­éŸ³ä¼šè¯å·²å…³é—­: {session_id}")
            else:
                logger.debug(f"ğŸ¤· ä¼šè¯ä¸å­˜åœ¨æˆ–å·²å…³é—­: {session_id}")
                
        except Exception as e:
            logger.warning(f"âš ï¸ å…³é—­ä¼šè¯æ—¶å‡ºç°å¼‚å¸¸: {session_id}, é”™è¯¯: {e}")
            # ç¡®ä¿æ¸…ç†ï¼Œå³ä½¿å‡ºç°å¼‚å¸¸
            self.active_sessions.pop(session_id, None)
            self.session_metadata.pop(session_id, None)
    
    def get_active_sessions(self) -> Dict[str, Dict]:
        """è·å–æ´»è·ƒä¼šè¯åˆ—è¡¨"""
        return self.session_metadata.copy()


# å…¨å±€ä¼šè¯ç®¡ç†å™¨
voice_session_manager = VoiceSessionManager()


# ==================== APIè·¯ç”± ====================

from pydantic import BaseModel

class CreateSessionRequest(BaseModel):
    user_id: str
    interview_session_id: str
    session_id: Optional[str] = None

@router.post("/create-session")
async def create_voice_session(request: CreateSessionRequest):
    """åˆ›å»ºè¯­éŸ³è¯†åˆ«ä¼šè¯"""
    try:
        # ä¼˜å…ˆå¤ç”¨å·²æœ‰ä¼šè¯
        existing_session = voice_session_manager.get_user_active_session(request.user_id)
        if existing_session and existing_session.is_connected:
            logger.info(f"ğŸ”„ å¤ç”¨å·²æœ‰ä¼šè¯: {existing_session.session_id}")
            return {
                "success": True,
                "session_id": existing_session.session_id,
                "status": "reused",
                "message": "å¤ç”¨å·²æœ‰è¯­éŸ³è¯†åˆ«ä¼šè¯"
            }
        
        # æ¸…ç†æ—§è¿æ¥ï¼ˆè®¯é£è¿æ¥æ•°é™åˆ¶ï¼‰
        if len(voice_session_manager.active_sessions) >= 1:
            logger.info("ğŸ§¹ æ¸…ç†æ—§è¿æ¥ä»¥é¿å…è¶…é™")
            await voice_session_manager.cleanup_old_sessions()
        
        # ç”Ÿæˆæ–°çš„ä¼šè¯ID
        session_id = request.session_id
        if not session_id:
            session_id = f"voice_{request.user_id}_{int(time.time())}"
        
        # åˆ›å»ºæ–°ä¼šè¯
        proxy = await voice_session_manager.create_session_async(
            session_id=session_id,
            user_id=request.user_id,
            interview_session_id=request.interview_session_id
        )
        
        # è¿æ¥è®¯é£æœåŠ¡
        success = await proxy.connect_xunfei()
        if not success:
            await voice_session_manager.close_session(session_id)
            raise HTTPException(status_code=500, detail="è¿æ¥è¯­éŸ³è¯†åˆ«æœåŠ¡å¤±è´¥")
        
        return {
            "success": True,
            "session_id": session_id,
            "status": "connected",
            "message": "è¯­éŸ³è¯†åˆ«ä¼šè¯åˆ›å»ºæˆåŠŸ"
        }
        
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºè¯­éŸ³ä¼šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºä¼šè¯å¤±è´¥: {str(e)}")


@router.websocket("/recognition/{session_id}")
async def voice_recognition_websocket(websocket: WebSocket, session_id: str):
    """WebSocketè¯­éŸ³è¯†åˆ«ç«¯ç‚¹"""
    await websocket.accept()
    logger.info(f"ğŸ”— WebSocketè¿æ¥å»ºç«‹: {session_id}")
    
    proxy = voice_session_manager.get_session(session_id)
    if not proxy:
        await websocket.send_json({
            "type": "error",
            "message": "ä¼šè¯ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºä¼šè¯"
        })
        await websocket.close()
        return
    
    proxy.client_ws = websocket
    
    try:
        # å¯åŠ¨è¯†åˆ«ç»“æœç›‘å¬ä»»åŠ¡
        recognition_task = asyncio.create_task(
            listen_recognition_results(proxy, websocket)
        )
        
        # å¤„ç†å®¢æˆ·ç«¯æ¶ˆæ¯
        while proxy.is_connected:
            try:
                # æ¥æ”¶å®¢æˆ·ç«¯æ•°æ®
                data = await websocket.receive()
                
                if data.get("type") == "websocket.receive":
                    if "bytes" in data:
                        # éŸ³é¢‘æ•°æ®
                        audio_data = data["bytes"]
                        success = await proxy.send_audio_data(audio_data)
                        if not success:
                            # å‘é€å¤±è´¥ï¼Œè¿æ¥å¯èƒ½å·²æ–­å¼€
                            break
                        
                    elif "text" in data:
                        # æ§åˆ¶æŒ‡ä»¤
                        try:
                            message = json.loads(data["text"])
                            await handle_control_message(proxy, websocket, message)
                        except json.JSONDecodeError:
                            logger.warning("âš ï¸ æ”¶åˆ°æ— æ•ˆJSONæ§åˆ¶æŒ‡ä»¤")
                
            except WebSocketDisconnect:
                logger.info(f"ğŸ”Œ WebSocketå®¢æˆ·ç«¯æ–­å¼€: {session_id}")
                break
            except Exception as e:
                # é™é»˜å¤„ç†å¼‚å¸¸ï¼Œé¿å…å¤§é‡é”™è¯¯æ—¥å¿—
                if "1000" not in str(e) and "disconnect" not in str(e).lower():
                    logger.warning(f"âš ï¸ WebSocketæ¶ˆæ¯å¤„ç†å¼‚å¸¸: {e}")
                break
    
    except Exception:
        # é™é»˜å¤„ç†é¡¶å±‚å¼‚å¸¸
        pass
    
    finally:
        # æ¸…ç†èµ„æº
        if 'recognition_task' in locals():
            recognition_task.cancel()
        
        await voice_session_manager.close_session(session_id)
        logger.info(f"ğŸ§¹ WebSocketä¼šè¯æ¸…ç†å®Œæˆ: {session_id}")


async def listen_recognition_results(proxy: XunfeiVoiceProxy, websocket: WebSocket):
    """ç›‘å¬è¯†åˆ«ç»“æœ"""
    result_count = 0
    no_result_count = 0
    max_no_result = 200  # 20ç§’æ— ç»“æœåè®°å½•è­¦å‘Šï¼ˆ0.1s * 200ï¼‰
    
    try:
        logger.info(f"ğŸ§ å¼€å§‹ç›‘å¬è¯†åˆ«ç»“æœ - ä¼šè¯: {proxy.session_id}")
        
        while proxy.is_connected and proxy.xunfei_ws:
            try:
                # å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œé¿å…é”™è¿‡è®¯é£çš„å®æ—¶ç»“æœ
                result = await asyncio.wait_for(proxy.receive_recognition_result(), timeout=2.0)
                if result:
                    result_count += 1
                    no_result_count = 0  # é‡ç½®æ— ç»“æœè®¡æ•°
                    
                    logger.info(f"ğŸ“¥ æ”¶åˆ°è¯†åˆ«ç»“æœ #{result_count}: {result.get('result_type', 'unknown')} - '{result.get('text', '')[:30]}...'")
                    await websocket.send_json(result)
                    
                    # å¦‚æœæ˜¯æœ€ç»ˆç»“æœï¼Œä»…å‘é€è¯†åˆ«ç»“æœï¼Œä¸è‡ªåŠ¨è§¦å‘LangGraph
                    if result.get("type") == "result" and result.get("is_final"):
                        text = result.get("text", "").strip()
                        if text:
                            logger.info(f"âœ… æœ€ç»ˆè¯†åˆ«æ–‡æœ¬: '{text}'")
                            
                            # å‘é€æœ€ç»ˆè¯†åˆ«ç»“æœç»™å‰ç«¯
                            await websocket.send_json({
                                "type": "final_result",
                                "text": text,
                                "session_id": proxy.session_id
                            })
                            # æ³¨æ„ï¼šä¸å†è‡ªåŠ¨è°ƒç”¨integrate_with_interview_system
                            # LangGraphé›†æˆå°†åœ¨å‰ç«¯ä¸»åŠ¨åœæ­¢å½•éŸ³æ—¶è§¦å‘
                    else:
                        # å®æ—¶ç»“æœï¼Œç»§ç»­ç­‰å¾…æ›´å¤šå†…å®¹
                        logger.debug(f"ğŸ”„ å®æ—¶ç»“æœï¼Œç»§ç»­ç›‘å¬...")
                else:
                    no_result_count += 1
                    
                    # æ›´é¢‘ç¹çš„çŠ¶æ€æ£€æŸ¥å’Œæ—¥å¿—è¾“å‡º
                    if no_result_count % 10 == 0:  # æ¯20ç§’æ£€æŸ¥ä¸€æ¬¡ï¼ˆ2s * 10ï¼‰
                        logger.info(f"ğŸ“Š ç›‘å¬çŠ¶æ€ - å·²æ”¶åˆ° {result_count} ä¸ªç»“æœï¼Œè¿ç»­æ— ç»“æœ: {no_result_count} æ¬¡")
                        logger.info(f"ğŸ” æœŸæœ›çŠ¶æ€ - å°åŒ…æ¨¡å¼åº”è¯¥æ¯0.5ç§’æ”¶åˆ°å®æ—¶ç»“æœ(type=1)")
                        logger.debug(f"ğŸ”— è¿æ¥çŠ¶æ€ - ä»£ç†: {proxy.is_connected}, è®¯é£WS: {proxy.xunfei_ws is not None}")
                        
                        if not proxy.is_connected:
                            logger.warning("âš ï¸ ä»£ç†è¿æ¥å·²æ–­å¼€")
                            break
                        if not proxy.xunfei_ws:
                            logger.warning("âš ï¸ è®¯é£WebSocketè¿æ¥å·²æ–­å¼€")
                            break
                
            except asyncio.TimeoutError:
                # è¶…æ—¶ï¼Œä½†éœ€è¦è®°å½•é¢‘ç‡
                no_result_count += 1
                if no_result_count % 5 == 0:  # æ¯10ç§’è®°å½•ä¸€æ¬¡è¶…æ—¶
                    logger.debug(f"â° ç›‘å¬è¶…æ—¶ #{no_result_count} - è®¯é£æš‚æ— è¿”å›æ•°æ®")
                continue
            except (ConnectionClosedError, websockets.exceptions.ConnectionClosed):
                # è¿æ¥æ­£å¸¸å…³é—­
                logger.info("ğŸ”Œ è®¯é£è¿æ¥å…³é—­ï¼Œåœæ­¢ç›‘å¬")
                break
            except Exception as e:
                # å…¶ä»–é”™è¯¯ï¼Œè®°å½•å¹¶é€€å‡º
                logger.error(f"âŒ è¯†åˆ«ç»“æœæ¥æ”¶å¼‚å¸¸: {type(e).__name__}: {e}")
                break
                
    except Exception as e:
        logger.error(f"âŒ ç›‘å¬è¯†åˆ«ç»“æœå¼‚å¸¸: {e}")
    
    logger.info(f"ğŸ”š è¯†åˆ«ç»“æœç›‘å¬å·²åœæ­¢ - æ€»å…±æ”¶åˆ° {result_count} ä¸ªç»“æœ")


async def handle_control_message(proxy: XunfeiVoiceProxy, websocket: WebSocket, message: Dict):
    """å¤„ç†æ§åˆ¶æ¶ˆæ¯"""
    try:
        command = message.get("command")
        
        if command == "start":
            logger.info("ğŸ¤ å¼€å§‹è¯­éŸ³è¯†åˆ«")
            await websocket.send_json({
                "type": "status",
                "status": "recording",
                "message": "å¼€å§‹å½•éŸ³"
            })
        
        elif command == "stop":
            logger.info("â¹ï¸ å‰ç«¯ä¸»åŠ¨åœæ­¢è¯­éŸ³è¯†åˆ«")
            await proxy.send_end_signal()
            
            # è·å–ç´¯ç§¯çš„å®Œæ•´è¯†åˆ«æ–‡æœ¬
            final_text = proxy.get_final_text()
            logger.info(f"ğŸ” å®Œæ•´è¯†åˆ«æ–‡æœ¬: '{final_text}' (å­—ç¬¦æ•°: {len(final_text)})")
            
            # å‘é€è¯†åˆ«å®ŒæˆçŠ¶æ€
            await websocket.send_json({
                "type": "recording_stopped", 
                "text": final_text,
                "accumulated_text": final_text,
                "is_final": True,
                "message": "å½•éŸ³å·²åœæ­¢ï¼Œå¼€å§‹AIåˆ†æ"
            })
            
            # ğŸ¯ å…³é”®ä¿®æ”¹ï¼šç°åœ¨åœ¨å‰ç«¯åœæ­¢å½•éŸ³æ—¶æ‰è§¦å‘LangGraphæ„ŸçŸ¥èŠ‚ç‚¹
            if final_text and final_text.strip():
                logger.info("ğŸš€ å‰ç«¯åœæ­¢å½•éŸ³è§¦å‘ - å¼€å§‹è°ƒç”¨LangGraphæ„ŸçŸ¥èŠ‚ç‚¹")
                ai_response = await integrate_with_interview_system(proxy, final_text)
                if ai_response and ai_response.get("success"):
                    # å°†AIå›å¤å‘é€ç»™å‰ç«¯
                    await websocket.send_json({
                        "type": "ai_response",
                        "message": ai_response["message"],
                        "user_profile": ai_response.get("user_profile"),
                        "completeness_score": ai_response.get("completeness_score"),
                        "missing_info": ai_response.get("missing_info"),
                        "user_emotion": ai_response.get("user_emotion"),
                        "decision": ai_response.get("decision"),
                        "interview_stage": ai_response.get("interview_stage"),
                        "session_id": proxy.session_id
                    })
                    logger.info("âœ… LangGraphæ„ŸçŸ¥èŠ‚ç‚¹å¤„ç†å®Œæˆï¼ŒAIå›å¤å·²å‘é€")
                else:
                    logger.warning("âš ï¸ LangGraphå¤„ç†å¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆAIå›å¤")
            else:
                logger.warning("âš ï¸ è¯†åˆ«æ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡LangGraphæ„ŸçŸ¥èŠ‚ç‚¹")
        
        elif command == "cancel":
            logger.info("âŒ å–æ¶ˆè¯­éŸ³è¯†åˆ«")
            await websocket.send_json({
                "type": "status",
                "status": "cancelled",
                "message": "è¯†åˆ«å·²å–æ¶ˆ"
            })
        
        else:
            logger.warning(f"âš ï¸ æœªçŸ¥æ§åˆ¶å‘½ä»¤: {command}")
            
    except Exception as e:
        logger.error(f"âŒ å¤„ç†æ§åˆ¶æ¶ˆæ¯å¤±è´¥: {e}")
        await websocket.send_json({
            "type": "error",
            "message": f"å¤„ç†å‘½ä»¤å¤±è´¥: {str(e)}"
        })


async def integrate_with_interview_system(proxy: XunfeiVoiceProxy, recognized_text: str):
    """å°†è¯­éŸ³è¯†åˆ«æ–‡æœ¬é›†æˆåˆ°LangGraphé¢è¯•ç³»ç»Ÿ"""
    try:
        if not recognized_text or not recognized_text.strip():
            logger.warning("âš ï¸ è¯†åˆ«æ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡é›†æˆ")
            return None
        
        # è·å–ä¼šè¯å…ƒæ•°æ®
        session_metadata = voice_session_manager.session_metadata.get(proxy.session_id)
        if not session_metadata:
            logger.error("âŒ æ‰¾ä¸åˆ°ä¼šè¯å…ƒæ•°æ®")
            return await generate_mock_response(recognized_text)
        
        user_id = session_metadata["user_id"]
        interview_session_id = session_metadata["interview_session_id"]
        
        logger.info(f"ğŸ¤– è¯­éŸ³æ–‡æœ¬é›†æˆåˆ°LangGraphç³»ç»Ÿ: {recognized_text[:50]}...")
        
        # æ£€æŸ¥LangGraphæ¨¡å—æ˜¯å¦å¯ç”¨
        if not LANGGRAPH_CHAT_AVAILABLE:
            logger.warning("âš ï¸ LangGraphèŠå¤©æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå“åº”")
            return await generate_mock_response(recognized_text)
        
        # è·å–LangGraphæ™ºèƒ½ä½“
        agent = get_langgraph_agent()
        if not agent:
            logger.warning("âš ï¸ LangGraphæ™ºèƒ½ä½“ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå“åº”")
            return await generate_mock_response(recognized_text)
        
        # æ£€æŸ¥é¢è¯•ä¼šè¯æ˜¯å¦å­˜åœ¨
        session_info = active_sessions.get(interview_session_id)
        if not session_info:
            # å°è¯•ä»æ•°æ®åº“æ¢å¤ä¼šè¯
            try:
                session_mgr = get_session_manager()
                session_info = session_mgr.get_session(interview_session_id)
                
                if session_info:
                    active_sessions[interview_session_id] = session_info
                    logger.info(f"ğŸ”„ ä»æ•°æ®åº“æ¢å¤é¢è¯•ä¼šè¯: {interview_session_id}")
                else:
                    logger.warning(f"âš ï¸ é¢è¯•ä¼šè¯ä¸å­˜åœ¨: {interview_session_id}")
                    return await generate_mock_response(recognized_text)
            except Exception as e:
                logger.error(f"âŒ æ¢å¤ä¼šè¯å¤±è´¥: {e}")
                return await generate_mock_response(recognized_text)
        
        # æ„å»ºç”¨æˆ·ç”»åƒ
        current_profile = {
            "basic_info": {
                "name": session_info.get("user_name", "ç”¨æˆ·"),
                "target_position": session_info.get("target_position", "æœªçŸ¥èŒä½"),
                "target_field": session_info.get("target_field", "æŠ€æœ¯é¢è¯•"),
            },
            "completeness_score": 0.3
        }
        
        # è°ƒç”¨LangGraphå¤„ç†è¯­éŸ³è¯†åˆ«æ–‡æœ¬
        result = await agent.process_message_via_langgraph(
            user_id=user_id,
            session_id=interview_session_id,
            user_name=session_info.get("user_name", "ç”¨æˆ·"),
            target_position=session_info.get("target_position", "æœªçŸ¥èŒä½"),
            user_message=recognized_text,
            user_profile=current_profile
        )
        
        if result["success"]:
            logger.info("âœ… LangGraphå¤„ç†è¯­éŸ³æ–‡æœ¬æˆåŠŸ")
            return {
                "success": True,
                "message": result["response"],
                "user_profile": result.get("user_profile"),
                "completeness_score": result.get("completeness_score"),
                "missing_info": result.get("missing_info"),
                "user_emotion": result.get("user_emotion"),
                "decision": result.get("decision"),
                "interview_stage": result.get("interview_stage")
            }
        else:
            logger.warning(f"âš ï¸ LangGraphå¤„ç†å¤±è´¥: {result.get('error')}")
            return await generate_mock_response(recognized_text)
        
    except Exception as e:
        logger.error(f"âŒ é›†æˆLangGraphé¢è¯•ç³»ç»Ÿå¤±è´¥: {e}")
        return await generate_mock_response(recognized_text)


async def generate_mock_response(recognized_text: str) -> dict:
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„é¢è¯•å“åº”ï¼ˆå½“LangGraphä¸å¯ç”¨æ—¶ï¼‰"""
    try:
        logger.info(f"ğŸ­ ç”Ÿæˆæ¨¡æ‹Ÿå“åº”: {recognized_text[:30]}...")
        
        # ç®€å•çš„æ–‡æœ¬åˆ†æ
        text_lower = recognized_text.lower()
        
        # æ ¹æ®å…³é”®è¯ç”Ÿæˆä¸åŒçš„å“åº”
        if any(word in text_lower for word in ['é¡¹ç›®', 'project', 'å¼€å‘', 'ä»£ç ', 'ç³»ç»Ÿ']):
            response_message = f"å¬èµ·æ¥æ‚¨æœ‰ä¸°å¯Œçš„é¡¹ç›®ç»éªŒã€‚èƒ½è¯¦ç»†ä»‹ç»ä¸€ä¸‹æ‚¨åœ¨è¿™ä¸ªé¡¹ç›®ä¸­é‡åˆ°çš„æœ€å¤§æŒ‘æˆ˜æ˜¯ä»€ä¹ˆå—ï¼Ÿ"
            missing_info = ["é¡¹ç›®æŒ‘æˆ˜", "è§£å†³æ–¹æ¡ˆ", "æŠ€æœ¯æ ˆè¯¦æƒ…"]
            emotion = "confident"
        elif any(word in text_lower for word in ['æŠ€èƒ½', 'skill', 'è¯­è¨€', 'æ¡†æ¶', 'æŠ€æœ¯']):
            response_message = f"å¾ˆå¥½ï¼Œæ‚¨æåˆ°äº†æŠ€æœ¯æŠ€èƒ½ã€‚èƒ½ä¸¾ä¸ªå…·ä½“ä¾‹å­è¯´æ˜æ‚¨æ˜¯å¦‚ä½•åº”ç”¨è¿™äº›æŠ€æœ¯çš„å—ï¼Ÿ"
            missing_info = ["å…·ä½“åº”ç”¨åœºæ™¯", "é¡¹ç›®æˆæœ", "æŠ€æœ¯æ·±åº¦"]
            emotion = "confident"
        elif any(word in text_lower for word in ['ç»éªŒ', 'experience', 'å·¥ä½œ', 'å…¬å¸']):
            response_message = f"æ‚¨çš„å·¥ä½œç»éªŒå¾ˆæœ‰æ„æ€ã€‚åœ¨è¿™æ®µç»å†ä¸­ï¼Œæ‚¨å­¦åˆ°äº†ä»€ä¹ˆæœ€é‡è¦çš„ä¸œè¥¿ï¼Ÿ"
            missing_info = ["æ ¸å¿ƒæ”¶è·", "æˆé•¿ç»å†", "å›¢é˜Ÿåä½œ"]
            emotion = "confident"
        elif any(word in text_lower for word in ['å­¦ä¹ ', 'å­¦æ ¡', 'å¤§å­¦', 'ä¸“ä¸š']):
            response_message = f"æ‚¨çš„æ•™è‚²èƒŒæ™¯å¾ˆæ£’ã€‚èƒ½è°ˆè°ˆæ‚¨åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­æœ€å°è±¡æ·±åˆ»çš„é¡¹ç›®æˆ–è¯¾ç¨‹å—ï¼Ÿ"
            missing_info = ["å­¦ä¹ é¡¹ç›®", "ä¸“ä¸šæŠ€èƒ½", "å®è·µç»éªŒ"]
            emotion = "neutral"
        else:
            response_message = f"è°¢è°¢æ‚¨çš„å›ç­”ã€‚åŸºäºæ‚¨æåˆ°çš„å†…å®¹ï¼Œæˆ‘æƒ³äº†è§£æ›´å¤šç»†èŠ‚ã€‚èƒ½å…·ä½“å±•å¼€è¯´è¯´å—ï¼Ÿ"
            missing_info = ["è¯¦ç»†ä¿¡æ¯", "å…·ä½“ä¾‹å­", "ç›¸å…³ç»éªŒ"]
            emotion = "neutral"
        
        # æ ¹æ®å›ç­”é•¿åº¦è¯„ä¼°å®Œæ•´åº¦
        completeness = min(0.8, max(0.2, len(recognized_text) / 150))
        
        return {
            "success": True,
            "message": response_message,
            "user_profile": {
                "completeness_score": completeness,
                "extracted_info": {
                    "communication_ability": "è‰¯å¥½" if len(recognized_text) > 30 else "å¾…è§‚å¯Ÿ",
                    "response_detail": "è¯¦ç»†" if len(recognized_text) > 50 else "ç®€æ´"
                }
            },
            "completeness_score": completeness,
            "missing_info": missing_info,
            "user_emotion": emotion,
            "decision": {
                "action_type": "ask_question",
                "reasoning": "éœ€è¦è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯æ¥å®Œå–„ç”¨æˆ·ç”»åƒ"
            },
            "interview_stage": "information_gathering"
        }
        
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆæ¨¡æ‹Ÿå“åº”å¤±è´¥: {e}")
        return {
            "success": True,
            "message": "è°¢è°¢æ‚¨çš„å›ç­”ï¼Œè¯·ç»§ç»­åˆ†äº«æ‚¨çš„æƒ³æ³•ã€‚",
            "completeness_score": 0.3,
            "missing_info": ["æ›´å¤šä¿¡æ¯"],
            "user_emotion": "neutral",
            "decision": {"action_type": "continue", "reasoning": "ç»§ç»­å¯¹è¯"},
            "interview_stage": "general"
        }


@router.delete("/session/{session_id}")
async def close_voice_session(session_id: str):
    """å…³é—­è¯­éŸ³è¯†åˆ«ä¼šè¯"""
    try:
        await voice_session_manager.close_session(session_id)
        
        return {
            "success": True,
            "message": "ä¼šè¯å·²å…³é—­"
        }
        
    except Exception as e:
        logger.error(f"âŒ å…³é—­è¯­éŸ³ä¼šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å…³é—­ä¼šè¯å¤±è´¥: {str(e)}")


@router.get("/sessions")
async def get_active_sessions():
    """è·å–æ´»è·ƒçš„è¯­éŸ³ä¼šè¯åˆ—è¡¨"""
    try:
        sessions = voice_session_manager.get_active_sessions()
        
        return {
            "success": True,
            "sessions": sessions,
            "count": len(sessions)
        }
        
    except Exception as e:
        logger.error(f"âŒ è·å–ä¼šè¯åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–ä¼šè¯åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.get("/health")
async def voice_service_health():
    """è¯­éŸ³æœåŠ¡å¥åº·æ£€æŸ¥"""
    try:
        active_count = len(voice_session_manager.active_sessions)
        
        return {
            "success": True,
            "service": "voice_recognition",
            "status": "healthy",
            "active_sessions": active_count,
            "xunfei_config": {
                "app_id": XUNFEI_CONFIG["app_id"],
                "base_url": XUNFEI_CONFIG["base_url"],
                "sample_rate": XUNFEI_CONFIG["sample_rate"]
            },
            "audio_processing": AUDIO_PROCESSING_AVAILABLE
        }
        
    except Exception as e:
        logger.error(f"âŒ è¯­éŸ³æœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return {
            "success": False,
            "service": "voice_recognition", 
            "status": "unhealthy",
            "error": str(e)
        }


# ==================== è°ƒè¯•ç«¯ç‚¹ ====================

@router.post("/debug/audio-saving/{session_id}")
async def debug_toggle_audio_saving(session_id: str, enabled: bool = True):
    """è°ƒè¯•ï¼šæ§åˆ¶æŒ‡å®šä¼šè¯çš„éŸ³é¢‘ä¿å­˜åŠŸèƒ½"""
    try:
        proxy = voice_session_manager.get_session(session_id)
        if not proxy:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        proxy.enable_audio_saving(enabled)
        audio_info = proxy.get_audio_info()
        
        return {
            "success": True,
            "session_id": session_id,
            "audio_info": audio_info
        }
        
    except Exception as e:
        logger.error(f"âŒ æ§åˆ¶éŸ³é¢‘ä¿å­˜å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }

@router.get("/debug/audio-info/{session_id}")
async def debug_get_audio_info(session_id: str):
    """è°ƒè¯•ï¼šè·å–æŒ‡å®šä¼šè¯çš„éŸ³é¢‘ä¿å­˜ä¿¡æ¯å’Œå»¶æ—¶ç»Ÿè®¡"""
    try:
        proxy = voice_session_manager.get_session(session_id)
        if not proxy:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        audio_info = proxy.get_audio_info()
        
        # æ·»åŠ å»¶æ—¶ç»Ÿè®¡ä¿¡æ¯
        current_time = time.time()
        latency_info = {
            "audio_send_count": proxy.audio_send_count,
            "result_receive_count": proxy.result_receive_count,
            "first_audio_send_time": proxy.first_audio_send_time,
            "last_audio_send_time": proxy.last_audio_send_time,
            "session_duration_ms": 0,
            "last_latency_ms": 0
        }
        
        if proxy.first_audio_send_time:
            latency_info["session_duration_ms"] = (current_time - proxy.first_audio_send_time) * 1000
        
        if proxy.last_audio_send_time:
            latency_info["last_latency_ms"] = (current_time - proxy.last_audio_send_time) * 1000
        
        return {
            "success": True,
            "session_id": session_id,
            "audio_info": audio_info,
            "latency_info": latency_info
        }
        
    except Exception as e:
        logger.error(f"âŒ è·å–éŸ³é¢‘ä¿¡æ¯å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }


# ==================== è¯­è°ƒåˆ†æç«¯ç‚¹ ====================

@router.post("/voice-analysis/{session_id}/toggle")
async def toggle_voice_analysis(session_id: str, enabled: bool = True):
    """å¼€å¯/å…³é—­å®æ—¶è¯­è°ƒåˆ†æ"""
    try:
        proxy = voice_session_manager.get_session(session_id)
        if not proxy:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        proxy.realtime_analysis_enabled = enabled
        
        return {
            "success": True,
            "session_id": session_id,
            "voice_analysis_enabled": enabled,
            "message": f"è¯­è°ƒåˆ†æå·²{'å¼€å¯' if enabled else 'å…³é—­'}"
        }
        
    except Exception as e:
        logger.error(f"âŒ åˆ‡æ¢è¯­è°ƒåˆ†æå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ‡æ¢è¯­è°ƒåˆ†æå¤±è´¥: {str(e)}")


@router.get("/voice-analysis/{session_id}/history")
async def get_voice_analysis_history(session_id: str):
    """è·å–è¯­è°ƒåˆ†æå†å²è®°å½•"""
    try:
        proxy = voice_session_manager.get_session(session_id)
        if not proxy:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        history = proxy.get_voice_analysis_history()
        
        return {
            "success": True,
            "session_id": session_id,
            "history": history,
            "count": len(history),
            "enabled": proxy.realtime_analysis_enabled
        }
        
    except Exception as e:
        logger.error(f"âŒ è·å–è¯­è°ƒåˆ†æå†å²å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–è¯­è°ƒåˆ†æå†å²å¤±è´¥: {str(e)}")


@router.delete("/voice-analysis/{session_id}/history")
async def clear_voice_analysis_history(session_id: str):
    """æ¸…ç©ºè¯­è°ƒåˆ†æå†å²è®°å½•"""
    try:
        proxy = voice_session_manager.get_session(session_id)
        if not proxy:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        proxy.clear_voice_analysis_history()
        
        return {
            "success": True,
            "session_id": session_id,
            "message": "è¯­è°ƒåˆ†æå†å²è®°å½•å·²æ¸…ç©º"
        }
        
    except Exception as e:
        logger.error(f"âŒ æ¸…ç©ºè¯­è°ƒåˆ†æå†å²å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç©ºè¯­è°ƒåˆ†æå†å²å¤±è´¥: {str(e)}")


@router.get("/voice-analysis/status")
async def get_voice_analysis_status():
    """è·å–è¯­è°ƒåˆ†æåŠŸèƒ½çŠ¶æ€"""
    try:
        return {
            "success": True,
            "librosa_available": LIBROSA_AVAILABLE,
            "audio_processing_available": AUDIO_PROCESSING_AVAILABLE,
            "active_sessions": len(voice_session_manager.active_sessions),
            "analysis_enabled_sessions": sum(
                1 for proxy in voice_session_manager.active_sessions.values()
                if getattr(proxy, 'realtime_analysis_enabled', False)
            )
        }
        
    except Exception as e:
        logger.error(f"âŒ è·å–è¯­è°ƒåˆ†æçŠ¶æ€å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }


# ==================== éŸ³é¢‘å¤„ç†å·¥å…· ====================

class AudioProcessor:
    """éŸ³é¢‘å¤„ç†å·¥å…·"""
    
    @staticmethod
    def convert_sample_rate(audio_data: bytes, from_rate: int, to_rate: int) -> bytes:
        """è½¬æ¢é‡‡æ ·ç‡"""
        if not AUDIO_PROCESSING_AVAILABLE:
            logger.warning("âš ï¸ éŸ³é¢‘å¤„ç†åº“ä¸å¯ç”¨ï¼Œè¿”å›åŸå§‹æ•°æ®")
            return audio_data
        
        try:
            # ä½¿ç”¨audioopè¿›è¡Œé‡‡æ ·ç‡è½¬æ¢
            converted = audioop.ratecv(audio_data, 2, 1, from_rate, to_rate, None)[0]
            return converted
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘é‡‡æ ·ç‡è½¬æ¢å¤±è´¥: {e}")
            return audio_data
    
    @staticmethod
    def normalize_audio(audio_data: bytes) -> bytes:
        """éŸ³é¢‘å½’ä¸€åŒ–"""
        if not AUDIO_PROCESSING_AVAILABLE:
            return audio_data
        
        try:
            # è®¡ç®—æœ€å¤§å€¼å¹¶å½’ä¸€åŒ–
            max_val = audioop.max(audio_data, 2)
            if max_val > 0:
                factor = 32767.0 / max_val
                normalized = audioop.mul(audio_data, 2, factor)
                return normalized
            
            return audio_data
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘å½’ä¸€åŒ–å¤±è´¥: {e}")
            return audio_data
    
    @staticmethod
    def validate_audio_format(audio_data: bytes) -> bool:
        """éªŒè¯éŸ³é¢‘æ ¼å¼"""
        try:
            # åŸºæœ¬é•¿åº¦æ£€æŸ¥
            if len(audio_data) < 1024:  # è‡³å°‘1KB
                return False
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„PCMæ•°æ®ï¼ˆç®€å•æ£€æŸ¥ï¼‰
            if len(audio_data) % 2 != 0:  # 16bit PCMåº”è¯¥æ˜¯å¶æ•°é•¿åº¦
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘æ ¼å¼éªŒè¯å¤±è´¥: {e}")
            return False
