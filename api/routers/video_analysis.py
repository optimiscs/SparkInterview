# -*- encoding:utf-8 -*-
"""
å®æ—¶è§†é¢‘å¤šæ¨¡æ€åˆ†ææœåŠ¡
åŸºäºWebSocketå®ç°å‰åç«¯è§†é¢‘åˆ†æé›†æˆ
é›†æˆMediaPipeã€DeepFaceç­‰å·¥å…·è¿›è¡ŒçœŸå®å¤šæ¨¡æ€åˆ†æ

ä¸»è¦åŠŸèƒ½ï¼š
- å®æ—¶è§†é¢‘æµæ¥æ”¶å’Œå¤„ç†
- å¤´éƒ¨å§¿æ€åˆ†æ
- é¢éƒ¨è¡¨æƒ…/æƒ…ç»ªåˆ†æ  
- è§†çº¿è¿½è¸ª
- ä½“æ€è¯­è¨€åˆ†æ
- ä¸è¯­éŸ³è¯†åˆ«ååŒå·¥ä½œ
"""
import asyncio
import json
import logging
import base64
import time
import cv2
import numpy as np
import traceback
from datetime import datetime
from typing import Dict, Optional, Any, List
from io import BytesIO
from pathlib import Path

from fastapi import APIRouter, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel

# è®¾ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# å¤šæ¨¡æ€åˆ†æå·¥å…·
from src.tools.multimodal_analyzer import create_multimodal_analyzer, VideoAnalyzer, DEEPFACE_AVAILABLE

# å¯¼å…¥DeepFaceç”¨äºè°ƒè¯•åˆ†æ
try:
    from deepface import DeepFace
    logger.info("âœ… DeepFaceç›´æ¥å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    DeepFace = None
    logger.error(f"âŒ DeepFaceç›´æ¥å¯¼å…¥å¤±è´¥: {e}")

# è·¯ç”±å™¨
router = APIRouter(tags=["è§†é¢‘åˆ†æ"])

class RealTimeAnalysisManager:
    """å®æ—¶åˆ†æç®¡ç†å™¨ - å¤„ç†è§†é¢‘å¸§ç¼“å­˜å’Œåˆ†æè°ƒåº¦"""
    
    def __init__(self):
        self.video_analyzer = VideoAnalyzer()
        self.frame_buffer = []  # å¸§ç¼“å­˜
        self.analysis_results = []  # åˆ†æç»“æœç¼“å­˜
        self.max_buffer_size = 30  # æœ€å¤šç¼“å­˜30å¸§
        self.analysis_interval = 5  # æ¯5å¸§åˆ†æä¸€æ¬¡
        self.frame_count = 0
        self.last_analysis_time = time.time()
        
        # å®æ—¶çŠ¶æ€è·Ÿè¸ª
        self.current_emotion = {"dominant_emotion": "neutral", "confidence": 0.0}
        self.head_pose_stability = 0.0
        self.eye_contact_ratio = 0.0
        self.tension_level = 0.0
        self.confidence_score = 0.5
        
        # è°ƒè¯•åŠŸèƒ½
        self.debug_enabled = True  # æ˜¯å¦ä¿å­˜è°ƒè¯•å›¾åƒ
        self.debug_frames_saved = 0  # å·²ä¿å­˜çš„è°ƒè¯•å¸§æ•°é‡
        self.max_debug_frames = 50  # æœ€å¤šä¿å­˜è°ƒè¯•å¸§æ•°é‡ï¼ˆå¾ªç¯è¦†ç›–ï¼‰
        self.deepface_backends = ['opencv', 'retinaface', 'mtcnn']  # ä¸åŒçš„æ£€æµ‹å™¨
        self.current_backend_index = 0
        
        logger.info("ğŸ“Š å®æ—¶åˆ†æç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def add_frame(self, frame_data) -> bool:
        """æ·»åŠ æ–°å¸§åˆ°ç¼“å­˜"""
        try:
            logger.debug(f"ğŸ” æ¥æ”¶å¸§æ•°æ®ç±»å‹: {type(frame_data)}, å¤§å°: {len(frame_data) if hasattr(frame_data, '__len__') else 'N/A'}")
            
            # è§£ç å›¾åƒæ•°æ®
            if isinstance(frame_data, str):
                # Base64å­—ç¬¦ä¸²æ ¼å¼
                logger.debug("ğŸ“ å¤„ç†Base64å­—ç¬¦ä¸²æ ¼å¼")
                # ç§»é™¤data URLå‰ç¼€
                if frame_data.startswith('data:image'):
                    frame_data = frame_data.split(',')[1]
                frame_bytes = base64.b64decode(frame_data)
            else:
                # äºŒè¿›åˆ¶æ•°æ®æ ¼å¼
                logger.debug("ğŸ“¦ å¤„ç†äºŒè¿›åˆ¶æ•°æ®æ ¼å¼")
                frame_bytes = frame_data
            
            logger.debug(f"ğŸ”¢ è§£ç åæ•°æ®å¤§å°: {len(frame_bytes)} bytes")
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            nparr = np.frombuffer(frame_bytes, np.uint8)
            frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if frame is None:
                logger.error(f"âŒ å¸§è§£ç å¤±è´¥ - æ•°æ®å‰32å­—èŠ‚: {frame_bytes[:32]}")
                return False
            
            # æ£€æŸ¥å¸§å°ºå¯¸
            height, width = frame.shape[:2]
            logger.debug(f"ğŸ–¼ï¸ å¸§å°ºå¯¸: {width}x{height}")
            
            # æ·»åŠ åˆ°ç¼“å­˜
            timestamp = time.time()
            self.frame_buffer.append({
                'frame': frame,
                'timestamp': timestamp,
                'frame_id': self.frame_count
            })
            self.frame_count += 1
            
            # ç»´æŠ¤ç¼“å­˜å¤§å°
            if len(self.frame_buffer) > self.max_buffer_size:
                self.frame_buffer.pop(0)
            
            logger.debug(f"âœ… æ·»åŠ å¸§ #{self.frame_count}, ç¼“å­˜å¤§å°: {len(self.frame_buffer)}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ å¸§å¤±è´¥: {e}")
            import traceback
            logger.error(f"ğŸ”§ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return False
    
    async def analyze_current_frame(self) -> Optional[Dict[str, Any]]:
        """åˆ†æå½“å‰å¸§"""
        if not self.frame_buffer:
            return None
        
        current_time = time.time()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†æï¼ˆé¿å…è¿‡äºé¢‘ç¹ï¼‰
        if current_time - self.last_analysis_time < 0.5:  # æœ€å°‘0.5ç§’é—´éš”ï¼ŒåŒ¹é…å‰ç«¯2FPS
            return self._get_cached_results()
        
        try:
            # è·å–æœ€æ–°å¸§
            latest_frame_data = self.frame_buffer[-1]
            frame = latest_frame_data['frame']
            
            logger.debug(f"ğŸ” å¼€å§‹åˆ†æå¸§ #{latest_frame_data['frame_id']}")
            
            # æ‰§è¡Œåˆ†æ
            analysis_result = await self._analyze_single_frame(frame)
            
            if analysis_result:
                # æ›´æ–°å®æ—¶çŠ¶æ€
                self._update_realtime_state(analysis_result)
                
                # ç¼“å­˜ç»“æœ
                self.analysis_results.append({
                    'timestamp': current_time,
                    'frame_id': latest_frame_data['frame_id'],
                    'analysis': analysis_result
                })
                
                # ç»´æŠ¤ç»“æœç¼“å­˜å¤§å°
                if len(self.analysis_results) > 10:
                    self.analysis_results.pop(0)
                
                self.last_analysis_time = current_time
                
                logger.info(f"âœ… å¸§åˆ†æå®Œæˆ #{latest_frame_data['frame_id']}")
                return self._format_realtime_result(analysis_result)
            
            return self._get_cached_results()
            
        except Exception as e:
            logger.error(f"âŒ å¸§åˆ†æå¤±è´¥: {e}")
            return self._get_cached_results()
    
    async def _analyze_single_frame(self, frame: np.ndarray) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªå¸§"""
        results = {}
        
        try:
            # ä¿å­˜è°ƒè¯•å›¾åƒï¼ˆå¦‚æœå¯ç”¨ä¸”æœªè¾¾åˆ°é™åˆ¶ï¼‰
            debug_path = self._save_debug_frame(frame)
            if not debug_path:
                debug_path = f"frame_{self.frame_count}"  # ä½¿ç”¨å¤‡ç”¨æ ‡è¯†ç¬¦
            
            # MediaPipeé¢éƒ¨æ£€æµ‹
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            mediapipe_results = self.video_analyzer.face_mesh.process(rgb_frame)
            
            if mediapipe_results.multi_face_landmarks:
                face_landmarks = mediapipe_results.multi_face_landmarks[0]
                
                # å¤´éƒ¨å§¿æ€åˆ†æ
                try:
                    head_pose = self.video_analyzer._analyze_head_pose(face_landmarks, frame.shape)
                    if head_pose:
                        results['head_pose'] = head_pose
                        logger.debug(f"âœ… å¤´éƒ¨å§¿æ€: {head_pose}")
                except Exception as e:
                    logger.warning(f"âš ï¸ å¤´éƒ¨å§¿æ€åˆ†æå¤±è´¥: {e}")
                
                # è§†çº¿æ–¹å‘åˆ†æ
                try:
                    gaze = self.video_analyzer._analyze_gaze_direction(face_landmarks, frame.shape)
                    if gaze:
                        results['gaze'] = gaze
                        logger.debug(f"âœ… è§†çº¿æ–¹å‘: {gaze}")
                except Exception as e:
                    logger.warning(f"âš ï¸ è§†çº¿åˆ†æå¤±è´¥: {e}")
            
            # æƒ…ç»ªåˆ†æï¼ˆDeepFaceï¼‰- å¢å¼ºè°ƒè¯•ç‰ˆæœ¬
            if DEEPFACE_AVAILABLE:
                try:
                    emotion_result = self._analyze_emotion_with_debug(frame, debug_path)
                    if emotion_result:
                        results['emotion'] = emotion_result
                        logger.debug(f"âœ… æƒ…ç»ªåˆ†æ: {emotion_result['dominant_emotion']} ({emotion_result['dominant_score']:.1f}%)")
                except Exception as e:
                    logger.warning(f"âš ï¸ æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
            else:
                logger.debug("âš ï¸ DeepFaceä¸å¯ç”¨ï¼Œè·³è¿‡æƒ…ç»ªåˆ†æ")
            
            # ä½“æ€è¯­è¨€åˆ†æ
            try:
                body_language_result = self.video_analyzer._analyze_body_language(frame)
                if body_language_result:
                    results['body_language'] = body_language_result
                    logger.debug(f"âœ… ä½“æ€è¯­è¨€åˆ†æ: å§¿æ€åˆ†æ•°={body_language_result.get('posture_score', 0):.1f}")
                    
                    # æ›´æ–°å®æ—¶çŠ¶æ€
                    self.posture_score = body_language_result.get('posture_score', 75)
                    self.body_angle = body_language_result.get('body_angle', 0)
                    self.tension_level = body_language_result.get('tension_level', 25) / 100.0  # æ ‡å‡†åŒ–åˆ°0-1
                    self.posture_type = body_language_result.get('posture_type', 'sitting')
            except Exception as e:
                logger.warning(f"âš ï¸ ä½“æ€è¯­è¨€åˆ†æå¤±è´¥: {e}")
            
            # æ‰‹åŠ¿åˆ†æ
            try:
                gesture_result = self.video_analyzer._analyze_gestures(frame)
                if gesture_result:
                    results['gestures'] = gesture_result
                    logger.debug(f"âœ… æ‰‹åŠ¿åˆ†æ: æ´»è·ƒåº¦={gesture_result.get('gesture_activity', 0):.1f}, ä¸»å¯¼æ‰‹åŠ¿={gesture_result.get('dominant_gesture', 'none')}")
                    
                    # æ›´æ–°å®æ—¶çŠ¶æ€
                    self.gesture_activity = gesture_result.get('gesture_activity', 0)
                    self.dominant_gesture = gesture_result.get('dominant_gesture', 'none')
            except Exception as e:
                logger.warning(f"âš ï¸ æ‰‹åŠ¿åˆ†æå¤±è´¥: {e}")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ å•å¸§åˆ†æå¼‚å¸¸: {e}")
            return {}
    
    def _save_debug_frame(self, frame: np.ndarray) -> str:
        """ä¿å­˜è°ƒè¯•å¸§ï¼ˆå¾ªç¯è¦†ç›–æ¨¡å¼ï¼‰"""
        if not self.debug_enabled:
            return ""
        
        try:
            # åˆ›å»ºè°ƒè¯•ç›®å½•
            debug_dir = Path("data/debug_frames")
            debug_dir.mkdir(parents=True, exist_ok=True)
            
            # æ¸…ç†æ—§çš„è°ƒè¯•æ–‡ä»¶ï¼ˆå¦‚æœæ˜¯ç¬¬ä¸€æ¬¡ä¿å­˜ï¼‰
            if self.debug_frames_saved == 0:
                self._cleanup_old_debug_files(debug_dir)
            
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨å¾ªç¯ç´¢å¼•ï¼‰
            debug_index = self.debug_frames_saved % self.max_debug_frames
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
            filename = f"debug_frame_{timestamp}_{self.frame_count}.jpg"
            filepath = debug_dir / filename
            
            # ä¿å­˜å›¾åƒ
            success = cv2.imwrite(str(filepath), frame, [cv2.IMWRITE_JPEG_QUALITY, 95])
            
            if success:
                self.debug_frames_saved += 1
                logger.debug(f"ğŸ’¾ è°ƒè¯•å¸§å·²ä¿å­˜: {filepath} (æ€»è®¡: {self.debug_frames_saved})")
                return str(filepath)
            else:
                logger.warning(f"âš ï¸ è°ƒè¯•å¸§ä¿å­˜å¤±è´¥: {filepath}")
                return ""
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜è°ƒè¯•å¸§å¤±è´¥: {e}")
            return ""
    
    def _cleanup_old_debug_files(self, debug_dir: Path):
        """æ¸…ç†æ—§çš„è°ƒè¯•æ–‡ä»¶"""
        try:
            for file in debug_dir.glob("debug_frame_*"):
                file.unlink()
            logger.info("ğŸ§¹ å·²æ¸…ç†æ—§çš„è°ƒè¯•æ–‡ä»¶")
        except Exception as e:
            logger.warning(f"âš ï¸ æ¸…ç†è°ƒè¯•æ–‡ä»¶å¤±è´¥: {e}")
    
    def _analyze_emotion_with_debug(self, frame: np.ndarray, debug_path: str) -> Optional[Dict[str, Any]]:
        """å¸¦è°ƒè¯•ä¿¡æ¯çš„æƒ…ç»ªåˆ†æ"""
        if not DEEPFACE_AVAILABLE or DeepFace is None:
            logger.error("âŒ DeepFaceä¸å¯ç”¨")
            return None
        
        try:
            # æ£€æŸ¥è¾“å…¥å¸§
            height, width = frame.shape[:2]
            logger.info(f"ğŸ” æƒ…ç»ªåˆ†æè¾“å…¥å¸§: {width}x{height}, è°ƒè¯•å›¾åƒ: {debug_path}")
            
            # æ£€æŸ¥å›¾åƒè´¨é‡
            image_quality = self._assess_image_quality(frame)
            logger.info(f"ğŸ“Š å›¾åƒè´¨é‡è¯„ä¼°: {image_quality}")
            
            # åˆ›å»ºé¢éƒ¨æ£€æµ‹çš„è°ƒè¯•ç‰ˆæœ¬
            frame_for_analysis = frame.copy()
            
            # é¢„å¤„ç†ï¼šè°ƒæ•´å›¾åƒè´¨é‡
            if width > 640:
                scale = 640 / width
                new_width = int(width * scale)  
                new_height = int(height * scale)
                frame_for_analysis = cv2.resize(frame_for_analysis, (new_width, new_height))
                logger.debug(f"ğŸ”„ å›¾åƒç¼©æ”¾: {width}x{height} â†’ {new_width}x{new_height}")
            
            # ä¿å­˜å¤„ç†åçš„å›¾åƒç”¨äºè°ƒè¯•
            processed_debug_path = debug_path.replace('.jpg', '_processed.jpg')
            try:
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                Path(processed_debug_path).parent.mkdir(parents=True, exist_ok=True)
                
                # ä½¿ç”¨æ›´ç¨³å®šçš„ä¿å­˜æ–¹æ³•
                success = cv2.imwrite(processed_debug_path, frame_for_analysis, 
                                    [cv2.IMWRITE_JPEG_QUALITY, 95])
                
                if success:
                    logger.debug(f"ğŸ’¾ å¤„ç†åå›¾åƒå·²ä¿å­˜: {processed_debug_path}")
                else:
                    logger.warning(f"âš ï¸ å¤„ç†åå›¾åƒä¿å­˜å¤±è´¥: {processed_debug_path}")
                    processed_debug_path = debug_path  # ä½¿ç”¨åŸå§‹è·¯å¾„ä½œä¸ºfallback
                    
            except Exception as save_error:
                logger.warning(f"âš ï¸ ä¿å­˜å¤„ç†åå›¾åƒæ—¶å‡ºé”™: {save_error}")
                processed_debug_path = debug_path  # ä½¿ç”¨åŸå§‹è·¯å¾„ä½œä¸ºfallback
            
            # ä½¿ç”¨DeepFaceåˆ†æ - å°è¯•ä¸åŒçš„æ£€æµ‹å™¨  
            current_backend = self.deepface_backends[self.current_backend_index]
            logger.info(f"ğŸ§  å¼€å§‹DeepFaceæƒ…ç»ªåˆ†æ... (ä½¿ç”¨æ£€æµ‹å™¨: {current_backend})")
            
            # ç¡®ä¿æœ‰æœ‰æ•ˆçš„å›¾åƒç”¨äºåˆ†æ
            if frame_for_analysis is None or frame_for_analysis.size == 0:
                logger.error("âŒ åˆ†æç”¨å›¾åƒæ— æ•ˆ")
                return None
            
            try:
                result = DeepFace.analyze(
                    frame_for_analysis, 
                    actions=['emotion'], 
                    enforce_detection=False,
                    detector_backend=current_backend,
                    silent=True
                )
            except Exception as detector_error:
                logger.warning(f"âš ï¸ æ£€æµ‹å™¨ {current_backend} å¤±è´¥: {detector_error}")
                # å°è¯•ä¸‹ä¸€ä¸ªæ£€æµ‹å™¨
                self.current_backend_index = (self.current_backend_index + 1) % len(self.deepface_backends)
                next_backend = self.deepface_backends[self.current_backend_index]
                logger.info(f"ğŸ”„ å°è¯•åˆ‡æ¢åˆ°æ£€æµ‹å™¨: {next_backend}")
                
                try:
                    result = DeepFace.analyze(
                        frame_for_analysis, 
                        actions=['emotion'], 
                        enforce_detection=False,
                        detector_backend=next_backend,
                        silent=True
                    )
                    current_backend = next_backend  # æ›´æ–°å½“å‰ä½¿ç”¨çš„æ£€æµ‹å™¨
                except Exception as fallback_error:
                    logger.error(f"âŒ æ‰€æœ‰æ£€æµ‹å™¨éƒ½å¤±è´¥: {fallback_error}")
                    return None
            
            if isinstance(result, list):
                result = result[0]
            
            emotions = result.get('emotion', {})
            logger.info(f"ğŸ“Š DeepFaceåŸå§‹ç»“æœ: {emotions}")
            
            if not emotions:
                logger.error("âŒ DeepFaceè¿”å›ç©ºçš„æƒ…ç»ªç»“æœ")
                return None
            
            # æ‰¾å‡ºä¸»å¯¼æƒ…ç»ª
            dominant_emotion = max(emotions.items(), key=lambda x: x[1])
            
            # ä¿å­˜åˆ†æç»“æœåˆ°è°ƒè¯•æ–‡ä»¶
            debug_result = {
                'analysis_timestamp': datetime.now().isoformat(),
                'frame_info': {
                    'frame_count': self.frame_count,
                    'original_size': f"{width}x{height}",
                    'processed_size': f"{frame_for_analysis.shape[1]}x{frame_for_analysis.shape[0]}",
                    'debug_path': debug_path,
                    'processed_debug_path': processed_debug_path
                },
                'image_quality': image_quality,
                'deepface_config': {
                    'detector_backend': current_backend,
                    'enforce_detection': False,
                    'actions': ['emotion']
                },
                'deepface_result': {
                    'dominant_emotion': dominant_emotion[0],
                    'dominant_score': float(dominant_emotion[1]),
                    'all_emotions': {k: float(v) for k, v in emotions.items()}
                },
                'problem_analysis': {
                    'is_consistent_angry': bool(dominant_emotion[0] == 'angry' and dominant_emotion[1] > 80),
                    'score_very_high': bool(dominant_emotion[1] > 95),
                    'emotions_distribution': len(emotions),
                    'potential_issues': []
                }
            }
            
            # æ·»åŠ æ½œåœ¨é—®é¢˜åˆ†æ
            if dominant_emotion[0] == 'angry' and dominant_emotion[1] > 80:
                debug_result['problem_analysis']['potential_issues'].append("ä¸€ç›´æ£€æµ‹ä¸ºangryï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜")
            
            if dominant_emotion[1] > 95:
                debug_result['problem_analysis']['potential_issues'].append("æƒ…ç»ªç½®ä¿¡åº¦è¿‡é«˜ï¼Œå¯èƒ½æ£€æµ‹æœ‰è¯¯")
            
            if len(set(emotions.values())) < 3:
                debug_result['problem_analysis']['potential_issues'].append("æƒ…ç»ªåˆ†å¸ƒå•ä¸€ï¼Œå¯èƒ½æ¨¡å‹æœ‰é—®é¢˜")
            
            # ä¿å­˜JSONè°ƒè¯•æ–‡ä»¶ï¼ˆå¯é€‰ï¼Œå¤±è´¥ä¸å½±å“åˆ†æï¼‰
            if debug_path and debug_path != f"frame_{self.frame_count}":
                try:
                    debug_json_path = debug_path.replace('.jpg', '_analysis.json')
                    
                    # ä½¿ç”¨è‡ªå®šä¹‰JSONç¼–ç å™¨å¤„ç†æ‰€æœ‰numpyç±»å‹
                    class NumpyEncoder(json.JSONEncoder):
                        def default(self, obj):
                            if isinstance(obj, np.integer):
                                return int(obj)
                            elif isinstance(obj, np.floating):
                                return float(obj)
                            elif isinstance(obj, np.ndarray):
                                return obj.tolist()
                            elif isinstance(obj, np.bool_):
                                return bool(obj)
                            return super(NumpyEncoder, self).default(obj)
                    
                    with open(debug_json_path, 'w', encoding='utf-8') as f:
                        json.dump(debug_result, f, ensure_ascii=False, indent=2, cls=NumpyEncoder)
                        
                    logger.debug(f"ğŸ’¾ JSONè°ƒè¯•æ–‡ä»¶å·²ä¿å­˜: {debug_json_path}")
                except Exception as json_error:
                    logger.warning(f"âš ï¸ JSONè°ƒè¯•æ–‡ä»¶ä¿å­˜å¤±è´¥: {json_error}")
            
            logger.info(f"âœ… æƒ…ç»ªåˆ†æå®Œæˆ: {dominant_emotion[0]} ({dominant_emotion[1]:.1f}%)")
            
            return {
                'dominant_emotion': dominant_emotion[0],
                'dominant_score': float(dominant_emotion[1]),
                'emotions': {k: float(v) for k, v in emotions.items()},
                'debug_info': debug_result
            }
            
        except Exception as e:
            logger.error(f"âŒ æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
            logger.error(f"ğŸ”§ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return None
    
    def _assess_image_quality(self, frame: np.ndarray) -> Dict[str, Any]:
        """è¯„ä¼°å›¾åƒè´¨é‡"""
        try:
            # åŸºæœ¬ç»Ÿè®¡
            height, width = frame.shape[:2]
            
            # äº®åº¦åˆ†æ
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            mean_brightness = np.mean(gray)
            brightness_std = np.std(gray)
            
            # å¯¹æ¯”åº¦åˆ†æ (ä½¿ç”¨Laplacianæ–¹å·®)
            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            
            # é¢œè‰²åˆ†å¸ƒ
            b_mean, g_mean, r_mean = cv2.mean(frame)[:3]
            
            quality_info = {
                'resolution': f"{width}x{height}",
                'brightness': {
                    'mean': float(mean_brightness),
                    'std': float(brightness_std),
                    'is_too_dark': bool(mean_brightness < 50),
                    'is_too_bright': bool(mean_brightness > 200)
                },
                'contrast': {
                    'laplacian_variance': float(laplacian_var),
                    'is_blurry': bool(laplacian_var < 100)
                },
                'color_balance': {
                    'blue_mean': float(b_mean),
                    'green_mean': float(g_mean), 
                    'red_mean': float(r_mean)
                },
                'potential_issues': []
            }
            
            # é—®é¢˜æ£€æµ‹
            if mean_brightness < 50:
                quality_info['potential_issues'].append("å›¾åƒè¿‡æš—")
            if mean_brightness > 200:
                quality_info['potential_issues'].append("å›¾åƒè¿‡äº®")
            if laplacian_var < 100:
                quality_info['potential_issues'].append("å›¾åƒæ¨¡ç³Š")
            if brightness_std < 20:
                quality_info['potential_issues'].append("å¯¹æ¯”åº¦è¿‡ä½")
            
            return quality_info
            
        except Exception as e:
            logger.error(f"âŒ å›¾åƒè´¨é‡è¯„ä¼°å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _update_realtime_state(self, analysis_result: Dict[str, Any]):
        """æ›´æ–°å®æ—¶çŠ¶æ€"""
        try:
            # æ›´æ–°æƒ…ç»ªçŠ¶æ€
            if 'emotion' in analysis_result:
                emotion = analysis_result['emotion']
                self.current_emotion = {
                    "dominant_emotion": emotion['dominant_emotion'],
                    "confidence": emotion['dominant_score']
                }
                
                # è®¡ç®—ç´§å¼ åº¦ï¼ˆåŸºäºè´Ÿé¢æƒ…ç»ªï¼‰
                negative_emotions = ['angry', 'fear', 'sad']
                negative_score = sum(emotion['emotions'].get(e, 0) for e in negative_emotions)
                self.tension_level = min(1.0, negative_score / 100.0)
                
                # è®¡ç®—è‡ªä¿¡åº¦ï¼ˆåŸºäºæ­£é¢æƒ…ç»ªå’Œä¸­æ€§ï¼‰
                positive_emotions = ['happy', 'neutral']
                positive_score = sum(emotion['emotions'].get(e, 0) for e in positive_emotions)
                self.confidence_score = min(1.0, positive_score / 100.0)
            
            # æ›´æ–°å¤´éƒ¨å§¿æ€ç¨³å®šæ€§
            if 'head_pose' in analysis_result:
                pose = analysis_result['head_pose']
                # åŸºäºå¤´éƒ¨åè½¬è§’åº¦è®¡ç®—ç¨³å®šæ€§
                angle_variance = abs(pose.get('yaw', 0)) + abs(pose.get('pitch', 0)) + abs(pose.get('roll', 0))
                self.head_pose_stability = max(0.0, 1.0 - angle_variance / 90.0)  # 90åº¦ä¸ºå®Œå…¨ä¸ç¨³å®š
            
            # æ›´æ–°çœ¼ç¥æ¥è§¦æ¯”ä¾‹
            if 'gaze' in analysis_result:
                gaze = analysis_result['gaze']
                gaze_magnitude = gaze.get('gaze_magnitude', 0)
                # è§†çº¿åç§»å°äºé˜ˆå€¼è®¤ä¸ºæ˜¯çœ¼ç¥æ¥è§¦
                is_eye_contact = gaze_magnitude < 5.0
                
                # ä½¿ç”¨æ»‘åŠ¨å¹³å‡æ›´æ–°çœ¼ç¥æ¥è§¦æ¯”ä¾‹
                alpha = 0.1  # å¹³æ»‘å› å­
                if is_eye_contact:
                    self.eye_contact_ratio = (1 - alpha) * self.eye_contact_ratio + alpha * 1.0
                else:
                    self.eye_contact_ratio = (1 - alpha) * self.eye_contact_ratio + alpha * 0.0
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°å®æ—¶çŠ¶æ€å¤±è´¥: {e}")
    
    def _format_realtime_result(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–ä¸ºå‰ç«¯éœ€è¦çš„å®æ—¶ç»“æœ"""
        return {
            'type': 'analysis_update',
            'timestamp': time.time(),
            'micro_expressions': {
                'dominant_emotion': self.current_emotion['dominant_emotion'],
                'confidence': round(self.confidence_score * 100, 1),
                'tension': round(self.tension_level * 100, 1),
                'focus': round(self.eye_contact_ratio * 100, 1)
            },
            'body_language': {
                'eye_contact_ratio': round(self.eye_contact_ratio * 100, 1),
                'head_stability': round(self.head_pose_stability * 100, 1),
                'posture_score': round(getattr(self, 'posture_score', 75), 1),
                'body_angle': round(getattr(self, 'body_angle', 0), 1),
                'tension_level': round(getattr(self, 'tension_level', 25), 1),
                'posture_type': getattr(self, 'posture_type', 'sitting'),
                'gesture_activity': round(getattr(self, 'gesture_activity', 0), 1),
                'dominant_gesture': getattr(self, 'dominant_gesture', 'none')
            },
            'voice_analysis': {
                # è¿™éƒ¨åˆ†æ•°æ®æ¥è‡ªè¯­éŸ³è¯†åˆ«æ¨¡å—ï¼Œè¿™é‡Œæä¾›å ä½
                'speech_rate': 0,
                'pitch_variance': 0,
                'volume_consistency': 0
            },
            'quality_assessment': {
                'logic_score': round(self.confidence_score * 100, 1),
                'completeness_score': 75,  # åŸºäºå›ç­”é•¿åº¦ç­‰å› ç´ 
                'relevance_score': 80   # åŸºäºè¯­ä¹‰åˆ†æ
            },
            'suggestions': self._generate_suggestions(),
            'raw_analysis': analysis_result
        }
    
    def _generate_suggestions(self) -> List[Dict[str, str]]:
        """ç”Ÿæˆå®æ—¶å»ºè®®"""
        suggestions = []
        
        # åŸºäºå½“å‰çŠ¶æ€ç”Ÿæˆå»ºè®®
        if self.tension_level > 0.3:
            suggestions.append({
                'type': 'warning',
                'message': 'æ£€æµ‹åˆ°ç´§å¼ æƒ…ç»ªï¼Œå°è¯•æ·±å‘¼å¸æ”¾æ¾'
            })
        
        if self.eye_contact_ratio < 0.6:
            suggestions.append({
                'type': 'info', 
                'message': 'å°è¯•æ›´å¤šåœ°ä¸æ‘„åƒå¤´è¿›è¡Œçœ¼ç¥æ¥è§¦'
            })
        
        if self.head_pose_stability < 0.7:
            suggestions.append({
                'type': 'info',
                'message': 'ä¿æŒå¤´éƒ¨å§¿æ€ç¨³å®šï¼Œé¿å…è¿‡åº¦æ‘†åŠ¨'
            })
        
        if self.confidence_score > 0.8:
            suggestions.append({
                'type': 'success',
                'message': 'è¡¨ç°å‡ºè‰²ï¼ä¿æŒå½“å‰çš„è‡ªä¿¡çŠ¶æ€'
            })
        
        # è‡³å°‘ä¿è¯æœ‰ä¸€ä¸ªå»ºè®®
        if not suggestions:
            suggestions.append({
                'type': 'info',
                'message': 'ç»§ç»­ä¿æŒï¼Œè¡¨ç°å¾ˆå¥½ï¼'
            })
        
        return suggestions[:3]  # æœ€å¤š3ä¸ªå»ºè®®
    
    def _get_cached_results(self) -> Optional[Dict[str, Any]]:
        """è·å–ç¼“å­˜çš„åˆ†æç»“æœ"""
        if self.analysis_results:
            # è¿”å›åŸºäºå½“å‰å®æ—¶çŠ¶æ€çš„æ ¼å¼åŒ–ç»“æœ
            return self._format_realtime_result({})
        return None
    
    def reset_session(self):
        """é‡ç½®ä¼šè¯"""
        self.frame_buffer.clear()
        self.analysis_results.clear()
        self.frame_count = 0
        self.last_analysis_time = time.time()
        
        # é‡ç½®çŠ¶æ€
        self.current_emotion = {"dominant_emotion": "neutral", "confidence": 0.0}
        self.head_pose_stability = 0.0
        self.eye_contact_ratio = 0.0
        self.tension_level = 0.0
        self.confidence_score = 0.5
        
        logger.info("ğŸ”„ åˆ†æä¼šè¯å·²é‡ç½®")


class VideoSessionManager:
    """è§†é¢‘åˆ†æä¼šè¯ç®¡ç†å™¨"""
    
    def __init__(self):
        self.active_sessions: Dict[str, RealTimeAnalysisManager] = {}
        self.session_metadata: Dict[str, Dict] = {}
        logger.info("ğŸ“¹ è§†é¢‘ä¼šè¯ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def create_session(self, session_id: str, user_id: str) -> RealTimeAnalysisManager:
        """åˆ›å»ºè§†é¢‘åˆ†æä¼šè¯"""
        
        # æ£€æŸ¥ä¼šè¯æ˜¯å¦å·²å­˜åœ¨
        if session_id in self.active_sessions:
            logger.info(f"ğŸ”„ å¤ç”¨ç°æœ‰è§†é¢‘åˆ†æä¼šè¯: {session_id}")
            return self.active_sessions[session_id]
        
        # åˆ›å»ºæ–°çš„åˆ†æç®¡ç†å™¨
        analyzer = RealTimeAnalysisManager()
        
        self.active_sessions[session_id] = analyzer
        self.session_metadata[session_id] = {
            'user_id': user_id,
            'created_at': time.time(),
            'status': 'active'
        }
        
        logger.info(f"ğŸ¬ åˆ›å»ºè§†é¢‘åˆ†æä¼šè¯: {session_id}")
        return analyzer
    
    def get_session(self, session_id: str) -> Optional[RealTimeAnalysisManager]:
        """è·å–è§†é¢‘åˆ†æä¼šè¯"""
        return self.active_sessions.get(session_id)
    
    def close_session(self, session_id: str):
        """å…³é—­è§†é¢‘åˆ†æä¼šè¯"""
        analyzer = self.active_sessions.pop(session_id, None)
        metadata = self.session_metadata.pop(session_id, None)
        
        if analyzer:
            analyzer.reset_session()
            logger.info(f"ğŸ”š è§†é¢‘åˆ†æä¼šè¯å·²å…³é—­: {session_id}")
        else:
            logger.debug(f"ğŸ¤· ä¼šè¯ä¸å­˜åœ¨: {session_id}")
    
    def get_active_sessions(self) -> Dict[str, Dict]:
        """è·å–æ´»è·ƒä¼šè¯åˆ—è¡¨"""
        return self.session_metadata.copy()


# å…¨å±€è§†é¢‘ä¼šè¯ç®¡ç†å™¨
video_session_manager = VideoSessionManager()


# ==================== APIè·¯ç”± ====================

class CreateVideoSessionRequest(BaseModel):
    user_id: str
    session_id: Optional[str] = None

@router.post("/create-video-session")
async def create_video_session(request: CreateVideoSessionRequest):
    """åˆ›å»ºè§†é¢‘åˆ†æä¼šè¯"""
    try:
        # ç”Ÿæˆä¼šè¯ID
        session_id = request.session_id
        if not session_id:
            session_id = f"video_{request.user_id}_{int(time.time())}"
        
        # åˆ›å»ºä¼šè¯
        analyzer = video_session_manager.create_session(session_id, request.user_id)
        
        return {
            "success": True,
            "session_id": session_id,
            "status": "created",
            "message": "è§†é¢‘åˆ†æä¼šè¯åˆ›å»ºæˆåŠŸ",
            "deepface_available": DEEPFACE_AVAILABLE
        }
        
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºè§†é¢‘åˆ†æä¼šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºä¼šè¯å¤±è´¥: {str(e)}")


@router.websocket("/video-analysis/{session_id}")
async def video_analysis_websocket(websocket: WebSocket, session_id: str):
    """WebSocketè§†é¢‘åˆ†æç«¯ç‚¹"""
    await websocket.accept()
    logger.info(f"ğŸ”— è§†é¢‘åˆ†æWebSocketè¿æ¥å»ºç«‹: {session_id}")
    
    analyzer = video_session_manager.get_session(session_id)
    if not analyzer:
        await websocket.send_json({
            "type": "error",
            "message": "ä¼šè¯ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºä¼šè¯"
        })
        await websocket.close()
        return
    
    try:
        # å‘é€åˆå§‹çŠ¶æ€
        await websocket.send_json({
            "type": "session_ready",
            "session_id": session_id,
            "deepface_available": DEEPFACE_AVAILABLE,
            "message": "è§†é¢‘åˆ†æä¼šè¯å‡†å¤‡å°±ç»ª"
        })
        
        while True:
            try:
                # æ¥æ”¶å®¢æˆ·ç«¯æ•°æ®
                data = await websocket.receive()
                
                if data.get("type") == "websocket.receive":
                    if "bytes" in data:
                        # è§†é¢‘å¸§æ•°æ® (äºŒè¿›åˆ¶)
                        frame_data = data["bytes"]
                        logger.debug(f"ğŸ“¥ æ”¶åˆ°è§†é¢‘å¸§æ•°æ®: {len(frame_data)} bytes")
                        
                        # æ·»åŠ å¸§åˆ°åˆ†æå™¨
                        if analyzer.add_frame(frame_data):
                            # æ‰§è¡Œåˆ†æ
                            analysis_result = await analyzer.analyze_current_frame()
                            
                            if analysis_result:
                                # å‘é€åˆ†æç»“æœ
                                await websocket.send_json(analysis_result)
                                logger.debug("ğŸ“¤ å‘é€åˆ†æç»“æœ")
                        
                    elif "text" in data:
                        # æ§åˆ¶æŒ‡ä»¤
                        try:
                            message = json.loads(data["text"])
                            logger.debug(f"ğŸ“ æ”¶åˆ°æ§åˆ¶æŒ‡ä»¤: {message}")
                            await handle_video_control_message(analyzer, websocket, message)
                        except json.JSONDecodeError as e:
                            logger.warning(f"âš ï¸ æ”¶åˆ°æ— æ•ˆJSONæ§åˆ¶æŒ‡ä»¤: {data['text'][:100]}... é”™è¯¯: {e}")
                            
                elif data.get("type") == "websocket.disconnect":
                    logger.info("ğŸ”Œ WebSocketå®¢æˆ·ç«¯ä¸»åŠ¨æ–­å¼€")
                    break
                
            except WebSocketDisconnect:
                logger.info(f"ğŸ”Œ è§†é¢‘åˆ†æWebSocketå®¢æˆ·ç«¯æ–­å¼€: {session_id}")
                break
            except Exception as e:
                logger.warning(f"âš ï¸ è§†é¢‘åˆ†æWebSocketæ¶ˆæ¯å¤„ç†å¼‚å¸¸: {e}")
                break
    
    except Exception as e:
        logger.error(f"âŒ è§†é¢‘åˆ†æWebSocketå¼‚å¸¸: {e}")
    
    finally:
        video_session_manager.close_session(session_id)
        logger.info(f"ğŸ§¹ è§†é¢‘åˆ†æWebSocketä¼šè¯æ¸…ç†å®Œæˆ: {session_id}")


async def handle_video_control_message(analyzer: RealTimeAnalysisManager, websocket: WebSocket, message: Dict):
    """å¤„ç†è§†é¢‘æ§åˆ¶æ¶ˆæ¯"""
    try:
        command = message.get("command")
        
        if command == "start_analysis":
            logger.info("ğŸ¬ å¼€å§‹è§†é¢‘åˆ†æ")
            await websocket.send_json({
                "type": "status",
                "status": "analyzing",
                "message": "å¼€å§‹è§†é¢‘åˆ†æ"
            })
        
        elif command == "stop_analysis":
            logger.info("â¹ï¸ åœæ­¢è§†é¢‘åˆ†æ")
            await websocket.send_json({
                "type": "status",
                "status": "stopped",
                "message": "è§†é¢‘åˆ†æå·²åœæ­¢"
            })
        
        elif command == "reset_analysis":
            logger.info("ğŸ”„ é‡ç½®è§†é¢‘åˆ†æ")
            analyzer.reset_session()
            await websocket.send_json({
                "type": "status",
                "status": "reset",
                "message": "è§†é¢‘åˆ†æå·²é‡ç½®"
            })
        
        elif command == "get_current_status":
            # è¿”å›å½“å‰åˆ†æçŠ¶æ€
            current_result = analyzer._get_cached_results()
            if current_result:
                await websocket.send_json(current_result)
        
        else:
            logger.warning(f"âš ï¸ æœªçŸ¥è§†é¢‘æ§åˆ¶å‘½ä»¤: {command}")
            
    except Exception as e:
        logger.error(f"âŒ å¤„ç†è§†é¢‘æ§åˆ¶æ¶ˆæ¯å¤±è´¥: {e}")
        await websocket.send_json({
            "type": "error",
            "message": f"å¤„ç†å‘½ä»¤å¤±è´¥: {str(e)}"
        })


@router.delete("/video-session/{session_id}")
async def close_video_session(session_id: str):
    """å…³é—­è§†é¢‘åˆ†æä¼šè¯"""
    try:
        video_session_manager.close_session(session_id)
        
        return {
            "success": True,
            "message": "è§†é¢‘åˆ†æä¼šè¯å·²å…³é—­"
        }
        
    except Exception as e:
        logger.error(f"âŒ å…³é—­è§†é¢‘åˆ†æä¼šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å…³é—­ä¼šè¯å¤±è´¥: {str(e)}")


@router.get("/video-sessions")
async def get_video_sessions():
    """è·å–æ´»è·ƒçš„è§†é¢‘åˆ†æä¼šè¯åˆ—è¡¨"""
    try:
        sessions = video_session_manager.get_active_sessions()
        
        return {
            "success": True,
            "sessions": sessions,
            "count": len(sessions)
        }
        
    except Exception as e:
        logger.error(f"âŒ è·å–è§†é¢‘ä¼šè¯åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–ä¼šè¯åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.get("/video-analysis-health")
async def video_analysis_health():
    """è§†é¢‘åˆ†ææœåŠ¡å¥åº·æ£€æŸ¥"""
    try:
        active_count = len(video_session_manager.active_sessions)
        
        return {
            "success": True,
            "service": "video_analysis",
            "status": "healthy",
            "active_sessions": active_count,
            "deepface_available": DEEPFACE_AVAILABLE,
            "supported_features": {
                "head_pose_analysis": True,
                "gaze_tracking": True,
                "emotion_analysis": DEEPFACE_AVAILABLE,
                "realtime_analysis": True
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ è§†é¢‘åˆ†ææœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return {
            "success": False,
            "service": "video_analysis",
            "status": "unhealthy",
            "error": str(e)
        }
