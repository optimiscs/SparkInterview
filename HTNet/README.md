# HTNet微表情识别项目说明

## 项目简介

HTNet 是一个专为微表情识别设计的分层 Transformer 网络。该模型能够自动识别面部肌肉运动的关键区域，尤其适合捕捉微表情这种细微且短暂的面部变化。HTNet 结合了局部区域特征和全局语义特征，显著提升了微表情识别的准确率。

---

## 模型结构详解

HTNet 的整体结构分为以下几个核心模块：

### 1. 分块处理（Patch Embedding）

- 输入的人脸光流图像会被划分为多个小块（patch），每个块作为后续特征提取的基本单元。
- 通过卷积和重排操作，将原始图像转为适合 Transformer 处理的高维特征块。

### 2. 分层 Transformer 层（Hierarchical Transformer）

- 模型包含多层 Transformer，每层通过自注意力机制提取局部区域的细粒度特征，同时捕捉不同区域之间的空间关系。
- 每个 Transformer 层都包括：
  - **自注意力机制（Attention）**：自动聚焦于面部运动显著的区域，捕捉长距离依赖。
  - **前馈网络（FeedForward）**：对特征进行非线性变换和升降维，增强表达能力。
  - **归一化（LayerNorm）**：保证特征分布稳定，提升训练效果。
  - **残差连接**：有助于信息流动和深层网络训练。
  - **位置编码**：为每个块加入空间位置信息，帮助模型理解结构。

### 3. 聚合层（Aggregation Block）

- 在每个层级结束后，聚合层用于融合不同区域的特征，实现局部与全局信息的交互。
- 通过卷积和池化操作，逐步压缩空间信息，让模型从细粒度到粗粒度递归聚合面部运动特征。

### 4. 区域特征融合（Fusionmodel）

- 除了整体特征，模型还会单独提取五个面部关键区域（如左右眼、左右嘴角、鼻子）的特征。
- 这些区域特征会与整体特征拼接，通过两层全连接网络进行融合和分类。
- 这样，模型既能关注全局信息，也能聚焦于微表情变化最显著的局部区域，从而提升识别准确率。

### 5. 分类头（MLP Head）

- 最后一层特征会经过归一化处理，然后对空间维度做均值池化，把每个通道的空间特征平均为一个值。
- 最后通过全连接层输出每个类别的得分，实现微表情的分类。

---

## 项目目录结构

请将数据集和代码文件按照如下结构放置：

```
├─datasets
│  ├─three_norm_u_v_os
│  ├─combined_datasets_whole
├─main_HTNet.py
├─Model.py
├─requirements.txt
```

---

## 环境依赖安装

请先安装项目所需的依赖库：

```bash
pip install -r requirements.txt
```

---

## 项目运行方式

### 训练与评估

在命令行中运行以下命令即可开始模型训练和评估：

```bash
python main_HTNet.py --train True
```

---

## 主要流程说明

1. **数据准备**：项目支持多种公开微表情数据集，需提前下载并放入 `datasets` 文件夹。
2. **特征裁剪**：程序会自动检测人脸关键点，并在光流图像上裁剪五个面部区域块。
3. **模型训练**：HTNet 会对每个被试进行独立训练，融合整体与局部区域特征。
4. **结果评估**：训练完成后，模型会输出每个类别的识别准确率等评估指标。

---

## 注意事项

- 请确保数据集格式与代码要求一致，关键文件和文件夹名称不要修改。
- 推荐使用支持 CUDA 的显卡环境以加速训练过程。

---